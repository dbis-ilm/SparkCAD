{"Event":"SparkListenerLogStart","Spark Version":"3.1.2"}
{"Event":"SparkListenerResourceProfileAdded","Resource Profile Id":0,"Executor Resource Requests":{"cores":{"Resource Name":"cores","Amount":2,"Discovery Script":"","Vendor":""},"memory":{"Resource Name":"memory","Amount":1024,"Discovery Script":"","Vendor":""},"offHeap":{"Resource Name":"offHeap","Amount":0,"Discovery Script":"","Vendor":""}},"Task Resource Requests":{"cpus":{"Resource Name":"cpus","Amount":1.0}}}
{"Event":"SparkListenerBlockManagerAdded","Block Manager ID":{"Executor ID":"driver","Host":"host-name","Port":42077},"Maximum Memory":383936102,"Timestamp":1641575642310,"Maximum Onheap Memory":383936102,"Maximum Offheap Memory":0}
{"Event":"SparkListenerEnvironmentUpdate","JVM Information":{"Java Home":"MODIFIED","Java Version":"1.8.0_291 (Oracle Corporation)","Scala Version":"version 2.12.10"},"Spark Properties":{"spark.driver.host":"MODIFIED","spark.eventLog.enabled":"true","spark.driver.port":"38901","spark.jars":"file:/home/MODIFIED/sparkbench-assembly-8.0-SNAPSHOT-dist.jar","spark.app.name":"ScalaSort","spark.scheduler.mode":"FIFO","spark.driver.memory":"1g","spark.executor.instances":"1","spark.submit.pyFiles":"","spark.default.parallelism":"2","spark.app.startTime":"1636543318973","spark.executor.id":"driver","spark.app.initial.jar.urls":"spark://MODIFIED:38901/jars/sparkbench-assembly-8.0-SNAPSHOT-dist.jar","spark.submit.deployMode":"client","spark.master":"yarn","spark.ui.filters":"org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter","spark.executor.memory":"12g","spark.eventLog.dir":"file:/home/MODIFIED/spark-events","spark.executor.cores":"4","spark.driver.appUIAddress":"http://MODIFIED:4040","spark.org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter.param.PROXY_HOSTS":"MODIFIED","spark.org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter.param.PROXY_URI_BASES":"http://MODIFIED","spark.app.id":"application_1635092038229_0101","spark.sql.shuffle.partitions":"2"},"Hadoop Properties":{"hadoop.service.shutdown.timeout":"30s","yarn.resourcemanager.amlauncher.thread-count":"50","yarn.sharedcache.enabled":"false","fs.s3a.connection.maximum":"15","yarn.nodemanager.numa-awareness.numactl.cmd":"/usr/bin/numactl","fs.s3a.impl":"org.apache.hadoop.fs.s3a.S3AFileSystem","yarn.app.mapreduce.am.scheduler.heartbeat.interval-ms":"1000","yarn.timeline-service.timeline-client.number-of-async-entities-to-merge":"10","hadoop.security.kms.client.timeout":"60","hadoop.http.authentication.kerberos.principal":"HTTP/_HOST@LOCALHOST","mapreduce.jobhistory.loadedjob.tasks.max":"-1","mapreduce.framework.name":"yarn","yarn.sharedcache.uploader.server.thread-count":"50","yarn.nodemanager.linux-container-executor.nonsecure-mode.user-pattern":"^[_.A-Za-z0-9][-@_.A-Za-z0-9]{0,255}?[$]?$","tfile.fs.output.buffer.size":"262144","yarn.app.mapreduce.am.job.task.listener.thread-count":"30","hadoop.security.groups.cache.background.reload.threads":"3","yarn.resourcemanager.webapp.cross-origin.enabled":"false","fs.AbstractFileSystem.ftp.impl":"org.apache.hadoop.fs.ftp.FtpFs","hadoop.registry.secure":"false","hadoop.shell.safely.delete.limit.num.files":"100","dfs.bytes-per-checksum":"512","mapreduce.job.acl-view-job":" ","fs.s3a.s3guard.ddb.background.sleep":"25ms","fs.s3a.retry.limit":"${fs.s3a.attempts.maximum}","mapreduce.jobhistory.loadedjobs.cache.size":"5","fs.s3a.s3guard.ddb.table.create":"false","yarn.nodemanager.amrmproxy.enabled":"false","yarn.timeline-service.entity-group-fs-store.with-user-dir":"false","mapreduce.input.fileinputformat.split.minsize":"0","yarn.resourcemanager.container.liveness-monitor.interval-ms":"600000","yarn.resourcemanager.client.thread-count":"50","io.seqfile.compress.blocksize":"1000000","yarn.sharedcache.checksum.algo.impl":"org.apache.hadoop.yarn.sharedcache.ChecksumSHA256Impl","yarn.nodemanager.amrmproxy.interceptor-class.pipeline":"org.apache.hadoop.yarn.server.nodemanager.amrmproxy.DefaultRequestInterceptor","dfs.replication":"1","yarn.timeline-service.entity-group-fs-store.leveldb-cache-read-cache-size":"10485760","mapreduce.reduce.shuffle.fetch.retry.interval-ms":"1000","mapreduce.task.profile.maps":"0-2","yarn.scheduler.include-port-in-node-name":"false","yarn.nodemanager.admin-env":"MALLOC_ARENA_MAX=$MALLOC_ARENA_MAX","yarn.resourcemanager.node-removal-untracked.timeout-ms":"60000","mapreduce.am.max-attempts":"2","hadoop.security.kms.client.failover.sleep.base.millis":"100","mapreduce.jobhistory.webapp.https.address":"0.0.0.0:19890","yarn.node-labels.fs-store.impl.class":"org.apache.hadoop.yarn.nodelabels.FileSystemNodeLabelsStore","yarn.nodemanager.collector-service.address":"${yarn.nodemanager.hostname}:8048","fs.trash.checkpoint.interval":"0","mapreduce.job.map.output.collector.class":"org.apache.hadoop.mapred.MapTask$MapOutputBuffer","yarn.resourcemanager.node-ip-cache.expiry-interval-secs":"-1","hadoop.http.authentication.signature.secret.file":"*********(redacted)","hadoop.jetty.logs.serve.aliases":"true","yarn.resourcemanager.placement-constraints.handler":"disabled","yarn.timeline-service.handler-thread-count":"10","yarn.resourcemanager.max-completed-applications":"1000","yarn.resourcemanager.placement-constraints.algorithm.class":"org.apache.hadoop.yarn.server.resourcemanager.scheduler.constraint.algorithm.DefaultPlacementAlgorithm","yarn.sharedcache.webapp.address":"0.0.0.0:8788","yarn.resourcemanager.delegation.token.renew-interval":"*********(redacted)","yarn.sharedcache.nm.uploader.replication.factor":"10","hadoop.security.groups.negative-cache.secs":"30","yarn.app.mapreduce.task.container.log.backups":"0","mapreduce.reduce.skip.proc-count.auto-incr":"true","hadoop.security.group.mapping.ldap.posix.attr.gid.name":"gidNumber","ipc.client.fallback-to-simple-auth-allowed":"false","yarn.nodemanager.resource.memory.enforced":"true","yarn.client.failover-proxy-provider":"org.apache.hadoop.yarn.client.ConfiguredRMFailoverProxyProvider","yarn.timeline-service.http-authentication.simple.anonymous.allowed":"true","ha.health-monitor.check-interval.ms":"1000","yarn.acl.reservation-enable":"false","yarn.resourcemanager.store.class":"org.apache.hadoop.yarn.server.resourcemanager.recovery.FileSystemRMStateStore","yarn.app.mapreduce.am.hard-kill-timeout-ms":"10000","fs.s3a.etag.checksum.enabled":"false","yarn.nodemanager.container-metrics.enable":"true","yarn.timeline-service.client.fd-clean-interval-secs":"60","yarn.resourcemanager.nodemanagers.heartbeat-interval-ms":"1000","hadoop.common.configuration.version":"3.0.0","fs.s3a.s3guard.ddb.table.capacity.read":"500","yarn.nodemanager.remote-app-log-dir-suffix":"logs","yarn.nodemanager.windows-container.cpu-limit.enabled":"false","yarn.nodemanager.runtime.linux.docker.privileged-containers.allowed":"false","file.blocksize":"67108864","hadoop.registry.zk.retry.ceiling.ms":"60000","yarn.scheduler.configuration.leveldb-store.path":"${hadoop.tmp.dir}/yarn/system/confstore","yarn.sharedcache.store.in-memory.initial-delay-mins":"10","mapreduce.jobhistory.principal":"jhs/_HOST@REALM.TLD","mapreduce.map.skip.proc-count.auto-incr":"true","fs.s3a.committer.name":"file","mapreduce.task.profile.reduces":"0-2","hadoop.zk.num-retries":"1000","yarn.webapp.xfs-filter.enabled":"true","seq.io.sort.mb":"100","yarn.scheduler.configuration.max.version":"100","yarn.timeline-service.webapp.https.address":"${yarn.timeline-service.hostname}:8190","yarn.resourcemanager.scheduler.address":"localhost:8030","yarn.node-labels.enabled":"false","yarn.resourcemanager.webapp.ui-actions.enabled":"true","mapreduce.task.timeout":"600000","yarn.sharedcache.client-server.thread-count":"50","hadoop.security.groups.shell.command.timeout":"0s","hadoop.security.crypto.cipher.suite":"AES/CTR/NoPadding","yarn.nodemanager.elastic-memory-control.oom-handler":"org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.DefaultOOMHandler","yarn.resourcemanager.connect.max-wait.ms":"900000","fs.defaultFS":"hdfs://localhost:9000","yarn.minicluster.use-rpc":"false","fs.har.impl.disable.cache":"true","yarn.webapp.ui2.enable":"false","io.compression.codec.bzip2.library":"system-native","yarn.nodemanager.distributed-scheduling.enabled":"false","mapreduce.shuffle.connection-keep-alive.timeout":"5","yarn.resourcemanager.webapp.https.address":"${yarn.resourcemanager.hostname}:8090","mapreduce.jobhistory.address":"0.0.0.0:10020","yarn.resourcemanager.nm-tokens.master-key-rolling-interval-secs":"*********(redacted)","yarn.is.minicluster":"false","yarn.nodemanager.address":"${yarn.nodemanager.hostname}:0","fs.abfss.impl":"org.apache.hadoop.fs.azurebfs.SecureAzureBlobFileSystem","fs.AbstractFileSystem.s3a.impl":"org.apache.hadoop.fs.s3a.S3A","mapreduce.task.combine.progress.records":"10000","yarn.resourcemanager.epoch.range":"0","yarn.resourcemanager.am.max-attempts":"2","yarn.nodemanager.linux-container-executor.cgroups.hierarchy":"/hadoop-yarn","fs.AbstractFileSystem.wasbs.impl":"org.apache.hadoop.fs.azure.Wasbs","yarn.timeline-service.entity-group-fs-store.cache-store-class":"org.apache.hadoop.yarn.server.timeline.MemoryTimelineStore","fs.ftp.transfer.mode":"BLOCK_TRANSFER_MODE","ipc.server.log.slow.rpc":"false","yarn.resourcemanager.node-labels.provider.fetch-interval-ms":"1800000","yarn.router.webapp.https.address":"0.0.0.0:8091","yarn.nodemanager.webapp.cross-origin.enabled":"false","fs.wasb.impl":"org.apache.hadoop.fs.azure.NativeAzureFileSystem","yarn.resourcemanager.auto-update.containers":"false","yarn.app.mapreduce.am.job.committer.cancel-timeout":"60000","yarn.scheduler.configuration.zk-store.parent-path":"/confstore","yarn.nodemanager.default-container-executor.log-dirs.permissions":"710","yarn.app.attempt.diagnostics.limit.kc":"64","ftp.bytes-per-checksum":"512","yarn.nodemanager.resource.memory-mb":"-1","fs.AbstractFileSystem.abfs.impl":"org.apache.hadoop.fs.azurebfs.Abfs","yarn.timeline-service.writer.flush-interval-seconds":"60","fs.s3a.fast.upload.active.blocks":"4","hadoop.security.credential.clear-text-fallback":"true","yarn.nodemanager.collector-service.thread-count":"5","fs.azure.secure.mode":"false","mapreduce.jobhistory.joblist.cache.size":"20000","fs.ftp.host":"0.0.0.0","yarn.resourcemanager.fs.state-store.num-retries":"0","yarn.resourcemanager.nodemanager-connect-retries":"10","yarn.nodemanager.log-aggregation.num-log-files-per-app":"30","hadoop.security.kms.client.encrypted.key.cache.low-watermark":"0.3f","fs.s3a.committer.magic.enabled":"false","yarn.timeline-service.client.max-retries":"30","dfs.ha.fencing.ssh.connect-timeout":"30000","yarn.log-aggregation-enable":"false","yarn.system-metrics-publisher.enabled":"false","mapreduce.reduce.markreset.buffer.percent":"0.0","fs.AbstractFileSystem.viewfs.impl":"org.apache.hadoop.fs.viewfs.ViewFs","mapreduce.task.io.sort.factor":"10","yarn.nodemanager.amrmproxy.client.thread-count":"25","ha.failover-controller.new-active.rpc-timeout.ms":"60000","yarn.nodemanager.container-localizer.java.opts":"-Xmx256m","mapreduce.jobhistory.datestring.cache.size":"200000","mapreduce.job.acl-modify-job":" ","yarn.nodemanager.windows-container.memory-limit.enabled":"false","yarn.timeline-service.webapp.address":"${yarn.timeline-service.hostname}:8188","yarn.app.mapreduce.am.job.committer.commit-window":"10000","yarn.nodemanager.container-manager.thread-count":"20","yarn.minicluster.fixed.ports":"false","hadoop.tags.system":"YARN,HDFS,NAMENODE,DATANODE,REQUIRED,SECURITY,KERBEROS,PERFORMANCE,CLIENT\n      ,SERVER,DEBUG,DEPRECATED,COMMON,OPTIONAL","yarn.cluster.max-application-priority":"0","yarn.timeline-service.ttl-enable":"true","mapreduce.jobhistory.recovery.store.fs.uri":"${hadoop.tmp.dir}/mapred/history/recoverystore","hadoop.caller.context.signature.max.size":"40","yarn.client.load.resource-types.from-server":"false","ha.zookeeper.session-timeout.ms":"10000","tfile.io.chunk.size":"1048576","fs.s3a.s3guard.ddb.table.capacity.write":"100","mapreduce.job.speculative.slowtaskthreshold":"1.0","io.serializations":"org.apache.hadoop.io.serializer.WritableSerialization, org.apache.hadoop.io.serializer.avro.AvroSpecificSerialization, org.apache.hadoop.io.serializer.avro.AvroReflectSerialization","hadoop.security.kms.client.failover.sleep.max.millis":"2000","hadoop.security.group.mapping.ldap.directory.search.timeout":"10000","yarn.scheduler.configuration.store.max-logs":"1000","yarn.nodemanager.node-attributes.provider.fetch-interval-ms":"600000","fs.swift.impl":"org.apache.hadoop.fs.swift.snative.SwiftNativeFileSystem","yarn.nodemanager.local-cache.max-files-per-directory":"8192","hadoop.http.cross-origin.enabled":"false","hadoop.zk.acl":"world:anyone:rwcda","mapreduce.map.sort.spill.percent":"0.80","yarn.timeline-service.entity-group-fs-store.scan-interval-seconds":"60","yarn.node-attribute.fs-store.impl.class":"org.apache.hadoop.yarn.server.resourcemanager.nodelabels.FileSystemNodeAttributeStore","fs.s3a.retry.interval":"500ms","yarn.timeline-service.client.best-effort":"false","yarn.resourcemanager.webapp.delegation-token-auth-filter.enabled":"*********(redacted)","hadoop.security.group.mapping.ldap.posix.attr.uid.name":"uidNumber","fs.AbstractFileSystem.swebhdfs.impl":"org.apache.hadoop.fs.SWebHdfs","yarn.nodemanager.elastic-memory-control.timeout-sec":"5","mapreduce.ifile.readahead":"true","yarn.timeline-service.leveldb-timeline-store.ttl-interval-ms":"300000","yarn.timeline-service.reader.webapp.address":"${yarn.timeline-service.webapp.address}","yarn.resourcemanager.placement-constraints.algorithm.pool-size":"1","yarn.timeline-service.hbase.coprocessor.jar.hdfs.location":"/hbase/coprocessor/hadoop-yarn-server-timelineservice.jar","hadoop.security.kms.client.encrypted.key.cache.num.refill.threads":"2","yarn.resourcemanager.scheduler.class":"org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler","yarn.app.mapreduce.am.command-opts":"-Xmx1024m","mapreduce.cluster.local.dir":"${hadoop.tmp.dir}/mapred/local","io.mapfile.bloom.error.rate":"0.005","fs.client.resolve.topology.enabled":"false","yarn.nodemanager.runtime.linux.allowed-runtimes":"default","yarn.sharedcache.store.class":"org.apache.hadoop.yarn.server.sharedcachemanager.store.InMemorySCMStore","ha.failover-controller.graceful-fence.rpc-timeout.ms":"5000","ftp.replication":"3","hadoop.security.uid.cache.secs":"14400","mapreduce.job.maxtaskfailures.per.tracker":"3","fs.s3a.metadatastore.impl":"org.apache.hadoop.fs.s3a.s3guard.NullMetadataStore","io.skip.checksum.errors":"false","yarn.app.mapreduce.client-am.ipc.max-retries-on-timeouts":"3","yarn.timeline-service.webapp.xfs-filter.xframe-options":"SAMEORIGIN","fs.s3a.connection.timeout":"200000","mapreduce.job.max.split.locations":"15","yarn.resourcemanager.nm-container-queuing.max-queue-length":"15","hadoop.registry.zk.session.timeout.ms":"60000","yarn.federation.cache-ttl.secs":"300","mapreduce.jvm.system-properties-to-log":"os.name,os.version,java.home,java.runtime.version,java.vendor,java.version,java.vm.name,java.class.path,java.io.tmpdir,user.dir,user.name","yarn.resourcemanager.opportunistic-container-allocation.nodes-used":"10","yarn.timeline-service.entity-group-fs-store.active-dir":"/tmp/entity-file-history/active","mapreduce.shuffle.transfer.buffer.size":"131072","yarn.timeline-service.client.retry-interval-ms":"1000","yarn.http.policy":"HTTP_ONLY","fs.s3a.socket.send.buffer":"8192","fs.AbstractFileSystem.abfss.impl":"org.apache.hadoop.fs.azurebfs.Abfss","yarn.sharedcache.uploader.server.address":"0.0.0.0:8046","yarn.resourcemanager.delegation-token.max-conf-size-bytes":"*********(redacted)","hadoop.http.authentication.token.validity":"*********(redacted)","mapreduce.shuffle.max.connections":"0","yarn.minicluster.yarn.nodemanager.resource.memory-mb":"4096","mapreduce.job.emit-timeline-data":"false","yarn.nodemanager.resource.system-reserved-memory-mb":"-1","hadoop.kerberos.min.seconds.before.relogin":"60","mapreduce.jobhistory.move.thread-count":"3","yarn.resourcemanager.admin.client.thread-count":"1","yarn.dispatcher.drain-events.timeout":"300000","fs.s3a.buffer.dir":"${hadoop.tmp.dir}/s3a","hadoop.ssl.enabled.protocols":"TLSv1,SSLv2Hello,TLSv1.1,TLSv1.2","mapreduce.jobhistory.admin.address":"0.0.0.0:10033","yarn.log-aggregation-status.time-out.ms":"600000","fs.s3a.assumed.role.sts.endpoint.region":"us-west-1","mapreduce.shuffle.port":"13562","yarn.resourcemanager.max-log-aggregation-diagnostics-in-memory":"10","yarn.nodemanager.health-checker.interval-ms":"600000","yarn.router.clientrm.interceptor-class.pipeline":"org.apache.hadoop.yarn.server.router.clientrm.DefaultClientRequestInterceptor","yarn.resourcemanager.zk-appid-node.split-index":"0","ftp.blocksize":"67108864","yarn.nodemanager.runtime.linux.sandbox-mode.local-dirs.permissions":"read","yarn.router.rmadmin.interceptor-class.pipeline":"org.apache.hadoop.yarn.server.router.rmadmin.DefaultRMAdminRequestInterceptor","yarn.nodemanager.log-container-debug-info.enabled":"true","yarn.client.max-cached-nodemanagers-proxies":"0","yarn.nodemanager.linux-container-executor.cgroups.delete-delay-ms":"20","yarn.nodemanager.delete.debug-delay-sec":"0","yarn.nodemanager.pmem-check-enabled":"true","yarn.nodemanager.disk-health-checker.max-disk-utilization-per-disk-percentage":"90.0","mapreduce.app-submission.cross-platform":"false","yarn.resourcemanager.work-preserving-recovery.scheduling-wait-ms":"10000","yarn.nodemanager.container-retry-minimum-interval-ms":"1000","hadoop.security.groups.cache.secs":"300","yarn.federation.enabled":"false","fs.azure.local.sas.key.mode":"false","ipc.maximum.data.length":"67108864","mapreduce.shuffle.max.threads":"0","yarn.router.pipeline.cache-max-size":"25","yarn.resourcemanager.nm-container-queuing.load-comparator":"QUEUE_LENGTH","hadoop.security.authorization":"false","mapreduce.job.complete.cancel.delegation.tokens":"*********(redacted)","fs.s3a.paging.maximum":"5000","nfs.exports.allowed.hosts":"* rw","yarn.nodemanager.amrmproxy.ha.enable":"false","mapreduce.jobhistory.http.policy":"HTTP_ONLY","yarn.sharedcache.store.in-memory.check-period-mins":"720","hadoop.security.group.mapping.ldap.ssl":"false","yarn.client.application-client-protocol.poll-interval-ms":"200","yarn.scheduler.configuration.leveldb-store.compaction-interval-secs":"86400","yarn.timeline-service.writer.class":"org.apache.hadoop.yarn.server.timelineservice.storage.HBaseTimelineWriterImpl","ha.zookeeper.parent-znode":"/hadoop-ha","yarn.nodemanager.log-aggregation.policy.class":"org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.AllContainerLogAggregationPolicy","mapreduce.reduce.shuffle.merge.percent":"0.66","hadoop.security.group.mapping.ldap.search.filter.group":"(objectClass=group)","dfs.blocksize":"64M","yarn.resourcemanager.placement-constraints.scheduler.pool-size":"1","yarn.nodemanager.resourcemanager.minimum.version":"NONE","mapreduce.job.speculative.speculative-cap-running-tasks":"0.1","yarn.admin.acl":"*","yarn.nodemanager.recovery.supervised":"false","yarn.sharedcache.admin.thread-count":"1","yarn.resourcemanager.ha.automatic-failover.enabled":"true","mapreduce.reduce.skip.maxgroups":"0","mapreduce.reduce.shuffle.connect.timeout":"180000","yarn.resourcemanager.address":"localhost:8032","ipc.client.ping":"true","mapreduce.task.local-fs.write-limit.bytes":"-1","fs.adl.oauth2.access.token.provider.type":"*********(redacted)","mapreduce.shuffle.ssl.file.buffer.size":"65536","yarn.resourcemanager.ha.automatic-failover.embedded":"true","yarn.nodemanager.resource-plugins.gpu.docker-plugin":"nvidia-docker-v1","hadoop.ssl.enabled":"false","fs.s3a.multipart.purge":"false","yarn.scheduler.configuration.store.class":"file","yarn.resourcemanager.nm-container-queuing.queue-limit-stdev":"1.0f","mapreduce.job.end-notification.max.attempts":"5","mapreduce.output.fileoutputformat.compress.codec":"org.apache.hadoop.io.compress.DefaultCodec","yarn.nodemanager.container-monitor.procfs-tree.smaps-based-rss.enabled":"false","ipc.client.bind.wildcard.addr":"false","yarn.resourcemanager.webapp.rest-csrf.enabled":"false","ha.health-monitor.connect-retry-interval.ms":"1000","yarn.nodemanager.keytab":"/etc/krb5.keytab","mapreduce.jobhistory.keytab":"/etc/security/keytab/jhs.service.keytab","fs.s3a.threads.max":"10","mapreduce.reduce.shuffle.input.buffer.percent":"0.70","yarn.nodemanager.runtime.linux.docker.allowed-container-networks":"host,none,bridge","yarn.nodemanager.node-labels.resync-interval-ms":"120000","hadoop.tmp.dir":"/tmp/hadoop-${user.name}","mapreduce.job.maps":"2","mapreduce.jobhistory.webapp.rest-csrf.custom-header":"X-XSRF-Header","mapreduce.job.end-notification.max.retry.interval":"5000","yarn.log-aggregation.retain-check-interval-seconds":"-1","yarn.resourcemanager.resource-tracker.client.thread-count":"50","yarn.rm.system-metrics-publisher.emit-container-events":"false","yarn.timeline-service.leveldb-timeline-store.start-time-read-cache-size":"10000","yarn.resourcemanager.ha.automatic-failover.zk-base-path":"/yarn-leader-election","io.seqfile.local.dir":"${hadoop.tmp.dir}/io/local","fs.s3a.s3guard.ddb.throttle.retry.interval":"100ms","fs.AbstractFileSystem.wasb.impl":"org.apache.hadoop.fs.azure.Wasb","mapreduce.client.submit.file.replication":"10","mapreduce.jobhistory.minicluster.fixed.ports":"false","fs.s3a.multipart.threshold":"2147483647","yarn.resourcemanager.webapp.xfs-filter.xframe-options":"SAMEORIGIN","mapreduce.jobhistory.done-dir":"${yarn.app.mapreduce.am.staging-dir}/history/done","ipc.client.idlethreshold":"4000","yarn.nodemanager.linux-container-executor.cgroups.strict-resource-usage":"false","mapreduce.reduce.input.buffer.percent":"0.0","yarn.nodemanager.runtime.linux.docker.userremapping-gid-threshold":"1","yarn.nodemanager.webapp.rest-csrf.enabled":"false","fs.ftp.host.port":"21","ipc.ping.interval":"60000","yarn.resourcemanager.history-writer.multi-threaded-dispatcher.pool-size":"10","yarn.resourcemanager.admin.address":"${yarn.resourcemanager.hostname}:8033","file.client-write-packet-size":"65536","ipc.client.kill.max":"10","mapreduce.reduce.speculative":"true","hadoop.security.key.default.bitlength":"128","mapreduce.job.reducer.unconditional-preempt.delay.sec":"300","yarn.nodemanager.disk-health-checker.interval-ms":"120000","yarn.nodemanager.log.deletion-threads-count":"4","yarn.webapp.filter-entity-list-by-user":"false","ipc.client.connection.maxidletime":"10000","mapreduce.task.io.sort.mb":"100","yarn.nodemanager.localizer.client.thread-count":"5","io.erasurecode.codec.rs.rawcoders":"rs_native,rs_java","io.erasurecode.codec.rs-legacy.rawcoders":"rs-legacy_java","yarn.sharedcache.admin.address":"0.0.0.0:8047","yarn.resourcemanager.placement-constraints.algorithm.iterator":"SERIAL","yarn.nodemanager.localizer.cache.cleanup.interval-ms":"600000","hadoop.security.crypto.codec.classes.aes.ctr.nopadding":"org.apache.hadoop.crypto.OpensslAesCtrCryptoCodec, org.apache.hadoop.crypto.JceAesCtrCryptoCodec","mapreduce.job.cache.limit.max-resources-mb":"0","fs.s3a.connection.ssl.enabled":"true","yarn.nodemanager.process-kill-wait.ms":"5000","mapreduce.job.hdfs-servers":"${fs.defaultFS}","hadoop.workaround.non.threadsafe.getpwuid":"true","fs.df.interval":"60000","fs.s3a.multiobjectdelete.enable":"true","yarn.sharedcache.cleaner.resource-sleep-ms":"0","yarn.nodemanager.disk-health-checker.min-healthy-disks":"0.25","hadoop.shell.missing.defaultFs.warning":"false","io.file.buffer.size":"65536","hadoop.security.group.mapping.ldap.search.attr.member":"member","hadoop.security.random.device.file.path":"/dev/urandom","hadoop.security.sensitive-config-keys":"*********(redacted)","fs.s3a.s3guard.ddb.max.retries":"9","hadoop.rpc.socket.factory.class.default":"org.apache.hadoop.net.StandardSocketFactory","yarn.intermediate-data-encryption.enable":"false","yarn.resourcemanager.connect.retry-interval.ms":"30000","yarn.nodemanager.container.stderr.pattern":"{*stderr*,*STDERR*}","yarn.scheduler.minimum-allocation-mb":"1024","yarn.app.mapreduce.am.staging-dir":"/tmp/hadoop-yarn/staging","mapreduce.reduce.shuffle.read.timeout":"180000","hadoop.http.cross-origin.max-age":"1800","io.erasurecode.codec.xor.rawcoders":"xor_native,xor_java","fs.s3a.connection.establish.timeout":"5000","mapreduce.job.running.map.limit":"0","yarn.minicluster.control-resource-monitoring":"false","hadoop.ssl.require.client.cert":"false","hadoop.kerberos.kinit.command":"kinit","yarn.federation.state-store.class":"org.apache.hadoop.yarn.server.federation.store.impl.MemoryFederationStateStore","mapreduce.reduce.log.level":"INFO","hadoop.security.dns.log-slow-lookups.threshold.ms":"1000","mapreduce.job.ubertask.enable":"false","adl.http.timeout":"-1","yarn.resourcemanager.placement-constraints.retry-attempts":"3","hadoop.caller.context.enabled":"false","yarn.nodemanager.vmem-pmem-ratio":"2.1","hadoop.rpc.protection":"authentication","ha.health-monitor.rpc-timeout.ms":"45000","yarn.nodemanager.remote-app-log-dir":"/tmp/logs","hadoop.zk.timeout-ms":"10000","fs.s3a.s3guard.cli.prune.age":"86400000","yarn.nodemanager.resource.pcores-vcores-multiplier":"1.0","yarn.nodemanager.runtime.linux.sandbox-mode":"disabled","yarn.app.mapreduce.am.containerlauncher.threadpool-initial-size":"10","fs.s3a.committer.threads":"8","hadoop.zk.retry-interval-ms":"1000","hadoop.security.crypto.buffer.size":"8192","yarn.nodemanager.node-labels.provider.fetch-interval-ms":"600000","mapreduce.jobhistory.recovery.store.leveldb.path":"${hadoop.tmp.dir}/mapred/history/recoverystore","yarn.client.failover-retries-on-socket-timeouts":"0","yarn.nodemanager.resource.memory.enabled":"false","fs.azure.authorization.caching.enable":"true","hadoop.security.instrumentation.requires.admin":"false","yarn.nodemanager.delete.thread-count":"4","mapreduce.job.finish-when-all-reducers-done":"true","hadoop.registry.jaas.context":"Client","yarn.timeline-service.leveldb-timeline-store.path":"${hadoop.tmp.dir}/yarn/timeline","io.map.index.interval":"128","yarn.resourcemanager.nm-container-queuing.max-queue-wait-time-ms":"100","fs.abfs.impl":"org.apache.hadoop.fs.azurebfs.AzureBlobFileSystem","mapreduce.job.counters.max":"120","mapreduce.jobhistory.webapp.rest-csrf.enabled":"false","yarn.timeline-service.store-class":"org.apache.hadoop.yarn.server.timeline.LeveldbTimelineStore","mapreduce.jobhistory.move.interval-ms":"180000","yarn.nodemanager.localizer.fetch.thread-count":"4","yarn.resourcemanager.scheduler.client.thread-count":"50","hadoop.ssl.hostname.verifier":"DEFAULT","yarn.timeline-service.leveldb-state-store.path":"${hadoop.tmp.dir}/yarn/timeline","mapreduce.job.classloader":"false","mapreduce.task.profile.map.params":"${mapreduce.task.profile.params}","ipc.client.connect.timeout":"20000","hadoop.security.auth_to_local.mechanism":"hadoop","yarn.timeline-service.app-collector.linger-period.ms":"60000","yarn.nm.liveness-monitor.expiry-interval-ms":"600000","yarn.resourcemanager.reservation-system.planfollower.time-step":"1000","yarn.nodemanager.runtime.linux.docker.enable-userremapping.allowed":"true","yarn.webapp.api-service.enable":"false","yarn.nodemanager.recovery.enabled":"false","mapreduce.job.end-notification.retry.interval":"1000","fs.du.interval":"600000","fs.ftp.impl":"org.apache.hadoop.fs.ftp.FTPFileSystem","yarn.nodemanager.container.stderr.tail.bytes":"4096","hadoop.security.group.mapping.ldap.read.timeout.ms":"60000","hadoop.security.groups.cache.warn.after.ms":"5000","file.bytes-per-checksum":"512","mapreduce.outputcommitter.factory.scheme.s3a":"org.apache.hadoop.fs.s3a.commit.S3ACommitterFactory","hadoop.security.groups.cache.background.reload":"false","yarn.nodemanager.container-monitor.enabled":"true","yarn.nodemanager.elastic-memory-control.enabled":"false","net.topology.script.number.args":"100","mapreduce.task.merge.progress.records":"10000","yarn.nodemanager.localizer.address":"${yarn.nodemanager.hostname}:8040","yarn.timeline-service.keytab":"/etc/krb5.keytab","mapreduce.reduce.shuffle.fetch.retry.timeout-ms":"30000","yarn.resourcemanager.rm.container-allocation.expiry-interval-ms":"600000","mapreduce.fileoutputcommitter.algorithm.version":"1","yarn.resourcemanager.work-preserving-recovery.enabled":"true","mapreduce.map.skip.maxrecords":"0","yarn.sharedcache.root-dir":"/sharedcache","fs.s3a.retry.throttle.limit":"${fs.s3a.attempts.maximum}","hadoop.http.authentication.type":"simple","mapreduce.job.cache.limit.max-resources":"0","mapreduce.task.userlog.limit.kb":"0","yarn.resourcemanager.scheduler.monitor.enable":"false","ipc.client.connect.max.retries":"10","hadoop.registry.zk.retry.times":"5","yarn.nodemanager.resource-monitor.interval-ms":"3000","yarn.nodemanager.resource-plugins.gpu.allowed-gpu-devices":"auto","mapreduce.job.sharedcache.mode":"disabled","yarn.nodemanager.webapp.rest-csrf.custom-header":"X-XSRF-Header","mapreduce.shuffle.listen.queue.size":"128","yarn.scheduler.configuration.mutation.acl-policy.class":"org.apache.hadoop.yarn.server.resourcemanager.scheduler.DefaultConfigurationMutationACLPolicy","mapreduce.map.cpu.vcores":"1","yarn.log-aggregation.file-formats":"TFile","yarn.timeline-service.client.fd-retain-secs":"300","hadoop.user.group.static.mapping.overrides":"dr.who=;","fs.azure.sas.expiry.period":"90d","mapreduce.jobhistory.recovery.store.class":"org.apache.hadoop.mapreduce.v2.hs.HistoryServerFileSystemStateStoreService","yarn.resourcemanager.fail-fast":"${yarn.fail-fast}","yarn.resourcemanager.proxy-user-privileges.enabled":"false","yarn.router.webapp.interceptor-class.pipeline":"org.apache.hadoop.yarn.server.router.webapp.DefaultRequestInterceptorREST","yarn.nodemanager.resource.memory.cgroups.soft-limit-percentage":"90.0","mapreduce.job.reducer.preempt.delay.sec":"0","hadoop.util.hash.type":"murmur","yarn.nodemanager.disk-validator":"basic","yarn.app.mapreduce.client.job.max-retries":"3","mapreduce.reduce.shuffle.retry-delay.max.ms":"60000","hadoop.security.group.mapping.ldap.connection.timeout.ms":"60000","mapreduce.task.profile.params":"-agentlib:hprof=cpu=samples,heap=sites,force=n,thread=y,verbose=n,file=%s","yarn.app.mapreduce.shuffle.log.backups":"0","yarn.nodemanager.container-diagnostics-maximum-size":"10000","hadoop.registry.zk.retry.interval.ms":"1000","yarn.nodemanager.linux-container-executor.cgroups.delete-timeout-ms":"1000","fs.AbstractFileSystem.file.impl":"org.apache.hadoop.fs.local.LocalFs","yarn.nodemanager.log-aggregation.roll-monitoring-interval-seconds":"-1","mapreduce.jobhistory.cleaner.interval-ms":"86400000","hadoop.registry.zk.quorum":"localhost:2181","mapreduce.output.fileoutputformat.compress":"false","yarn.resourcemanager.am-rm-tokens.master-key-rolling-interval-secs":"*********(redacted)","fs.s3a.assumed.role.session.duration":"30m","hadoop.security.group.mapping.ldap.conversion.rule":"none","hadoop.ssl.server.conf":"ssl-server.xml","fs.s3a.retry.throttle.interval":"1000ms","seq.io.sort.factor":"100","yarn.sharedcache.cleaner.initial-delay-mins":"10","mapreduce.client.completion.pollinterval":"5000","hadoop.ssl.keystores.factory.class":"org.apache.hadoop.security.ssl.FileBasedKeyStoresFactory","yarn.app.mapreduce.am.resource.cpu-vcores":"1","yarn.timeline-service.enabled":"false","yarn.nodemanager.runtime.linux.docker.capabilities":"CHOWN,DAC_OVERRIDE,FSETID,FOWNER,MKNOD,NET_RAW,SETGID,SETUID,SETFCAP,SETPCAP,NET_BIND_SERVICE,SYS_CHROOT,KILL,AUDIT_WRITE","yarn.acl.enable":"false","yarn.timeline-service.entity-group-fs-store.done-dir":"/tmp/entity-file-history/done/","mapreduce.task.profile":"false","yarn.resourcemanager.fs.state-store.uri":"${hadoop.tmp.dir}/yarn/system/rmstore","mapreduce.jobhistory.always-scan-user-dir":"false","yarn.nodemanager.opportunistic-containers-use-pause-for-preemption":"false","yarn.nodemanager.linux-container-executor.nonsecure-mode.local-user":"nobody","yarn.timeline-service.reader.class":"org.apache.hadoop.yarn.server.timelineservice.storage.HBaseTimelineReaderImpl","yarn.resourcemanager.configuration.provider-class":"org.apache.hadoop.yarn.LocalConfigurationProvider","yarn.nodemanager.runtime.linux.docker.userremapping-uid-threshold":"1","yarn.resourcemanager.configuration.file-system-based-store":"/yarn/conf","mapreduce.job.cache.limit.max-single-resource-mb":"0","yarn.nodemanager.runtime.linux.docker.stop.grace-period":"10","yarn.resourcemanager.resource-profiles.source-file":"resource-profiles.json","yarn.nodemanager.resource.percentage-physical-cpu-limit":"100","mapreduce.jobhistory.client.thread-count":"10","tfile.fs.input.buffer.size":"262144","mapreduce.client.progressmonitor.pollinterval":"1000","yarn.nodemanager.log-dirs":"${yarn.log.dir}/userlogs","fs.automatic.close":"true","yarn.nodemanager.hostname":"0.0.0.0","yarn.nodemanager.resource.memory.cgroups.swappiness":"0","ftp.stream-buffer-size":"4096","yarn.fail-fast":"false","yarn.timeline-service.app-aggregation-interval-secs":"15","hadoop.security.group.mapping.ldap.search.filter.user":"(&(objectClass=user)(sAMAccountName={0}))","yarn.nodemanager.container-localizer.log.level":"INFO","yarn.timeline-service.address":"${yarn.timeline-service.hostname}:10200","mapreduce.job.ubertask.maxmaps":"9","fs.s3a.threads.keepalivetime":"60","mapreduce.jobhistory.webapp.rest-csrf.methods-to-ignore":"GET,OPTIONS,HEAD","mapreduce.task.files.preserve.failedtasks":"false","yarn.app.mapreduce.client.job.retry-interval":"2000","ha.failover-controller.graceful-fence.connection.retries":"1","yarn.resourcemanager.delegation.token.max-lifetime":"*********(redacted)","yarn.timeline-service.client.drain-entities.timeout.ms":"2000","yarn.nodemanager.resource-plugins.fpga.vendor-plugin.class":"org.apache.hadoop.yarn.server.nodemanager.containermanager.resourceplugin.fpga.IntelFpgaOpenclPlugin","yarn.timeline-service.entity-group-fs-store.summary-store":"org.apache.hadoop.yarn.server.timeline.LeveldbTimelineStore","mapreduce.reduce.cpu.vcores":"1","mapreduce.job.encrypted-intermediate-data.buffer.kb":"128","fs.client.resolve.remote.symlinks":"true","yarn.nodemanager.webapp.https.address":"0.0.0.0:8044","hadoop.http.cross-origin.allowed-origins":"*","mapreduce.job.encrypted-intermediate-data":"false","yarn.timeline-service.entity-group-fs-store.retain-seconds":"604800","yarn.resourcemanager.metrics.runtime.buckets":"60,300,1440","yarn.timeline-service.generic-application-history.max-applications":"10000","yarn.nodemanager.local-dirs":"${hadoop.tmp.dir}/nm-local-dir","mapreduce.shuffle.connection-keep-alive.enable":"false","yarn.node-labels.configuration-type":"centralized","fs.s3a.path.style.access":"false","yarn.nodemanager.aux-services.mapreduce_shuffle.class":"org.apache.hadoop.mapred.ShuffleHandler","yarn.sharedcache.store.in-memory.staleness-period-mins":"10080","fs.adl.impl":"org.apache.hadoop.fs.adl.AdlFileSystem","yarn.resourcemanager.nodemanager.minimum.version":"NONE","mapreduce.jobhistory.webapp.xfs-filter.xframe-options":"SAMEORIGIN","yarn.app.mapreduce.am.staging-dir.erasurecoding.enabled":"false","net.topology.impl":"org.apache.hadoop.net.NetworkTopology","io.map.index.skip":"0","yarn.timeline-service.reader.webapp.https.address":"${yarn.timeline-service.webapp.https.address}","fs.ftp.data.connection.mode":"ACTIVE_LOCAL_DATA_CONNECTION_MODE","mapreduce.job.local-fs.single-disk-limit.check.kill-limit-exceed":"true","yarn.scheduler.maximum-allocation-vcores":"4","hadoop.http.cross-origin.allowed-headers":"X-Requested-With,Content-Type,Accept,Origin","yarn.nodemanager.log-aggregation.compression-type":"none","yarn.timeline-service.version":"1.0f","yarn.ipc.rpc.class":"org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC","mapreduce.reduce.maxattempts":"4","hadoop.security.dns.log-slow-lookups.enabled":"false","mapreduce.job.committer.setup.cleanup.needed":"true","mapreduce.job.running.reduce.limit":"0","ipc.maximum.response.length":"134217728","yarn.resourcemanager.webapp.rest-csrf.methods-to-ignore":"GET,OPTIONS,HEAD","mapreduce.job.token.tracking.ids.enabled":"*********(redacted)","hadoop.caller.context.max.size":"128","yarn.nodemanager.runtime.linux.docker.host-pid-namespace.allowed":"false","yarn.nodemanager.runtime.linux.docker.delayed-removal.allowed":"false","hadoop.registry.system.acls":"sasl:yarn@, sasl:mapred@, sasl:hdfs@","yarn.nodemanager.recovery.dir":"${hadoop.tmp.dir}/yarn-nm-recovery","fs.s3a.fast.upload.buffer":"disk","mapreduce.jobhistory.intermediate-done-dir":"${yarn.app.mapreduce.am.staging-dir}/history/done_intermediate","yarn.app.mapreduce.shuffle.log.separate":"true","fs.s3a.max.total.tasks":"5","fs.s3a.readahead.range":"64K","hadoop.http.authentication.simple.anonymous.allowed":"true","fs.s3a.attempts.maximum":"20","hadoop.registry.zk.connection.timeout.ms":"15000","yarn.resourcemanager.delegation-token-renewer.thread-count":"*********(redacted)","yarn.nodemanager.health-checker.script.timeout-ms":"1200000","yarn.timeline-service.leveldb-timeline-store.start-time-write-cache-size":"10000","yarn.resourcemanager.resource-profiles.enabled":"false","yarn.timeline-service.hbase-schema.prefix":"prod.","fs.azure.authorization":"false","mapreduce.map.log.level":"INFO","yarn.resourcemanager.decommissioning-nodes-watcher.poll-interval-secs":"20","mapreduce.output.fileoutputformat.compress.type":"RECORD","yarn.resourcemanager.leveldb-state-store.path":"${hadoop.tmp.dir}/yarn/system/rmstore","yarn.timeline-service.webapp.rest-csrf.custom-header":"X-XSRF-Header","mapreduce.ifile.readahead.bytes":"4194304","yarn.sharedcache.app-checker.class":"org.apache.hadoop.yarn.server.sharedcachemanager.RemoteAppChecker","yarn.nodemanager.linux-container-executor.nonsecure-mode.limit-users":"true","yarn.nodemanager.resource.detect-hardware-capabilities":"false","mapreduce.cluster.acls.enabled":"false","mapreduce.job.speculative.retry-after-no-speculate":"1000","hadoop.security.group.mapping.ldap.search.group.hierarchy.levels":"0","yarn.resourcemanager.fs.state-store.retry-interval-ms":"1000","file.stream-buffer-size":"4096","yarn.resourcemanager.application-timeouts.monitor.interval-ms":"3000","mapreduce.map.output.compress.codec":"org.apache.hadoop.io.compress.DefaultCodec","mapreduce.map.speculative":"true","mapreduce.job.speculative.retry-after-speculate":"15000","yarn.nodemanager.linux-container-executor.cgroups.mount":"false","yarn.app.mapreduce.am.container.log.backups":"0","yarn.app.mapreduce.am.log.level":"INFO","mapreduce.job.reduce.slowstart.completedmaps":"0.05","yarn.timeline-service.http-authentication.type":"simple","hadoop.security.group.mapping.ldap.search.attr.group.name":"cn","yarn.nodemanager.resource-plugins.fpga.allowed-fpga-devices":"0,1","yarn.timeline-service.client.internal-timers-ttl-secs":"420","hadoop.http.logs.enabled":"true","fs.s3a.block.size":"32M","yarn.sharedcache.client-server.address":"0.0.0.0:8045","yarn.nodemanager.logaggregation.threadpool-size-max":"100","yarn.resourcemanager.hostname":"localhost","yarn.resourcemanager.delegation.key.update-interval":"86400000","mapreduce.reduce.shuffle.fetch.retry.enabled":"${yarn.nodemanager.recovery.enabled}","mapreduce.map.memory.mb":"-1","mapreduce.task.skip.start.attempts":"2","fs.AbstractFileSystem.hdfs.impl":"org.apache.hadoop.fs.Hdfs","yarn.nodemanager.disk-health-checker.enable":"true","ipc.client.tcpnodelay":"true","ipc.client.rpc-timeout.ms":"0","yarn.nodemanager.webapp.rest-csrf.methods-to-ignore":"GET,OPTIONS,HEAD","ipc.client.low-latency":"false","mapreduce.input.lineinputformat.linespermap":"1","yarn.router.interceptor.user.threadpool-size":"5","ipc.client.connect.max.retries.on.timeouts":"45","yarn.timeline-service.leveldb-timeline-store.read-cache-size":"104857600","fs.AbstractFileSystem.har.impl":"org.apache.hadoop.fs.HarFs","mapreduce.job.split.metainfo.maxsize":"10000000","yarn.am.liveness-monitor.expiry-interval-ms":"600000","yarn.resourcemanager.container-tokens.master-key-rolling-interval-secs":"*********(redacted)","yarn.timeline-service.entity-group-fs-store.app-cache-size":"10","fs.s3a.socket.recv.buffer":"8192","yarn.resourcemanager.resource-tracker.address":"localhost:8031","yarn.nodemanager.node-labels.provider.fetch-timeout-ms":"1200000","mapreduce.job.heap.memory-mb.ratio":"0.8","yarn.resourcemanager.leveldb-state-store.compaction-interval-secs":"3600","yarn.resourcemanager.webapp.rest-csrf.custom-header":"X-XSRF-Header","yarn.scheduler.configuration.fs.path":"file://${hadoop.tmp.dir}/yarn/system/schedconf","mapreduce.client.output.filter":"FAILED","hadoop.http.filter.initializers":"org.apache.hadoop.http.lib.StaticUserWebFilter","mapreduce.reduce.memory.mb":"-1","yarn.timeline-service.hostname":"0.0.0.0","file.replication":"1","yarn.nodemanager.container-metrics.unregister-delay-ms":"10000","yarn.nodemanager.container-metrics.period-ms":"-1","mapreduce.fileoutputcommitter.task.cleanup.enabled":"false","yarn.nodemanager.log.retain-seconds":"10800","yarn.timeline-service.entity-group-fs-store.cleaner-interval-seconds":"3600","yarn.resourcemanager.keytab":"/etc/krb5.keytab","hadoop.security.group.mapping.providers.combined":"true","mapreduce.reduce.merge.inmem.threshold":"1000","yarn.timeline-service.recovery.enabled":"false","fs.azure.saskey.usecontainersaskeyforallaccess":"true","yarn.sharedcache.nm.uploader.thread-count":"20","yarn.resourcemanager.nodemanager-graceful-decommission-timeout-secs":"3600","mapreduce.shuffle.ssl.enabled":"false","yarn.timeline-service.hbase.coprocessor.app-final-value-retention-milliseconds":"259200000","fs.s3a.committer.staging.abort.pending.uploads":"true","yarn.nodemanager.opportunistic-containers-max-queue-length":"0","yarn.resourcemanager.state-store.max-completed-applications":"${yarn.resourcemanager.max-completed-applications}","mapreduce.job.speculative.minimum-allowed-tasks":"10","yarn.log-aggregation.retain-seconds":"-1","yarn.nodemanager.disk-health-checker.min-free-space-per-disk-mb":"0","mapreduce.jobhistory.max-age-ms":"604800000","hadoop.http.cross-origin.allowed-methods":"GET,POST,HEAD","yarn.resourcemanager.opportunistic-container-allocation.enabled":"false","mapreduce.jobhistory.webapp.address":"0.0.0.0:19888","hadoop.system.tags":"YARN,HDFS,NAMENODE,DATANODE,REQUIRED,SECURITY,KERBEROS,PERFORMANCE,CLIENT\n      ,SERVER,DEBUG,DEPRECATED,COMMON,OPTIONAL","yarn.log-aggregation.file-controller.TFile.class":"org.apache.hadoop.yarn.logaggregation.filecontroller.tfile.LogAggregationTFileController","yarn.client.nodemanager-connect.max-wait-ms":"180000","yarn.resourcemanager.webapp.address":"${yarn.resourcemanager.hostname}:8088","mapreduce.jobhistory.recovery.enable":"false","mapreduce.reduce.shuffle.parallelcopies":"5","fs.AbstractFileSystem.webhdfs.impl":"org.apache.hadoop.fs.WebHdfs","fs.trash.interval":"0","yarn.app.mapreduce.client.max-retries":"3","hadoop.security.authentication":"simple","mapreduce.task.profile.reduce.params":"${mapreduce.task.profile.params}","yarn.app.mapreduce.am.resource.mb":"1536","mapreduce.input.fileinputformat.list-status.num-threads":"1","yarn.nodemanager.container-executor.class":"org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor","io.mapfile.bloom.size":"1048576","yarn.timeline-service.ttl-ms":"604800000","yarn.resourcemanager.nm-container-queuing.min-queue-length":"5","yarn.nodemanager.resource.cpu-vcores":"-1","mapreduce.job.reduces":"1","fs.s3a.multipart.size":"100M","yarn.scheduler.minimum-allocation-vcores":"1","mapreduce.job.speculative.speculative-cap-total-tasks":"0.01","hadoop.ssl.client.conf":"ssl-client.xml","mapreduce.job.queuename":"default","mapreduce.job.encrypted-intermediate-data-key-size-bits":"128","fs.s3a.metadatastore.authoritative":"false","yarn.nodemanager.webapp.xfs-filter.xframe-options":"SAMEORIGIN","ha.health-monitor.sleep-after-disconnect.ms":"1000","yarn.app.mapreduce.shuffle.log.limit.kb":"0","hadoop.security.group.mapping":"org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback","yarn.client.application-client-protocol.poll-timeout-ms":"-1","mapreduce.jobhistory.jhist.format":"binary","yarn.resourcemanager.ha.enabled":"false","hadoop.http.staticuser.user":"dr.who","mapreduce.task.exit.timeout.check-interval-ms":"20000","mapreduce.jobhistory.intermediate-user-done-dir.permissions":"770","mapreduce.task.exit.timeout":"60000","yarn.nodemanager.linux-container-executor.resources-handler.class":"org.apache.hadoop.yarn.server.nodemanager.util.DefaultLCEResourcesHandler","mapreduce.reduce.shuffle.memory.limit.percent":"0.25","yarn.resourcemanager.reservation-system.enable":"false","mapreduce.map.output.compress":"false","ha.zookeeper.acl":"world:anyone:rwcda","ipc.server.max.connections":"0","yarn.nodemanager.aux-services":"mapreduce_shuffle","yarn.nodemanager.runtime.linux.docker.default-container-network":"host","yarn.router.webapp.address":"0.0.0.0:8089","yarn.scheduler.maximum-allocation-mb":"8192","yarn.resourcemanager.scheduler.monitor.policies":"org.apache.hadoop.yarn.server.resourcemanager.monitor.capacity.ProportionalCapacityPreemptionPolicy","yarn.sharedcache.cleaner.period-mins":"1440","yarn.nodemanager.resource-plugins.gpu.docker-plugin.nvidia-docker-v1.endpoint":"http://localhost:3476/v1.0/docker/cli","yarn.app.mapreduce.am.container.log.limit.kb":"0","ipc.client.connect.retry.interval":"1000","yarn.timeline-service.http-cross-origin.enabled":"false","fs.wasbs.impl":"org.apache.hadoop.fs.azure.NativeAzureFileSystem$Secure","yarn.federation.subcluster-resolver.class":"org.apache.hadoop.yarn.server.federation.resolver.DefaultSubClusterResolverImpl","yarn.resourcemanager.zk-state-store.parent-path":"/rmstore","mapreduce.jobhistory.cleaner.enable":"true","yarn.timeline-service.client.fd-flush-interval-secs":"10","hadoop.security.kms.client.encrypted.key.cache.expiry":"43200000","yarn.client.nodemanager-client-async.thread-pool-max-size":"500","mapreduce.map.maxattempts":"4","yarn.resourcemanager.nm-container-queuing.sorting-nodes-interval-ms":"1000","fs.s3a.committer.staging.tmp.path":"tmp/staging","yarn.nodemanager.sleep-delay-before-sigkill.ms":"250","yarn.resourcemanager.nm-container-queuing.min-queue-wait-time-ms":"10","mapreduce.job.end-notification.retry.attempts":"0","yarn.nodemanager.resource.count-logical-processors-as-cores":"false","hadoop.registry.zk.root":"/registry","adl.feature.ownerandgroup.enableupn":"false","yarn.resourcemanager.zk-max-znode-size.bytes":"1048576","mapreduce.job.reduce.shuffle.consumer.plugin.class":"org.apache.hadoop.mapreduce.task.reduce.Shuffle","yarn.resourcemanager.delayed.delegation-token.removal-interval-ms":"*********(redacted)","yarn.nodemanager.localizer.cache.target-size-mb":"10240","fs.s3a.committer.staging.conflict-mode":"fail","mapreduce.client.libjars.wildcard":"true","fs.s3a.committer.staging.unique-filenames":"true","yarn.nodemanager.node-attributes.provider.fetch-timeout-ms":"1200000","fs.s3a.list.version":"2","ftp.client-write-packet-size":"65536","fs.AbstractFileSystem.adl.impl":"org.apache.hadoop.fs.adl.Adl","hadoop.security.key.default.cipher":"AES/CTR/NoPadding","yarn.client.failover-retries":"0","fs.s3a.multipart.purge.age":"86400","mapreduce.job.local-fs.single-disk-limit.check.interval-ms":"5000","net.topology.node.switch.mapping.impl":"org.apache.hadoop.net.ScriptBasedMapping","yarn.nodemanager.amrmproxy.address":"0.0.0.0:8049","ipc.server.listen.queue.size":"128","map.sort.class":"org.apache.hadoop.util.QuickSort","fs.viewfs.rename.strategy":"SAME_MOUNTPOINT","hadoop.security.kms.client.authentication.retry-count":"1","fs.permissions.umask-mode":"022","fs.s3a.assumed.role.credentials.provider":"org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider","yarn.nodemanager.vmem-check-enabled":"true","yarn.nodemanager.numa-awareness.enabled":"false","yarn.nodemanager.recovery.compaction-interval-secs":"3600","yarn.app.mapreduce.client-am.ipc.max-retries":"3","yarn.federation.registry.base-dir":"yarnfederation/","mapreduce.job.max.map":"-1","mapreduce.job.local-fs.single-disk-limit.bytes":"-1","mapreduce.job.ubertask.maxreduces":"1","hadoop.security.kms.client.encrypted.key.cache.size":"500","hadoop.security.java.secure.random.algorithm":"SHA1PRNG","ha.failover-controller.cli-check.rpc-timeout.ms":"20000","mapreduce.jobhistory.jobname.limit":"50","mapreduce.application.classpath":"$HADOOP_MAPRED_HOME/share/hadoop/mapreduce/*:$HADOOP_MAPRED_HOME/share/hadoop/mapreduce/lib/*","yarn.client.nodemanager-connect.retry-interval-ms":"10000","yarn.timeline-service.state-store-class":"org.apache.hadoop.yarn.server.timeline.recovery.LeveldbTimelineStateStore","yarn.nodemanager.env-whitelist":"JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_MAPRED_HOME","yarn.sharedcache.nested-level":"3","yarn.timeline-service.webapp.rest-csrf.methods-to-ignore":"GET,OPTIONS,HEAD","fs.azure.user.agent.prefix":"unknown","yarn.resourcemanager.zk-delegation-token-node.split-index":"*********(redacted)","yarn.nodemanager.numa-awareness.read-topology":"false","yarn.nodemanager.webapp.address":"${yarn.nodemanager.hostname}:8042","rpc.metrics.quantile.enable":"false","yarn.registry.class":"org.apache.hadoop.registry.client.impl.FSRegistryOperationsService","mapreduce.jobhistory.admin.acl":"*","yarn.resourcemanager.system-metrics-publisher.dispatcher.pool-size":"10","yarn.scheduler.queue-placement-rules":"user-group","hadoop.http.authentication.kerberos.keytab":"${user.home}/hadoop.keytab","yarn.resourcemanager.recovery.enabled":"false","yarn.timeline-service.webapp.rest-csrf.enabled":"false"},"System Properties":{"java.io.tmpdir":"/tmp","line.separator":"\n","path.separator":":","sun.management.compiler":"HotSpot Tiered Compilers","SPARK_SUBMIT":"true","sun.cpu.endian":"little","java.specification.version":"1.8","java.vm.specification.name":"Java Virtual Machine Specification","java.vendor":"Oracle Corporation","java.vm.specification.version":"1.8","user.home":"/home/user","file.encoding.pkg":"sun.io","sun.nio.ch.bugLevel":"","sun.arch.data.model":"32","sun.boot.library.path":"/home/user/jdk1.8.0/jre/lib/i386","user.dir":"/home/user","java.library.path":"/usr/java/packages/lib/i386:/lib:/usr/lib","sun.cpu.isalist":"","sun.desktop":"gnome","os.arch":"i386","java.vm.version":"25.291-b10","jetty.git.hash":"b881a572662e1943a14ae12e7e1207989f218b74","java.endorsed.dirs":"/home/user/jdk1.8.0/jre/lib/endorsed","java.runtime.version":"1.8.0_291-b10","java.vm.info":"mixed mode","java.ext.dirs":"/home/user/jdk1.8.0/jre/lib/ext:/usr/java/packages/lib/ext","java.runtime.name":"Java(TM) SE Runtime Environment","file.separator":"/","java.class.version":"52.0","java.specification.name":"Java Platform API Specification","sun.boot.class.path":"/home/user/jdk1.8.0/jre/lib/resources.jar:/home/user/jdk1.8.0/jre/lib/rt.jar:/home/user/jdk1.8.0/jre/lib/sunrsasign.jar:/home/user/jdk1.8.0/jre/lib/jsse.jar:/home/user/jdk1.8.0/jre/lib/jce.jar:/home/user/jdk1.8.0/jre/lib/charsets.jar:/home/user/jdk1.8.0/jre/lib/jfr.jar:/home/user/jdk1.8.0/jre/classes","file.encoding":"UTF-8","user.timezone":"Europe/Berlin","java.specification.vendor":"Oracle Corporation","sun.java.launcher":"SUN_STANDARD","os.version":"5.11.0-38-generic","sun.os.patch.level":"unknown","java.vm.specification.vendor":"Oracle Corporation","user.country":"US","sun.jnu.encoding":"UTF-8","user.language":"en","java.vendor.url":"http://java.oracle.com/","java.awt.printerjob":"sun.print.PSPrinterJob","java.awt.graphicsenv":"sun.awt.X11GraphicsEnvironment","awt.toolkit":"sun.awt.X11.XToolkit","os.name":"Linux","java.vm.vendor":"Oracle Corporation","java.vendor.url.bug":"http://bugreport.sun.com/bugreport/","user.name":"user","java.vm.name":"Java HotSpot(TM) Server VM","sun.java.command":"org.apache.spark.deploy.SparkSubmit --master yarn --conf spark.eventLog.enabled=true --conf spark.eventLog.dir=file:/home/user/spark-events --properties-file /home/user/HiBench-master/report/sort/spark/conf/sparkbench/spark.conf --class com.intel.hibench.sparkbench.micro.ScalaSort --num-executors 1 --executor-cores 2 --executor-memory 1g /home/user/HiBench-master/sparkbench/assembly/target/sparkbench-assembly-8.0-SNAPSHOT-dist.jar hdfs://localhost:9000/HiBench/Sort/Input hdfs://localhost:9000/HiBench/Sort/Output","java.home":"/home/user/jdk1.8.0/jre","java.version":"1.8.0_291","sun.io.unicode.encoding":"UnicodeLittle"},"Classpath Entries":{"/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/zookeeper-3.4.14.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/stax2-api-3.1.4.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/chill-java-0.9.5.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/hive-jdbc-2.3.7.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/commons-text-1.6.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/kubernetes-model-extensions-4.12.0.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/libfb303-0.9.3.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/hadoop-common-3.2.0.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/re2j-1.1.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/aopalliance-1.0.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/hive-common-2.3.7.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/kerb-crypto-1.0.1.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/jackson-core-2.10.0.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/hk2-utils-2.6.1.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/hive-beeline-2.3.7.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/jersey-common-2.30.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/transaction-api-1.1.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/orc-shims-1.5.12.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/geronimo-jcache_1.0_spec-1.0-alpha-1.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/javax.jdo-3.2.0-m3.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/jersey-container-servlet-2.30.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/hadoop-yarn-common-3.2.0.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/hive-cli-2.3.7.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/curator-framework-2.13.0.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/hadoop-yarn-server-common-3.2.0.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/dnsjava-2.1.7.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/leveldbjni-all-1.8.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/jackson-dataformat-yaml-2.10.0.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/scala-library-2.12.10.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/shims-0.9.0.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/kerby-pkix-1.0.1.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/spark-mesos_2.12-3.1.2.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/commons-beanutils-1.9.4.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/threeten-extra-1.5.0.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/parquet-jackson-1.10.1.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/hadoop-yarn-api-3.2.0.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/lz4-java-1.7.1.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/pyrolite-4.30.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/commons-crypto-1.1.0.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/jakarta.servlet-api-4.0.3.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/xbean-asm7-shaded-4.15.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/hive-serde-2.3.7.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/datanucleus-core-4.1.17.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/scala-xml_2.12-1.2.0.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/kubernetes-model-settings-4.12.0.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/RoaringBitmap-0.9.0.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/httpclient-4.5.6.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/jaxb-api-2.2.11.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/ivy-2.4.0.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/univocity-parsers-2.9.1.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/kubernetes-model-rbac-4.12.0.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/jackson-module-scala_2.12-2.10.0.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/kubernetes-model-batch-4.12.0.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/spark-hive_2.12-3.1.2.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/HikariCP-2.5.1.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/derby-10.12.1.1.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/hadoop-mapreduce-client-core-3.2.0.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/okio-1.14.0.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/avro-mapred-1.8.2-hadoop2.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/okhttp-2.7.5.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/accessors-smart-1.2.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/arrow-vector-2.0.0.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/hadoop-yarn-registry-3.2.0.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/kubernetes-model-scheduling-4.12.0.jar":"System Classpath","/home/user/spark-3.1.2/conf/":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/kubernetes-model-core-4.12.0.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/ST4-4.0.4.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/hive-shims-common-2.3.7.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/jta-1.1.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/spire-platform_2.12-0.17.0-M1.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/parquet-common-1.10.1.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/spark-tags_2.12-3.1.2-tests.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/commons-compiler-3.0.16.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/kubernetes-model-common-4.12.0.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/jackson-module-paranamer-2.10.0.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/commons-collections-3.2.2.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/commons-configuration2-2.1.1.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/kerby-asn1-1.0.1.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/ehcache-3.3.1.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/spark-kubernetes_2.12-3.1.2.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/hk2-api-2.6.1.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/objenesis-2.6.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/orc-core-1.5.12.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/orc-mapreduce-1.5.12.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/scala-parser-combinators_2.12-1.1.2.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/hive-llap-common-2.3.7.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/scala-reflect-2.12.10.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/automaton-1.11-8.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/scala-collection-compat_2.12-2.1.1.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/libthrift-0.12.0.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/okhttp-3.12.12.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/json4s-core_2.12-3.7.0-M5.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/datanucleus-api-jdo-4.2.4.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/commons-logging-1.1.3.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/jcip-annotations-1.0-1.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/jackson-jaxrs-json-provider-2.9.5.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/commons-lang3-3.10.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/commons-dbcp-1.4.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/jersey-client-2.30.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/jackson-annotations-2.10.0.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/jakarta.ws.rs-api-2.1.6.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/super-csv-2.2.0.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/netty-all-4.1.51.Final.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/hive-exec-2.3.7-core.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/commons-lang-2.6.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/spire_2.12-0.17.0-M1.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/spark-launcher_2.12-3.1.2.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/kerb-simplekdc-1.0.1.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/parquet-encoding-1.10.1.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/jersey-media-jaxb-2.30.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/spark-kvstore_2.12-3.1.2.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/datanucleus-rdbms-4.1.19.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/audience-annotations-0.5.0.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/parquet-format-2.4.0.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/shapeless_2.12-2.3.3.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/oro-2.0.8.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/slf4j-log4j12-1.7.30.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/hive-storage-api-2.7.2.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/osgi-resource-locator-1.0.3.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/spire-macros_2.12-0.17.0-M1.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/hk2-locator-2.6.1.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/logging-interceptor-3.12.12.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/spark-catalyst_2.12-3.1.2.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/activation-1.1.1.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/joda-time-2.10.5.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/guava-14.0.1.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/kerb-client-1.0.1.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/hadoop-yarn-server-web-proxy-3.2.0.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/javax.inject-1.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/velocity-1.5.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/kubernetes-model-networking-4.12.0.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/spark-hive-thriftserver_2.12-3.1.2.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/hadoop-client-3.2.0.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/commons-io-2.5.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/JLargeArrays-1.5.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/hadoop-annotations-3.2.0.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/kubernetes-model-admissionregistration-4.12.0.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/mesos-1.4.0-shaded-protobuf.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/hive-shims-scheduler-2.3.7.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/parquet-column-1.10.1.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/commons-cli-1.2.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/hive-shims-0.23-2.3.7.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/jackson-jaxrs-base-2.9.5.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/javassist-3.25.0-GA.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/stream-2.9.6.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/arpack_combined_all-0.1.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/kerb-core-1.0.1.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/hadoop-auth-3.2.0.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/snappy-java-1.1.8.2.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/machinist_2.12-0.6.8.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/log4j-1.2.17.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/macro-compat_2.12-1.1.1.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/chill_2.12-0.9.5.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/paranamer-2.8.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/jakarta.annotation-api-1.3.5.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/jsp-api-2.1.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/jackson-databind-2.10.0.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/kubernetes-model-apiextensions-4.12.0.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/arrow-format-2.0.0.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/spark-repl_2.12-3.1.2.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/hive-shims-2.3.7.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/commons-codec-1.10.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/aopalliance-repackaged-2.6.1.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/avro-1.8.2.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/woodstox-core-5.0.3.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/kerby-config-1.0.1.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/core-1.1.2.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/spark-yarn_2.12-3.1.2.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/htrace-core4-4.1.0-incubating.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/spark-graphx_2.12-3.1.2.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/hadoop-mapreduce-client-jobclient-3.2.0.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/spark-unsafe_2.12-3.1.2.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/jersey-server-2.30.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/hive-vector-code-gen-2.3.7.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/httpcore-4.4.12.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/jakarta.validation-api-2.0.2.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/aircompressor-0.10.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/kubernetes-model-metrics-4.12.0.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/protobuf-java-2.5.0.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/hadoop-yarn-client-3.2.0.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/stax-api-1.0.1.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/kubernetes-model-events-4.12.0.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/json-smart-2.3.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/parquet-hadoop-1.10.1.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/kubernetes-model-coordination-4.12.0.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/jakarta.xml.bind-api-2.3.2.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/kerby-util-1.0.1.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/jersey-hk2-2.30.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/kerb-admin-1.0.1.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/commons-net-3.1.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/json4s-scalap_2.12-3.7.0-M5.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/JTransforms-3.1.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/hadoop-hdfs-client-3.2.0.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/commons-math3-3.4.1.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/antlr4-runtime-4.8-1.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/flatbuffers-java-1.9.0.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/jcl-over-slf4j-1.7.30.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/breeze-macros_2.12-1.0.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/py4j-0.10.9.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/algebra_2.12-2.0.0-M2.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/metrics-graphite-4.1.1.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/jakarta.inject-2.6.1.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/xz-1.5.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/dropwizard-metrics-hadoop-metrics2-reporter-0.1.2.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/spark-sketch_2.12-3.1.2.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/spark-core_2.12-3.1.2.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/jackson-datatype-jsr310-2.11.2.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/json-1.8.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/kubernetes-model-autoscaling-4.12.0.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/scala-compiler-2.12.10.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/kubernetes-client-4.12.0.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/jackson-mapper-asl-1.9.13.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/janino-3.0.16.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/slf4j-api-1.7.30.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/javolution-5.5.1.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/commons-httpclient-3.1.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/kubernetes-model-certificates-4.12.0.jar":"System Classpath","/home/user/hadoop-3.3.0/etc/hadoop/":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/arrow-memory-core-2.0.0.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/spark-streaming_2.12-3.1.2.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/zstd-jni-1.4.8-1.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/kerb-common-1.0.1.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/jodd-core-3.5.2.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/bonecp-0.8.0.RELEASE.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/metrics-jvm-4.1.1.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/json4s-jackson_2.12-3.7.0-M5.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/spark-tags_2.12-3.1.2.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/hive-service-rpc-3.1.2.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/spire-util_2.12-0.17.0-M1.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/kubernetes-model-storageclass-4.12.0.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/generex-1.0.2.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/token-provider-1.0.1.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/kubernetes-model-policy-4.12.0.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/spark-network-shuffle_2.12-3.1.2.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/jackson-core-asl-1.9.13.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/commons-daemon-1.0.13.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/jaxb-runtime-2.3.2.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/gson-2.2.4.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/hadoop-mapreduce-client-common-3.2.0.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/metrics-json-4.1.1.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/kryo-shaded-4.0.2.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/avro-ipc-1.8.2.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/json4s-ast_2.12-3.7.0-M5.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/opencsv-2.3.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/commons-pool-1.5.4.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/jersey-container-servlet-core-2.30.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/istack-commons-runtime-3.0.8.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/cats-kernel_2.12-2.0.0-M4.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/kerb-identity-1.0.1.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/jsr305-3.0.0.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/spark-mllib_2.12-3.1.2.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/jdo-api-3.0.1.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/kubernetes-model-apps-4.12.0.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/jline-2.14.6.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/arrow-memory-netty-2.0.0.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/guice-servlet-4.0.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/zjsonpatch-0.3.0.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/metrics-jmx-4.1.1.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/metrics-core-4.1.1.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/nimbus-jose-jwt-4.41.1.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/snakeyaml-1.24.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/jakarta.activation-api-1.2.1.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/breeze_2.12-1.0.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/kerby-xdr-1.0.1.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/jul-to-slf4j-1.7.30.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/antlr-runtime-3.5.2.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/compress-lzf-1.0.3.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/spark-network-common_2.12-3.1.2.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/curator-client-2.13.0.jar":"System Classpath","spark://host-name:38901/jars/sparkbench-assembly-8.0-SNAPSHOT-dist.jar":"Added By User","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/curator-recipes-2.13.0.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/jpam-1.1.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/commons-compress-1.20.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/minlog-1.3.0.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/spark-sql_2.12-3.1.2.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/guice-4.0.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/kerb-server-1.0.1.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/kubernetes-model-discovery-4.12.0.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/hive-metastore-2.3.7.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/jackson-module-jaxb-annotations-2.10.0.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/spark-mllib-local_2.12-3.1.2.jar":"System Classpath","/home/user/spark-3.1.2/assembly/target/scala-2.12/jars/kerb-util-1.0.1.jar":"System Classpath"}}
{"Event":"SparkListenerApplicationStart","App Name":"PipelineExample","App ID":"application_1641567765635_0075","Timestamp":1641575630976,"User":"user"}
{"Event":"SparkListenerExecutorAdded","Timestamp":1641575644837,"Executor ID":"1","Executor Info":{"Host":"host-name","Total Cores":2,"Log Urls":{"stdout":"http://host-name:8042/node/containerlogs/container_1641567765635_0075_01_000002/user/stdout?start=-4096","stderr":"http://host-name:8042/node/containerlogs/container_1641567765635_0075_01_000002/user/stderr?start=-4096"},"Attributes":{"NM_HTTP_ADDRESS":"host-name:8042","USER":"user","LOG_FILES":"stderr,stdout","NM_HTTP_PORT":"8042","CLUSTER_ID":"","NM_PORT":"45923","HTTP_SCHEME":"http://","NM_HOST":"host-name","CONTAINER_ID":"container_1641567765635_0075_01_000002"},"Resources":{},"Resource Profile Id":0}}
{"Event":"SparkListenerBlockManagerAdded","Block Manager ID":{"Executor ID":"1","Host":"host-name","Port":46743},"Maximum Memory":455501414,"Timestamp":1641575644955,"Maximum Onheap Memory":455501414,"Maximum Offheap Memory":0}
{"Event":"SparkListenerJobStart","Job ID":0,"Submission Time":1641575648149,"Stage Infos":[{"Stage ID":0,"Stage Attempt ID":0,"Stage Name":"treeAggregate at Summarizer.scala:232","Number of Tasks":2,"RDD Info":[{"RDD ID":11,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"7\",\"name\":\"treeAggregate\"}","Callsite":"treeAggregate at Summarizer.scala:232","Parent IDs":[10],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":6,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"4\",\"name\":\"LocalTableScan\"}","Callsite":"rdd at Predictor.scala:81","Parent IDs":[5],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":10,"Name":"training instances","Scope":"{\"id\":\"6\",\"name\":\"map\"}","Callsite":"map at Predictor.scala:81","Parent IDs":[9],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":9,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"5\",\"name\":\"mapPartitions\"}","Callsite":"rdd at Predictor.scala:81","Parent IDs":[8],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":7,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"3\",\"name\":\"DeserializeToObject\"}","Callsite":"rdd at Predictor.scala:81","Parent IDs":[6],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":5,"Name":"ParallelCollectionRDD","Scope":"{\"id\":\"4\",\"name\":\"LocalTableScan\"}","Callsite":"rdd at Predictor.scala:81","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":8,"Name":"SQLExecutionRDD","Callsite":"rdd at Predictor.scala:81","Parent IDs":[7],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.rdd.RDD.treeAggregate(RDD.scala:1222)\norg.apache.spark.ml.stat.Summarizer$.getClassificationSummarizers(Summarizer.scala:232)\norg.apache.spark.ml.classification.LogisticRegression.$anonfun$train$1(LogisticRegression.scala:510)\norg.apache.spark.ml.util.Instrumentation$.$anonfun$instrumented$1(Instrumentation.scala:191)\nscala.util.Try$.apply(Try.scala:213)\norg.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:191)\norg.apache.spark.ml.classification.LogisticRegression.train(LogisticRegression.scala:494)\norg.apache.spark.ml.classification.LogisticRegression.train(LogisticRegression.scala:285)\norg.apache.spark.ml.Predictor.fit(Predictor.scala:151)\norg.apache.spark.ml.Predictor.fit(Predictor.scala:115)\norg.apache.spark.ml.Pipeline.$anonfun$fit$5(Pipeline.scala:151)\norg.apache.spark.ml.MLEvents.withFitEvent(events.scala:130)\norg.apache.spark.ml.MLEvents.withFitEvent$(events.scala:123)\norg.apache.spark.ml.util.Instrumentation.withFitEvent(Instrumentation.scala:42)\norg.apache.spark.ml.Pipeline.$anonfun$fit$4(Pipeline.scala:151)\nscala.collection.Iterator.foreach(Iterator.scala:941)\nscala.collection.Iterator.foreach$(Iterator.scala:941)\nscala.collection.AbstractIterator.foreach(Iterator.scala:1429)\norg.apache.spark.ml.Pipeline.$anonfun$fit$2(Pipeline.scala:147)\norg.apache.spark.ml.MLEvents.withFitEvent(events.scala:130)","Accumulables":[],"Resource Profile Id":0}],"Stage IDs":[0],"Properties":{"spark.rdd.scope":"{\"id\":\"7\",\"name\":\"treeAggregate\"}","spark.rdd.scope.noOverride":"true"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":0,"Stage Attempt ID":0,"Stage Name":"treeAggregate at Summarizer.scala:232","Number of Tasks":2,"RDD Info":[{"RDD ID":11,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"7\",\"name\":\"treeAggregate\"}","Callsite":"treeAggregate at Summarizer.scala:232","Parent IDs":[10],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":6,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"4\",\"name\":\"LocalTableScan\"}","Callsite":"rdd at Predictor.scala:81","Parent IDs":[5],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":10,"Name":"training instances","Scope":"{\"id\":\"6\",\"name\":\"map\"}","Callsite":"map at Predictor.scala:81","Parent IDs":[9],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":9,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"5\",\"name\":\"mapPartitions\"}","Callsite":"rdd at Predictor.scala:81","Parent IDs":[8],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":7,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"3\",\"name\":\"DeserializeToObject\"}","Callsite":"rdd at Predictor.scala:81","Parent IDs":[6],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":5,"Name":"ParallelCollectionRDD","Scope":"{\"id\":\"4\",\"name\":\"LocalTableScan\"}","Callsite":"rdd at Predictor.scala:81","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":8,"Name":"SQLExecutionRDD","Callsite":"rdd at Predictor.scala:81","Parent IDs":[7],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.rdd.RDD.treeAggregate(RDD.scala:1222)\norg.apache.spark.ml.stat.Summarizer$.getClassificationSummarizers(Summarizer.scala:232)\norg.apache.spark.ml.classification.LogisticRegression.$anonfun$train$1(LogisticRegression.scala:510)\norg.apache.spark.ml.util.Instrumentation$.$anonfun$instrumented$1(Instrumentation.scala:191)\nscala.util.Try$.apply(Try.scala:213)\norg.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:191)\norg.apache.spark.ml.classification.LogisticRegression.train(LogisticRegression.scala:494)\norg.apache.spark.ml.classification.LogisticRegression.train(LogisticRegression.scala:285)\norg.apache.spark.ml.Predictor.fit(Predictor.scala:151)\norg.apache.spark.ml.Predictor.fit(Predictor.scala:115)\norg.apache.spark.ml.Pipeline.$anonfun$fit$5(Pipeline.scala:151)\norg.apache.spark.ml.MLEvents.withFitEvent(events.scala:130)\norg.apache.spark.ml.MLEvents.withFitEvent$(events.scala:123)\norg.apache.spark.ml.util.Instrumentation.withFitEvent(Instrumentation.scala:42)\norg.apache.spark.ml.Pipeline.$anonfun$fit$4(Pipeline.scala:151)\nscala.collection.Iterator.foreach(Iterator.scala:941)\nscala.collection.Iterator.foreach$(Iterator.scala:941)\nscala.collection.AbstractIterator.foreach(Iterator.scala:1429)\norg.apache.spark.ml.Pipeline.$anonfun$fit$2(Pipeline.scala:147)\norg.apache.spark.ml.MLEvents.withFitEvent(events.scala:130)","Submission Time":1641575648165,"Accumulables":[],"Resource Profile Id":0},"Properties":{"resource.executor.cores":"2","spark.rdd.scope":"{\"id\":\"7\",\"name\":\"treeAggregate\"}","spark.rdd.scope.noOverride":"true"}}
{"Event":"SparkListenerTaskStart","Stage ID":0,"Stage Attempt ID":0,"Task Info":{"Task ID":0,"Index":0,"Attempt":0,"Launch Time":1641575648280,"Executor ID":"1","Host":"host-name","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskStart","Stage ID":0,"Stage Attempt ID":0,"Task Info":{"Task ID":1,"Index":1,"Attempt":0,"Launch Time":1641575648291,"Executor ID":"1","Host":"host-name","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":0,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":1,"Index":1,"Attempt":0,"Launch Time":1641575648291,"Executor ID":"1","Host":"host-name","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1641575649809,"Failed":false,"Killed":false,"Accumulables":[{"ID":1,"Name":"number of output rows","Update":"2","Value":"2","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":2,"Name":"internal.metrics.executorDeserializeTime","Update":417,"Value":417,"Internal":true,"Count Failed Values":true},{"ID":3,"Name":"internal.metrics.executorDeserializeCpuTime","Update":102386625,"Value":102386625,"Internal":true,"Count Failed Values":true},{"ID":4,"Name":"internal.metrics.executorRunTime","Update":1059,"Value":1059,"Internal":true,"Count Failed Values":true},{"ID":5,"Name":"internal.metrics.executorCpuTime","Update":58960305,"Value":58960305,"Internal":true,"Count Failed Values":true},{"ID":6,"Name":"internal.metrics.resultSize","Update":26674,"Value":26674,"Internal":true,"Count Failed Values":true},{"ID":7,"Name":"internal.metrics.jvmGCTime","Update":28,"Value":28,"Internal":true,"Count Failed Values":true},{"ID":8,"Name":"internal.metrics.resultSerializationTime","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0},"Task Metrics":{"Executor Deserialize Time":417,"Executor Deserialize CPU Time":102386625,"Executor Run Time":1059,"Executor CPU Time":58960305,"Peak Execution Memory":0,"Result Size":26674,"JVM GC Time":28,"Result Serialization Time":1,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":0},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":0,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":0,"Index":0,"Attempt":0,"Launch Time":1641575648280,"Executor ID":"1","Host":"host-name","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1641575649811,"Failed":false,"Killed":false,"Accumulables":[{"ID":1,"Name":"number of output rows","Update":"2","Value":"4","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":2,"Name":"internal.metrics.executorDeserializeTime","Update":417,"Value":834,"Internal":true,"Count Failed Values":true},{"ID":3,"Name":"internal.metrics.executorDeserializeCpuTime","Update":314032061,"Value":416418686,"Internal":true,"Count Failed Values":true},{"ID":4,"Name":"internal.metrics.executorRunTime","Update":1059,"Value":2118,"Internal":true,"Count Failed Values":true},{"ID":5,"Name":"internal.metrics.executorCpuTime","Update":1020805498,"Value":1079765803,"Internal":true,"Count Failed Values":true},{"ID":6,"Name":"internal.metrics.resultSize","Update":26674,"Value":53348,"Internal":true,"Count Failed Values":true},{"ID":7,"Name":"internal.metrics.jvmGCTime","Update":28,"Value":56,"Internal":true,"Count Failed Values":true},{"ID":8,"Name":"internal.metrics.resultSerializationTime","Update":1,"Value":2,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0},"Task Metrics":{"Executor Deserialize Time":417,"Executor Deserialize CPU Time":314032061,"Executor Run Time":1059,"Executor CPU Time":1020805498,"Peak Execution Memory":0,"Result Size":26674,"JVM GC Time":28,"Result Serialization Time":1,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":0},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":0,"Stage Attempt ID":0,"Stage Name":"treeAggregate at Summarizer.scala:232","Number of Tasks":2,"RDD Info":[{"RDD ID":11,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"7\",\"name\":\"treeAggregate\"}","Callsite":"treeAggregate at Summarizer.scala:232","Parent IDs":[10],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":6,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"4\",\"name\":\"LocalTableScan\"}","Callsite":"rdd at Predictor.scala:81","Parent IDs":[5],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":10,"Name":"training instances","Scope":"{\"id\":\"6\",\"name\":\"map\"}","Callsite":"map at Predictor.scala:81","Parent IDs":[9],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":9,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"5\",\"name\":\"mapPartitions\"}","Callsite":"rdd at Predictor.scala:81","Parent IDs":[8],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":7,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"3\",\"name\":\"DeserializeToObject\"}","Callsite":"rdd at Predictor.scala:81","Parent IDs":[6],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":5,"Name":"ParallelCollectionRDD","Scope":"{\"id\":\"4\",\"name\":\"LocalTableScan\"}","Callsite":"rdd at Predictor.scala:81","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":8,"Name":"SQLExecutionRDD","Callsite":"rdd at Predictor.scala:81","Parent IDs":[7],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.rdd.RDD.treeAggregate(RDD.scala:1222)\norg.apache.spark.ml.stat.Summarizer$.getClassificationSummarizers(Summarizer.scala:232)\norg.apache.spark.ml.classification.LogisticRegression.$anonfun$train$1(LogisticRegression.scala:510)\norg.apache.spark.ml.util.Instrumentation$.$anonfun$instrumented$1(Instrumentation.scala:191)\nscala.util.Try$.apply(Try.scala:213)\norg.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:191)\norg.apache.spark.ml.classification.LogisticRegression.train(LogisticRegression.scala:494)\norg.apache.spark.ml.classification.LogisticRegression.train(LogisticRegression.scala:285)\norg.apache.spark.ml.Predictor.fit(Predictor.scala:151)\norg.apache.spark.ml.Predictor.fit(Predictor.scala:115)\norg.apache.spark.ml.Pipeline.$anonfun$fit$5(Pipeline.scala:151)\norg.apache.spark.ml.MLEvents.withFitEvent(events.scala:130)\norg.apache.spark.ml.MLEvents.withFitEvent$(events.scala:123)\norg.apache.spark.ml.util.Instrumentation.withFitEvent(Instrumentation.scala:42)\norg.apache.spark.ml.Pipeline.$anonfun$fit$4(Pipeline.scala:151)\nscala.collection.Iterator.foreach(Iterator.scala:941)\nscala.collection.Iterator.foreach$(Iterator.scala:941)\nscala.collection.AbstractIterator.foreach(Iterator.scala:1429)\norg.apache.spark.ml.Pipeline.$anonfun$fit$2(Pipeline.scala:147)\norg.apache.spark.ml.MLEvents.withFitEvent(events.scala:130)","Submission Time":1641575648165,"Completion Time":1641575649817,"Accumulables":[{"ID":1,"Name":"number of output rows","Value":"4","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":2,"Name":"internal.metrics.executorDeserializeTime","Value":834,"Internal":true,"Count Failed Values":true},{"ID":3,"Name":"internal.metrics.executorDeserializeCpuTime","Value":416418686,"Internal":true,"Count Failed Values":true},{"ID":4,"Name":"internal.metrics.executorRunTime","Value":2118,"Internal":true,"Count Failed Values":true},{"ID":5,"Name":"internal.metrics.executorCpuTime","Value":1079765803,"Internal":true,"Count Failed Values":true},{"ID":6,"Name":"internal.metrics.resultSize","Value":53348,"Internal":true,"Count Failed Values":true},{"ID":7,"Name":"internal.metrics.jvmGCTime","Value":56,"Internal":true,"Count Failed Values":true},{"ID":8,"Name":"internal.metrics.resultSerializationTime","Value":2,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0}}
{"Event":"SparkListenerJobEnd","Job ID":0,"Completion Time":1641575649821,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"SparkListenerJobStart","Job ID":1,"Submission Time":1641575650215,"Stage Infos":[{"Stage ID":1,"Stage Attempt ID":0,"Stage Name":"treeAggregate at RDDLossFunction.scala:61","Number of Tasks":2,"RDD Info":[{"RDD ID":14,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"17\",\"name\":\"treeAggregate\"}","Callsite":"treeAggregate at RDDLossFunction.scala:61","Parent IDs":[13],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":6,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"4\",\"name\":\"LocalTableScan\"}","Callsite":"rdd at Predictor.scala:81","Parent IDs":[5],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":13,"Name":"training blocks (blockSizeInMB=1.0)","Scope":"{\"id\":\"16\",\"name\":\"mapPartitions\"}","Callsite":"mapPartitions at Instance.scala:186","Parent IDs":[12],"Storage Level":{"Use Disk":true,"Use Memory":true,"Deserialized":true,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":10,"Name":"training instances","Scope":"{\"id\":\"6\",\"name\":\"map\"}","Callsite":"map at Predictor.scala:81","Parent IDs":[9],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":9,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"5\",\"name\":\"mapPartitions\"}","Callsite":"rdd at Predictor.scala:81","Parent IDs":[8],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":7,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"3\",\"name\":\"DeserializeToObject\"}","Callsite":"rdd at Predictor.scala:81","Parent IDs":[6],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":12,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"15\",\"name\":\"mapPartitions\"}","Callsite":"mapPartitions at LogisticRegression.scala:944","Parent IDs":[10],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":5,"Name":"ParallelCollectionRDD","Scope":"{\"id\":\"4\",\"name\":\"LocalTableScan\"}","Callsite":"rdd at Predictor.scala:81","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":8,"Name":"SQLExecutionRDD","Callsite":"rdd at Predictor.scala:81","Parent IDs":[7],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.rdd.RDD.treeAggregate(RDD.scala:1222)\norg.apache.spark.ml.optim.loss.RDDLossFunction.calculate(RDDLossFunction.scala:61)\norg.apache.spark.ml.optim.loss.RDDLossFunction.calculate(RDDLossFunction.scala:47)\nbreeze.optimize.CachedDiffFunction.calculate(CachedDiffFunction.scala:24)\nbreeze.optimize.FirstOrderMinimizer.calculateObjective(FirstOrderMinimizer.scala:51)\nbreeze.optimize.FirstOrderMinimizer.initialState(FirstOrderMinimizer.scala:45)\nbreeze.optimize.FirstOrderMinimizer.iterations(FirstOrderMinimizer.scala:97)\norg.apache.spark.ml.classification.LogisticRegression.trainImpl(LogisticRegression.scala:961)\norg.apache.spark.ml.classification.LogisticRegression.$anonfun$train$1(LogisticRegression.scala:627)\norg.apache.spark.ml.util.Instrumentation$.$anonfun$instrumented$1(Instrumentation.scala:191)\nscala.util.Try$.apply(Try.scala:213)\norg.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:191)\norg.apache.spark.ml.classification.LogisticRegression.train(LogisticRegression.scala:494)\norg.apache.spark.ml.classification.LogisticRegression.train(LogisticRegression.scala:285)\norg.apache.spark.ml.Predictor.fit(Predictor.scala:151)\norg.apache.spark.ml.Predictor.fit(Predictor.scala:115)\norg.apache.spark.ml.Pipeline.$anonfun$fit$5(Pipeline.scala:151)\norg.apache.spark.ml.MLEvents.withFitEvent(events.scala:130)\norg.apache.spark.ml.MLEvents.withFitEvent$(events.scala:123)\norg.apache.spark.ml.util.Instrumentation.withFitEvent(Instrumentation.scala:42)","Accumulables":[],"Resource Profile Id":0}],"Stage IDs":[1],"Properties":{"spark.rdd.scope":"{\"id\":\"17\",\"name\":\"treeAggregate\"}","spark.rdd.scope.noOverride":"true"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":1,"Stage Attempt ID":0,"Stage Name":"treeAggregate at RDDLossFunction.scala:61","Number of Tasks":2,"RDD Info":[{"RDD ID":14,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"17\",\"name\":\"treeAggregate\"}","Callsite":"treeAggregate at RDDLossFunction.scala:61","Parent IDs":[13],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":6,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"4\",\"name\":\"LocalTableScan\"}","Callsite":"rdd at Predictor.scala:81","Parent IDs":[5],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":13,"Name":"training blocks (blockSizeInMB=1.0)","Scope":"{\"id\":\"16\",\"name\":\"mapPartitions\"}","Callsite":"mapPartitions at Instance.scala:186","Parent IDs":[12],"Storage Level":{"Use Disk":true,"Use Memory":true,"Deserialized":true,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":10,"Name":"training instances","Scope":"{\"id\":\"6\",\"name\":\"map\"}","Callsite":"map at Predictor.scala:81","Parent IDs":[9],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":9,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"5\",\"name\":\"mapPartitions\"}","Callsite":"rdd at Predictor.scala:81","Parent IDs":[8],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":7,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"3\",\"name\":\"DeserializeToObject\"}","Callsite":"rdd at Predictor.scala:81","Parent IDs":[6],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":12,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"15\",\"name\":\"mapPartitions\"}","Callsite":"mapPartitions at LogisticRegression.scala:944","Parent IDs":[10],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":5,"Name":"ParallelCollectionRDD","Scope":"{\"id\":\"4\",\"name\":\"LocalTableScan\"}","Callsite":"rdd at Predictor.scala:81","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":8,"Name":"SQLExecutionRDD","Callsite":"rdd at Predictor.scala:81","Parent IDs":[7],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.rdd.RDD.treeAggregate(RDD.scala:1222)\norg.apache.spark.ml.optim.loss.RDDLossFunction.calculate(RDDLossFunction.scala:61)\norg.apache.spark.ml.optim.loss.RDDLossFunction.calculate(RDDLossFunction.scala:47)\nbreeze.optimize.CachedDiffFunction.calculate(CachedDiffFunction.scala:24)\nbreeze.optimize.FirstOrderMinimizer.calculateObjective(FirstOrderMinimizer.scala:51)\nbreeze.optimize.FirstOrderMinimizer.initialState(FirstOrderMinimizer.scala:45)\nbreeze.optimize.FirstOrderMinimizer.iterations(FirstOrderMinimizer.scala:97)\norg.apache.spark.ml.classification.LogisticRegression.trainImpl(LogisticRegression.scala:961)\norg.apache.spark.ml.classification.LogisticRegression.$anonfun$train$1(LogisticRegression.scala:627)\norg.apache.spark.ml.util.Instrumentation$.$anonfun$instrumented$1(Instrumentation.scala:191)\nscala.util.Try$.apply(Try.scala:213)\norg.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:191)\norg.apache.spark.ml.classification.LogisticRegression.train(LogisticRegression.scala:494)\norg.apache.spark.ml.classification.LogisticRegression.train(LogisticRegression.scala:285)\norg.apache.spark.ml.Predictor.fit(Predictor.scala:151)\norg.apache.spark.ml.Predictor.fit(Predictor.scala:115)\norg.apache.spark.ml.Pipeline.$anonfun$fit$5(Pipeline.scala:151)\norg.apache.spark.ml.MLEvents.withFitEvent(events.scala:130)\norg.apache.spark.ml.MLEvents.withFitEvent$(events.scala:123)\norg.apache.spark.ml.util.Instrumentation.withFitEvent(Instrumentation.scala:42)","Submission Time":1641575650217,"Accumulables":[],"Resource Profile Id":0},"Properties":{"resource.executor.cores":"2","spark.rdd.scope":"{\"id\":\"17\",\"name\":\"treeAggregate\"}","spark.rdd.scope.noOverride":"true"}}
{"Event":"SparkListenerTaskStart","Stage ID":1,"Stage Attempt ID":0,"Task Info":{"Task ID":2,"Index":0,"Attempt":0,"Launch Time":1641575650227,"Executor ID":"1","Host":"host-name","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskStart","Stage ID":1,"Stage Attempt ID":0,"Task Info":{"Task ID":3,"Index":1,"Attempt":0,"Launch Time":1641575650227,"Executor ID":"1","Host":"host-name","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":1,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":3,"Index":1,"Attempt":0,"Launch Time":1641575650227,"Executor ID":"1","Host":"host-name","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1641575650387,"Failed":false,"Killed":false,"Accumulables":[{"ID":1,"Name":"number of output rows","Update":"2","Value":"6","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":27,"Name":"internal.metrics.executorDeserializeTime","Update":78,"Value":78,"Internal":true,"Count Failed Values":true},{"ID":28,"Name":"internal.metrics.executorDeserializeCpuTime","Update":68057301,"Value":68057301,"Internal":true,"Count Failed Values":true},{"ID":29,"Name":"internal.metrics.executorRunTime","Update":74,"Value":74,"Internal":true,"Count Failed Values":true},{"ID":30,"Name":"internal.metrics.executorCpuTime","Update":46841116,"Value":46841116,"Internal":true,"Count Failed Values":true},{"ID":31,"Name":"internal.metrics.resultSize","Update":10068,"Value":10068,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0},"Task Metrics":{"Executor Deserialize Time":78,"Executor Deserialize CPU Time":68057301,"Executor Run Time":74,"Executor CPU Time":46841116,"Peak Execution Memory":0,"Result Size":10068,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":0},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":1,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":2,"Index":0,"Attempt":0,"Launch Time":1641575650227,"Executor ID":"1","Host":"host-name","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1641575650387,"Failed":false,"Killed":false,"Accumulables":[{"ID":1,"Name":"number of output rows","Update":"2","Value":"8","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":27,"Name":"internal.metrics.executorDeserializeTime","Update":78,"Value":156,"Internal":true,"Count Failed Values":true},{"ID":28,"Name":"internal.metrics.executorDeserializeCpuTime","Update":27630816,"Value":95688117,"Internal":true,"Count Failed Values":true},{"ID":29,"Name":"internal.metrics.executorRunTime","Update":74,"Value":148,"Internal":true,"Count Failed Values":true},{"ID":30,"Name":"internal.metrics.executorCpuTime","Update":29676119,"Value":76517235,"Internal":true,"Count Failed Values":true},{"ID":31,"Name":"internal.metrics.resultSize","Update":10068,"Value":20136,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0},"Task Metrics":{"Executor Deserialize Time":78,"Executor Deserialize CPU Time":27630816,"Executor Run Time":74,"Executor CPU Time":29676119,"Peak Execution Memory":0,"Result Size":10068,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":0},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":1,"Stage Attempt ID":0,"Stage Name":"treeAggregate at RDDLossFunction.scala:61","Number of Tasks":2,"RDD Info":[{"RDD ID":14,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"17\",\"name\":\"treeAggregate\"}","Callsite":"treeAggregate at RDDLossFunction.scala:61","Parent IDs":[13],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":6,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"4\",\"name\":\"LocalTableScan\"}","Callsite":"rdd at Predictor.scala:81","Parent IDs":[5],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":13,"Name":"training blocks (blockSizeInMB=1.0)","Scope":"{\"id\":\"16\",\"name\":\"mapPartitions\"}","Callsite":"mapPartitions at Instance.scala:186","Parent IDs":[12],"Storage Level":{"Use Disk":true,"Use Memory":true,"Deserialized":true,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":10,"Name":"training instances","Scope":"{\"id\":\"6\",\"name\":\"map\"}","Callsite":"map at Predictor.scala:81","Parent IDs":[9],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":9,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"5\",\"name\":\"mapPartitions\"}","Callsite":"rdd at Predictor.scala:81","Parent IDs":[8],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":7,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"3\",\"name\":\"DeserializeToObject\"}","Callsite":"rdd at Predictor.scala:81","Parent IDs":[6],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":12,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"15\",\"name\":\"mapPartitions\"}","Callsite":"mapPartitions at LogisticRegression.scala:944","Parent IDs":[10],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":5,"Name":"ParallelCollectionRDD","Scope":"{\"id\":\"4\",\"name\":\"LocalTableScan\"}","Callsite":"rdd at Predictor.scala:81","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":8,"Name":"SQLExecutionRDD","Callsite":"rdd at Predictor.scala:81","Parent IDs":[7],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.rdd.RDD.treeAggregate(RDD.scala:1222)\norg.apache.spark.ml.optim.loss.RDDLossFunction.calculate(RDDLossFunction.scala:61)\norg.apache.spark.ml.optim.loss.RDDLossFunction.calculate(RDDLossFunction.scala:47)\nbreeze.optimize.CachedDiffFunction.calculate(CachedDiffFunction.scala:24)\nbreeze.optimize.FirstOrderMinimizer.calculateObjective(FirstOrderMinimizer.scala:51)\nbreeze.optimize.FirstOrderMinimizer.initialState(FirstOrderMinimizer.scala:45)\nbreeze.optimize.FirstOrderMinimizer.iterations(FirstOrderMinimizer.scala:97)\norg.apache.spark.ml.classification.LogisticRegression.trainImpl(LogisticRegression.scala:961)\norg.apache.spark.ml.classification.LogisticRegression.$anonfun$train$1(LogisticRegression.scala:627)\norg.apache.spark.ml.util.Instrumentation$.$anonfun$instrumented$1(Instrumentation.scala:191)\nscala.util.Try$.apply(Try.scala:213)\norg.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:191)\norg.apache.spark.ml.classification.LogisticRegression.train(LogisticRegression.scala:494)\norg.apache.spark.ml.classification.LogisticRegression.train(LogisticRegression.scala:285)\norg.apache.spark.ml.Predictor.fit(Predictor.scala:151)\norg.apache.spark.ml.Predictor.fit(Predictor.scala:115)\norg.apache.spark.ml.Pipeline.$anonfun$fit$5(Pipeline.scala:151)\norg.apache.spark.ml.MLEvents.withFitEvent(events.scala:130)\norg.apache.spark.ml.MLEvents.withFitEvent$(events.scala:123)\norg.apache.spark.ml.util.Instrumentation.withFitEvent(Instrumentation.scala:42)","Submission Time":1641575650217,"Completion Time":1641575650397,"Accumulables":[{"ID":1,"Name":"number of output rows","Value":"8","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":27,"Name":"internal.metrics.executorDeserializeTime","Value":156,"Internal":true,"Count Failed Values":true},{"ID":28,"Name":"internal.metrics.executorDeserializeCpuTime","Value":95688117,"Internal":true,"Count Failed Values":true},{"ID":29,"Name":"internal.metrics.executorRunTime","Value":148,"Internal":true,"Count Failed Values":true},{"ID":30,"Name":"internal.metrics.executorCpuTime","Value":76517235,"Internal":true,"Count Failed Values":true},{"ID":31,"Name":"internal.metrics.resultSize","Value":20136,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0}}
{"Event":"SparkListenerJobEnd","Job ID":1,"Completion Time":1641575650398,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"SparkListenerJobStart","Job ID":2,"Submission Time":1641575650447,"Stage Infos":[{"Stage ID":2,"Stage Attempt ID":0,"Stage Name":"treeAggregate at RDDLossFunction.scala:61","Number of Tasks":2,"RDD Info":[{"RDD ID":15,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"22\",\"name\":\"treeAggregate\"}","Callsite":"treeAggregate at RDDLossFunction.scala:61","Parent IDs":[13],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":6,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"4\",\"name\":\"LocalTableScan\"}","Callsite":"rdd at Predictor.scala:81","Parent IDs":[5],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":13,"Name":"training blocks (blockSizeInMB=1.0)","Scope":"{\"id\":\"16\",\"name\":\"mapPartitions\"}","Callsite":"mapPartitions at Instance.scala:186","Parent IDs":[12],"Storage Level":{"Use Disk":true,"Use Memory":true,"Deserialized":true,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":10,"Name":"training instances","Scope":"{\"id\":\"6\",\"name\":\"map\"}","Callsite":"map at Predictor.scala:81","Parent IDs":[9],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":9,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"5\",\"name\":\"mapPartitions\"}","Callsite":"rdd at Predictor.scala:81","Parent IDs":[8],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":7,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"3\",\"name\":\"DeserializeToObject\"}","Callsite":"rdd at Predictor.scala:81","Parent IDs":[6],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":12,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"15\",\"name\":\"mapPartitions\"}","Callsite":"mapPartitions at LogisticRegression.scala:944","Parent IDs":[10],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":5,"Name":"ParallelCollectionRDD","Scope":"{\"id\":\"4\",\"name\":\"LocalTableScan\"}","Callsite":"rdd at Predictor.scala:81","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":8,"Name":"SQLExecutionRDD","Callsite":"rdd at Predictor.scala:81","Parent IDs":[7],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.rdd.RDD.treeAggregate(RDD.scala:1222)\norg.apache.spark.ml.optim.loss.RDDLossFunction.calculate(RDDLossFunction.scala:61)\norg.apache.spark.ml.optim.loss.RDDLossFunction.calculate(RDDLossFunction.scala:47)\nbreeze.optimize.CachedDiffFunction.calculate(CachedDiffFunction.scala:24)\nbreeze.optimize.LineSearch$$anon$1.calculate(LineSearch.scala:52)\nbreeze.optimize.LineSearch$$anon$1.calculate(LineSearch.scala:31)\nbreeze.optimize.StrongWolfeLineSearch.phi$1(StrongWolfe.scala:76)\nbreeze.optimize.StrongWolfeLineSearch.$anonfun$minimizeWithBound$7(StrongWolfe.scala:152)\nscala.collection.immutable.Range.foreach$mVc$sp(Range.scala:158)\nbreeze.optimize.StrongWolfeLineSearch.minimizeWithBound(StrongWolfe.scala:151)\nbreeze.optimize.StrongWolfeLineSearch.minimize(StrongWolfe.scala:62)\nbreeze.optimize.LBFGS.determineStepSize(LBFGS.scala:82)\nbreeze.optimize.LBFGS.determineStepSize(LBFGS.scala:38)\nbreeze.optimize.FirstOrderMinimizer.$anonfun$infiniteIterations$1(FirstOrderMinimizer.scala:61)\nscala.collection.Iterator$$anon$7.next(Iterator.scala:140)\nbreeze.util.IteratorImplicits$RichIterator$$anon$2.next(Implicits.scala:74)\norg.apache.spark.ml.classification.LogisticRegression.trainImpl(LogisticRegression.scala:971)\norg.apache.spark.ml.classification.LogisticRegression.$anonfun$train$1(LogisticRegression.scala:627)\norg.apache.spark.ml.util.Instrumentation$.$anonfun$instrumented$1(Instrumentation.scala:191)\nscala.util.Try$.apply(Try.scala:213)","Accumulables":[],"Resource Profile Id":0}],"Stage IDs":[2],"Properties":{"spark.rdd.scope":"{\"id\":\"22\",\"name\":\"treeAggregate\"}","spark.rdd.scope.noOverride":"true"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":2,"Stage Attempt ID":0,"Stage Name":"treeAggregate at RDDLossFunction.scala:61","Number of Tasks":2,"RDD Info":[{"RDD ID":15,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"22\",\"name\":\"treeAggregate\"}","Callsite":"treeAggregate at RDDLossFunction.scala:61","Parent IDs":[13],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":6,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"4\",\"name\":\"LocalTableScan\"}","Callsite":"rdd at Predictor.scala:81","Parent IDs":[5],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":13,"Name":"training blocks (blockSizeInMB=1.0)","Scope":"{\"id\":\"16\",\"name\":\"mapPartitions\"}","Callsite":"mapPartitions at Instance.scala:186","Parent IDs":[12],"Storage Level":{"Use Disk":true,"Use Memory":true,"Deserialized":true,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":10,"Name":"training instances","Scope":"{\"id\":\"6\",\"name\":\"map\"}","Callsite":"map at Predictor.scala:81","Parent IDs":[9],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":9,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"5\",\"name\":\"mapPartitions\"}","Callsite":"rdd at Predictor.scala:81","Parent IDs":[8],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":7,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"3\",\"name\":\"DeserializeToObject\"}","Callsite":"rdd at Predictor.scala:81","Parent IDs":[6],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":12,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"15\",\"name\":\"mapPartitions\"}","Callsite":"mapPartitions at LogisticRegression.scala:944","Parent IDs":[10],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":5,"Name":"ParallelCollectionRDD","Scope":"{\"id\":\"4\",\"name\":\"LocalTableScan\"}","Callsite":"rdd at Predictor.scala:81","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":8,"Name":"SQLExecutionRDD","Callsite":"rdd at Predictor.scala:81","Parent IDs":[7],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.rdd.RDD.treeAggregate(RDD.scala:1222)\norg.apache.spark.ml.optim.loss.RDDLossFunction.calculate(RDDLossFunction.scala:61)\norg.apache.spark.ml.optim.loss.RDDLossFunction.calculate(RDDLossFunction.scala:47)\nbreeze.optimize.CachedDiffFunction.calculate(CachedDiffFunction.scala:24)\nbreeze.optimize.LineSearch$$anon$1.calculate(LineSearch.scala:52)\nbreeze.optimize.LineSearch$$anon$1.calculate(LineSearch.scala:31)\nbreeze.optimize.StrongWolfeLineSearch.phi$1(StrongWolfe.scala:76)\nbreeze.optimize.StrongWolfeLineSearch.$anonfun$minimizeWithBound$7(StrongWolfe.scala:152)\nscala.collection.immutable.Range.foreach$mVc$sp(Range.scala:158)\nbreeze.optimize.StrongWolfeLineSearch.minimizeWithBound(StrongWolfe.scala:151)\nbreeze.optimize.StrongWolfeLineSearch.minimize(StrongWolfe.scala:62)\nbreeze.optimize.LBFGS.determineStepSize(LBFGS.scala:82)\nbreeze.optimize.LBFGS.determineStepSize(LBFGS.scala:38)\nbreeze.optimize.FirstOrderMinimizer.$anonfun$infiniteIterations$1(FirstOrderMinimizer.scala:61)\nscala.collection.Iterator$$anon$7.next(Iterator.scala:140)\nbreeze.util.IteratorImplicits$RichIterator$$anon$2.next(Implicits.scala:74)\norg.apache.spark.ml.classification.LogisticRegression.trainImpl(LogisticRegression.scala:971)\norg.apache.spark.ml.classification.LogisticRegression.$anonfun$train$1(LogisticRegression.scala:627)\norg.apache.spark.ml.util.Instrumentation$.$anonfun$instrumented$1(Instrumentation.scala:191)\nscala.util.Try$.apply(Try.scala:213)","Submission Time":1641575650449,"Accumulables":[],"Resource Profile Id":0},"Properties":{"resource.executor.cores":"2","spark.rdd.scope":"{\"id\":\"22\",\"name\":\"treeAggregate\"}","spark.rdd.scope.noOverride":"true"}}
{"Event":"SparkListenerTaskStart","Stage ID":2,"Stage Attempt ID":0,"Task Info":{"Task ID":4,"Index":0,"Attempt":0,"Launch Time":1641575650462,"Executor ID":"1","Host":"host-name","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskStart","Stage ID":2,"Stage Attempt ID":0,"Task Info":{"Task ID":5,"Index":1,"Attempt":0,"Launch Time":1641575650463,"Executor ID":"1","Host":"host-name","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":2,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":5,"Index":1,"Attempt":0,"Launch Time":1641575650463,"Executor ID":"1","Host":"host-name","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1641575650494,"Failed":false,"Killed":false,"Accumulables":[{"ID":52,"Name":"internal.metrics.executorDeserializeTime","Update":12,"Value":12,"Internal":true,"Count Failed Values":true},{"ID":53,"Name":"internal.metrics.executorDeserializeCpuTime","Update":3478818,"Value":3478818,"Internal":true,"Count Failed Values":true},{"ID":54,"Name":"internal.metrics.executorRunTime","Update":11,"Value":11,"Internal":true,"Count Failed Values":true},{"ID":55,"Name":"internal.metrics.executorCpuTime","Update":1998633,"Value":1998633,"Internal":true,"Count Failed Values":true},{"ID":56,"Name":"internal.metrics.resultSize","Update":10154,"Value":10154,"Internal":true,"Count Failed Values":true},{"ID":73,"Name":"internal.metrics.input.bytesRead","Update":288,"Value":288,"Internal":true,"Count Failed Values":true},{"ID":74,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0},"Task Metrics":{"Executor Deserialize Time":12,"Executor Deserialize CPU Time":3478818,"Executor Run Time":11,"Executor CPU Time":1998633,"Peak Execution Memory":0,"Result Size":10154,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":288,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":2,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":4,"Index":0,"Attempt":0,"Launch Time":1641575650462,"Executor ID":"1","Host":"host-name","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1641575650495,"Failed":false,"Killed":false,"Accumulables":[{"ID":52,"Name":"internal.metrics.executorDeserializeTime","Update":13,"Value":25,"Internal":true,"Count Failed Values":true},{"ID":53,"Name":"internal.metrics.executorDeserializeCpuTime","Update":7854081,"Value":11332899,"Internal":true,"Count Failed Values":true},{"ID":54,"Name":"internal.metrics.executorRunTime","Update":11,"Value":22,"Internal":true,"Count Failed Values":true},{"ID":55,"Name":"internal.metrics.executorCpuTime","Update":5931950,"Value":7930583,"Internal":true,"Count Failed Values":true},{"ID":56,"Name":"internal.metrics.resultSize","Update":10154,"Value":20308,"Internal":true,"Count Failed Values":true},{"ID":73,"Name":"internal.metrics.input.bytesRead","Update":312,"Value":600,"Internal":true,"Count Failed Values":true},{"ID":74,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":2,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0},"Task Metrics":{"Executor Deserialize Time":13,"Executor Deserialize CPU Time":7854081,"Executor Run Time":11,"Executor CPU Time":5931950,"Peak Execution Memory":0,"Result Size":10154,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":312,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":2,"Stage Attempt ID":0,"Stage Name":"treeAggregate at RDDLossFunction.scala:61","Number of Tasks":2,"RDD Info":[{"RDD ID":15,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"22\",\"name\":\"treeAggregate\"}","Callsite":"treeAggregate at RDDLossFunction.scala:61","Parent IDs":[13],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":6,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"4\",\"name\":\"LocalTableScan\"}","Callsite":"rdd at Predictor.scala:81","Parent IDs":[5],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":13,"Name":"training blocks (blockSizeInMB=1.0)","Scope":"{\"id\":\"16\",\"name\":\"mapPartitions\"}","Callsite":"mapPartitions at Instance.scala:186","Parent IDs":[12],"Storage Level":{"Use Disk":true,"Use Memory":true,"Deserialized":true,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":10,"Name":"training instances","Scope":"{\"id\":\"6\",\"name\":\"map\"}","Callsite":"map at Predictor.scala:81","Parent IDs":[9],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":9,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"5\",\"name\":\"mapPartitions\"}","Callsite":"rdd at Predictor.scala:81","Parent IDs":[8],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":7,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"3\",\"name\":\"DeserializeToObject\"}","Callsite":"rdd at Predictor.scala:81","Parent IDs":[6],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":12,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"15\",\"name\":\"mapPartitions\"}","Callsite":"mapPartitions at LogisticRegression.scala:944","Parent IDs":[10],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":5,"Name":"ParallelCollectionRDD","Scope":"{\"id\":\"4\",\"name\":\"LocalTableScan\"}","Callsite":"rdd at Predictor.scala:81","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":8,"Name":"SQLExecutionRDD","Callsite":"rdd at Predictor.scala:81","Parent IDs":[7],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.rdd.RDD.treeAggregate(RDD.scala:1222)\norg.apache.spark.ml.optim.loss.RDDLossFunction.calculate(RDDLossFunction.scala:61)\norg.apache.spark.ml.optim.loss.RDDLossFunction.calculate(RDDLossFunction.scala:47)\nbreeze.optimize.CachedDiffFunction.calculate(CachedDiffFunction.scala:24)\nbreeze.optimize.LineSearch$$anon$1.calculate(LineSearch.scala:52)\nbreeze.optimize.LineSearch$$anon$1.calculate(LineSearch.scala:31)\nbreeze.optimize.StrongWolfeLineSearch.phi$1(StrongWolfe.scala:76)\nbreeze.optimize.StrongWolfeLineSearch.$anonfun$minimizeWithBound$7(StrongWolfe.scala:152)\nscala.collection.immutable.Range.foreach$mVc$sp(Range.scala:158)\nbreeze.optimize.StrongWolfeLineSearch.minimizeWithBound(StrongWolfe.scala:151)\nbreeze.optimize.StrongWolfeLineSearch.minimize(StrongWolfe.scala:62)\nbreeze.optimize.LBFGS.determineStepSize(LBFGS.scala:82)\nbreeze.optimize.LBFGS.determineStepSize(LBFGS.scala:38)\nbreeze.optimize.FirstOrderMinimizer.$anonfun$infiniteIterations$1(FirstOrderMinimizer.scala:61)\nscala.collection.Iterator$$anon$7.next(Iterator.scala:140)\nbreeze.util.IteratorImplicits$RichIterator$$anon$2.next(Implicits.scala:74)\norg.apache.spark.ml.classification.LogisticRegression.trainImpl(LogisticRegression.scala:971)\norg.apache.spark.ml.classification.LogisticRegression.$anonfun$train$1(LogisticRegression.scala:627)\norg.apache.spark.ml.util.Instrumentation$.$anonfun$instrumented$1(Instrumentation.scala:191)\nscala.util.Try$.apply(Try.scala:213)","Submission Time":1641575650449,"Completion Time":1641575650496,"Accumulables":[{"ID":52,"Name":"internal.metrics.executorDeserializeTime","Value":25,"Internal":true,"Count Failed Values":true},{"ID":53,"Name":"internal.metrics.executorDeserializeCpuTime","Value":11332899,"Internal":true,"Count Failed Values":true},{"ID":54,"Name":"internal.metrics.executorRunTime","Value":22,"Internal":true,"Count Failed Values":true},{"ID":55,"Name":"internal.metrics.executorCpuTime","Value":7930583,"Internal":true,"Count Failed Values":true},{"ID":56,"Name":"internal.metrics.resultSize","Value":20308,"Internal":true,"Count Failed Values":true},{"ID":73,"Name":"internal.metrics.input.bytesRead","Value":600,"Internal":true,"Count Failed Values":true},{"ID":74,"Name":"internal.metrics.input.recordsRead","Value":2,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0}}
{"Event":"SparkListenerJobEnd","Job ID":2,"Completion Time":1641575650496,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"SparkListenerJobStart","Job ID":3,"Submission Time":1641575650517,"Stage Infos":[{"Stage ID":3,"Stage Attempt ID":0,"Stage Name":"treeAggregate at RDDLossFunction.scala:61","Number of Tasks":2,"RDD Info":[{"RDD ID":16,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"25\",\"name\":\"treeAggregate\"}","Callsite":"treeAggregate at RDDLossFunction.scala:61","Parent IDs":[13],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":6,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"4\",\"name\":\"LocalTableScan\"}","Callsite":"rdd at Predictor.scala:81","Parent IDs":[5],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":13,"Name":"training blocks (blockSizeInMB=1.0)","Scope":"{\"id\":\"16\",\"name\":\"mapPartitions\"}","Callsite":"mapPartitions at Instance.scala:186","Parent IDs":[12],"Storage Level":{"Use Disk":true,"Use Memory":true,"Deserialized":true,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":10,"Name":"training instances","Scope":"{\"id\":\"6\",\"name\":\"map\"}","Callsite":"map at Predictor.scala:81","Parent IDs":[9],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":9,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"5\",\"name\":\"mapPartitions\"}","Callsite":"rdd at Predictor.scala:81","Parent IDs":[8],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":7,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"3\",\"name\":\"DeserializeToObject\"}","Callsite":"rdd at Predictor.scala:81","Parent IDs":[6],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":12,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"15\",\"name\":\"mapPartitions\"}","Callsite":"mapPartitions at LogisticRegression.scala:944","Parent IDs":[10],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":5,"Name":"ParallelCollectionRDD","Scope":"{\"id\":\"4\",\"name\":\"LocalTableScan\"}","Callsite":"rdd at Predictor.scala:81","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":8,"Name":"SQLExecutionRDD","Callsite":"rdd at Predictor.scala:81","Parent IDs":[7],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.rdd.RDD.treeAggregate(RDD.scala:1222)\norg.apache.spark.ml.optim.loss.RDDLossFunction.calculate(RDDLossFunction.scala:61)\norg.apache.spark.ml.optim.loss.RDDLossFunction.calculate(RDDLossFunction.scala:47)\nbreeze.optimize.CachedDiffFunction.calculate(CachedDiffFunction.scala:24)\nbreeze.optimize.LineSearch$$anon$1.calculate(LineSearch.scala:52)\nbreeze.optimize.LineSearch$$anon$1.calculate(LineSearch.scala:31)\nbreeze.optimize.StrongWolfeLineSearch.phi$1(StrongWolfe.scala:76)\nbreeze.optimize.StrongWolfeLineSearch.$anonfun$minimizeWithBound$7(StrongWolfe.scala:152)\nscala.collection.immutable.Range.foreach$mVc$sp(Range.scala:158)\nbreeze.optimize.StrongWolfeLineSearch.minimizeWithBound(StrongWolfe.scala:151)\nbreeze.optimize.StrongWolfeLineSearch.minimize(StrongWolfe.scala:62)\nbreeze.optimize.LBFGS.determineStepSize(LBFGS.scala:82)\nbreeze.optimize.LBFGS.determineStepSize(LBFGS.scala:38)\nbreeze.optimize.FirstOrderMinimizer.$anonfun$infiniteIterations$1(FirstOrderMinimizer.scala:61)\nscala.collection.Iterator$$anon$7.next(Iterator.scala:140)\nbreeze.util.IteratorImplicits$RichIterator$$anon$2.next(Implicits.scala:74)\norg.apache.spark.ml.classification.LogisticRegression.trainImpl(LogisticRegression.scala:971)\norg.apache.spark.ml.classification.LogisticRegression.$anonfun$train$1(LogisticRegression.scala:627)\norg.apache.spark.ml.util.Instrumentation$.$anonfun$instrumented$1(Instrumentation.scala:191)\nscala.util.Try$.apply(Try.scala:213)","Accumulables":[],"Resource Profile Id":0}],"Stage IDs":[3],"Properties":{"spark.rdd.scope":"{\"id\":\"25\",\"name\":\"treeAggregate\"}","spark.rdd.scope.noOverride":"true"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":3,"Stage Attempt ID":0,"Stage Name":"treeAggregate at RDDLossFunction.scala:61","Number of Tasks":2,"RDD Info":[{"RDD ID":16,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"25\",\"name\":\"treeAggregate\"}","Callsite":"treeAggregate at RDDLossFunction.scala:61","Parent IDs":[13],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":6,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"4\",\"name\":\"LocalTableScan\"}","Callsite":"rdd at Predictor.scala:81","Parent IDs":[5],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":13,"Name":"training blocks (blockSizeInMB=1.0)","Scope":"{\"id\":\"16\",\"name\":\"mapPartitions\"}","Callsite":"mapPartitions at Instance.scala:186","Parent IDs":[12],"Storage Level":{"Use Disk":true,"Use Memory":true,"Deserialized":true,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":10,"Name":"training instances","Scope":"{\"id\":\"6\",\"name\":\"map\"}","Callsite":"map at Predictor.scala:81","Parent IDs":[9],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":9,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"5\",\"name\":\"mapPartitions\"}","Callsite":"rdd at Predictor.scala:81","Parent IDs":[8],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":7,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"3\",\"name\":\"DeserializeToObject\"}","Callsite":"rdd at Predictor.scala:81","Parent IDs":[6],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":12,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"15\",\"name\":\"mapPartitions\"}","Callsite":"mapPartitions at LogisticRegression.scala:944","Parent IDs":[10],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":5,"Name":"ParallelCollectionRDD","Scope":"{\"id\":\"4\",\"name\":\"LocalTableScan\"}","Callsite":"rdd at Predictor.scala:81","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":8,"Name":"SQLExecutionRDD","Callsite":"rdd at Predictor.scala:81","Parent IDs":[7],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.rdd.RDD.treeAggregate(RDD.scala:1222)\norg.apache.spark.ml.optim.loss.RDDLossFunction.calculate(RDDLossFunction.scala:61)\norg.apache.spark.ml.optim.loss.RDDLossFunction.calculate(RDDLossFunction.scala:47)\nbreeze.optimize.CachedDiffFunction.calculate(CachedDiffFunction.scala:24)\nbreeze.optimize.LineSearch$$anon$1.calculate(LineSearch.scala:52)\nbreeze.optimize.LineSearch$$anon$1.calculate(LineSearch.scala:31)\nbreeze.optimize.StrongWolfeLineSearch.phi$1(StrongWolfe.scala:76)\nbreeze.optimize.StrongWolfeLineSearch.$anonfun$minimizeWithBound$7(StrongWolfe.scala:152)\nscala.collection.immutable.Range.foreach$mVc$sp(Range.scala:158)\nbreeze.optimize.StrongWolfeLineSearch.minimizeWithBound(StrongWolfe.scala:151)\nbreeze.optimize.StrongWolfeLineSearch.minimize(StrongWolfe.scala:62)\nbreeze.optimize.LBFGS.determineStepSize(LBFGS.scala:82)\nbreeze.optimize.LBFGS.determineStepSize(LBFGS.scala:38)\nbreeze.optimize.FirstOrderMinimizer.$anonfun$infiniteIterations$1(FirstOrderMinimizer.scala:61)\nscala.collection.Iterator$$anon$7.next(Iterator.scala:140)\nbreeze.util.IteratorImplicits$RichIterator$$anon$2.next(Implicits.scala:74)\norg.apache.spark.ml.classification.LogisticRegression.trainImpl(LogisticRegression.scala:971)\norg.apache.spark.ml.classification.LogisticRegression.$anonfun$train$1(LogisticRegression.scala:627)\norg.apache.spark.ml.util.Instrumentation$.$anonfun$instrumented$1(Instrumentation.scala:191)\nscala.util.Try$.apply(Try.scala:213)","Submission Time":1641575650519,"Accumulables":[],"Resource Profile Id":0},"Properties":{"resource.executor.cores":"2","spark.rdd.scope":"{\"id\":\"25\",\"name\":\"treeAggregate\"}","spark.rdd.scope.noOverride":"true"}}
{"Event":"SparkListenerTaskStart","Stage ID":3,"Stage Attempt ID":0,"Task Info":{"Task ID":6,"Index":0,"Attempt":0,"Launch Time":1641575650525,"Executor ID":"1","Host":"host-name","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskStart","Stage ID":3,"Stage Attempt ID":0,"Task Info":{"Task ID":7,"Index":1,"Attempt":0,"Launch Time":1641575650525,"Executor ID":"1","Host":"host-name","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":3,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":6,"Index":0,"Attempt":0,"Launch Time":1641575650525,"Executor ID":"1","Host":"host-name","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1641575650554,"Failed":false,"Killed":false,"Accumulables":[{"ID":77,"Name":"internal.metrics.executorDeserializeTime","Update":11,"Value":11,"Internal":true,"Count Failed Values":true},{"ID":78,"Name":"internal.metrics.executorDeserializeCpuTime","Update":7341340,"Value":7341340,"Internal":true,"Count Failed Values":true},{"ID":79,"Name":"internal.metrics.executorRunTime","Update":11,"Value":11,"Internal":true,"Count Failed Values":true},{"ID":80,"Name":"internal.metrics.executorCpuTime","Update":6160694,"Value":6160694,"Internal":true,"Count Failed Values":true},{"ID":81,"Name":"internal.metrics.resultSize","Update":10154,"Value":10154,"Internal":true,"Count Failed Values":true},{"ID":98,"Name":"internal.metrics.input.bytesRead","Update":312,"Value":312,"Internal":true,"Count Failed Values":true},{"ID":99,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0},"Task Metrics":{"Executor Deserialize Time":11,"Executor Deserialize CPU Time":7341340,"Executor Run Time":11,"Executor CPU Time":6160694,"Peak Execution Memory":0,"Result Size":10154,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":312,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":3,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":7,"Index":1,"Attempt":0,"Launch Time":1641575650525,"Executor ID":"1","Host":"host-name","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1641575650555,"Failed":false,"Killed":false,"Accumulables":[{"ID":77,"Name":"internal.metrics.executorDeserializeTime","Update":12,"Value":23,"Internal":true,"Count Failed Values":true},{"ID":78,"Name":"internal.metrics.executorDeserializeCpuTime","Update":3787108,"Value":11128448,"Internal":true,"Count Failed Values":true},{"ID":79,"Name":"internal.metrics.executorRunTime","Update":10,"Value":21,"Internal":true,"Count Failed Values":true},{"ID":80,"Name":"internal.metrics.executorCpuTime","Update":1814868,"Value":7975562,"Internal":true,"Count Failed Values":true},{"ID":81,"Name":"internal.metrics.resultSize","Update":10154,"Value":20308,"Internal":true,"Count Failed Values":true},{"ID":98,"Name":"internal.metrics.input.bytesRead","Update":288,"Value":600,"Internal":true,"Count Failed Values":true},{"ID":99,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":2,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0},"Task Metrics":{"Executor Deserialize Time":12,"Executor Deserialize CPU Time":3787108,"Executor Run Time":10,"Executor CPU Time":1814868,"Peak Execution Memory":0,"Result Size":10154,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":288,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":3,"Stage Attempt ID":0,"Stage Name":"treeAggregate at RDDLossFunction.scala:61","Number of Tasks":2,"RDD Info":[{"RDD ID":16,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"25\",\"name\":\"treeAggregate\"}","Callsite":"treeAggregate at RDDLossFunction.scala:61","Parent IDs":[13],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":6,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"4\",\"name\":\"LocalTableScan\"}","Callsite":"rdd at Predictor.scala:81","Parent IDs":[5],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":13,"Name":"training blocks (blockSizeInMB=1.0)","Scope":"{\"id\":\"16\",\"name\":\"mapPartitions\"}","Callsite":"mapPartitions at Instance.scala:186","Parent IDs":[12],"Storage Level":{"Use Disk":true,"Use Memory":true,"Deserialized":true,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":10,"Name":"training instances","Scope":"{\"id\":\"6\",\"name\":\"map\"}","Callsite":"map at Predictor.scala:81","Parent IDs":[9],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":9,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"5\",\"name\":\"mapPartitions\"}","Callsite":"rdd at Predictor.scala:81","Parent IDs":[8],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":7,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"3\",\"name\":\"DeserializeToObject\"}","Callsite":"rdd at Predictor.scala:81","Parent IDs":[6],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":12,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"15\",\"name\":\"mapPartitions\"}","Callsite":"mapPartitions at LogisticRegression.scala:944","Parent IDs":[10],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":5,"Name":"ParallelCollectionRDD","Scope":"{\"id\":\"4\",\"name\":\"LocalTableScan\"}","Callsite":"rdd at Predictor.scala:81","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":8,"Name":"SQLExecutionRDD","Callsite":"rdd at Predictor.scala:81","Parent IDs":[7],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.rdd.RDD.treeAggregate(RDD.scala:1222)\norg.apache.spark.ml.optim.loss.RDDLossFunction.calculate(RDDLossFunction.scala:61)\norg.apache.spark.ml.optim.loss.RDDLossFunction.calculate(RDDLossFunction.scala:47)\nbreeze.optimize.CachedDiffFunction.calculate(CachedDiffFunction.scala:24)\nbreeze.optimize.LineSearch$$anon$1.calculate(LineSearch.scala:52)\nbreeze.optimize.LineSearch$$anon$1.calculate(LineSearch.scala:31)\nbreeze.optimize.StrongWolfeLineSearch.phi$1(StrongWolfe.scala:76)\nbreeze.optimize.StrongWolfeLineSearch.$anonfun$minimizeWithBound$7(StrongWolfe.scala:152)\nscala.collection.immutable.Range.foreach$mVc$sp(Range.scala:158)\nbreeze.optimize.StrongWolfeLineSearch.minimizeWithBound(StrongWolfe.scala:151)\nbreeze.optimize.StrongWolfeLineSearch.minimize(StrongWolfe.scala:62)\nbreeze.optimize.LBFGS.determineStepSize(LBFGS.scala:82)\nbreeze.optimize.LBFGS.determineStepSize(LBFGS.scala:38)\nbreeze.optimize.FirstOrderMinimizer.$anonfun$infiniteIterations$1(FirstOrderMinimizer.scala:61)\nscala.collection.Iterator$$anon$7.next(Iterator.scala:140)\nbreeze.util.IteratorImplicits$RichIterator$$anon$2.next(Implicits.scala:74)\norg.apache.spark.ml.classification.LogisticRegression.trainImpl(LogisticRegression.scala:971)\norg.apache.spark.ml.classification.LogisticRegression.$anonfun$train$1(LogisticRegression.scala:627)\norg.apache.spark.ml.util.Instrumentation$.$anonfun$instrumented$1(Instrumentation.scala:191)\nscala.util.Try$.apply(Try.scala:213)","Submission Time":1641575650519,"Completion Time":1641575650556,"Accumulables":[{"ID":77,"Name":"internal.metrics.executorDeserializeTime","Value":23,"Internal":true,"Count Failed Values":true},{"ID":78,"Name":"internal.metrics.executorDeserializeCpuTime","Value":11128448,"Internal":true,"Count Failed Values":true},{"ID":79,"Name":"internal.metrics.executorRunTime","Value":21,"Internal":true,"Count Failed Values":true},{"ID":80,"Name":"internal.metrics.executorCpuTime","Value":7975562,"Internal":true,"Count Failed Values":true},{"ID":81,"Name":"internal.metrics.resultSize","Value":20308,"Internal":true,"Count Failed Values":true},{"ID":98,"Name":"internal.metrics.input.bytesRead","Value":600,"Internal":true,"Count Failed Values":true},{"ID":99,"Name":"internal.metrics.input.recordsRead","Value":2,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0}}
{"Event":"SparkListenerJobEnd","Job ID":3,"Completion Time":1641575650556,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"SparkListenerJobStart","Job ID":4,"Submission Time":1641575650575,"Stage Infos":[{"Stage ID":4,"Stage Attempt ID":0,"Stage Name":"treeAggregate at RDDLossFunction.scala:61","Number of Tasks":2,"RDD Info":[{"RDD ID":17,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"28\",\"name\":\"treeAggregate\"}","Callsite":"treeAggregate at RDDLossFunction.scala:61","Parent IDs":[13],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":6,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"4\",\"name\":\"LocalTableScan\"}","Callsite":"rdd at Predictor.scala:81","Parent IDs":[5],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":13,"Name":"training blocks (blockSizeInMB=1.0)","Scope":"{\"id\":\"16\",\"name\":\"mapPartitions\"}","Callsite":"mapPartitions at Instance.scala:186","Parent IDs":[12],"Storage Level":{"Use Disk":true,"Use Memory":true,"Deserialized":true,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":10,"Name":"training instances","Scope":"{\"id\":\"6\",\"name\":\"map\"}","Callsite":"map at Predictor.scala:81","Parent IDs":[9],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":9,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"5\",\"name\":\"mapPartitions\"}","Callsite":"rdd at Predictor.scala:81","Parent IDs":[8],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":7,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"3\",\"name\":\"DeserializeToObject\"}","Callsite":"rdd at Predictor.scala:81","Parent IDs":[6],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":12,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"15\",\"name\":\"mapPartitions\"}","Callsite":"mapPartitions at LogisticRegression.scala:944","Parent IDs":[10],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":5,"Name":"ParallelCollectionRDD","Scope":"{\"id\":\"4\",\"name\":\"LocalTableScan\"}","Callsite":"rdd at Predictor.scala:81","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":8,"Name":"SQLExecutionRDD","Callsite":"rdd at Predictor.scala:81","Parent IDs":[7],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.rdd.RDD.treeAggregate(RDD.scala:1222)\norg.apache.spark.ml.optim.loss.RDDLossFunction.calculate(RDDLossFunction.scala:61)\norg.apache.spark.ml.optim.loss.RDDLossFunction.calculate(RDDLossFunction.scala:47)\nbreeze.optimize.CachedDiffFunction.calculate(CachedDiffFunction.scala:24)\nbreeze.optimize.LineSearch$$anon$1.calculate(LineSearch.scala:52)\nbreeze.optimize.LineSearch$$anon$1.calculate(LineSearch.scala:31)\nbreeze.optimize.StrongWolfeLineSearch.phi$1(StrongWolfe.scala:76)\nbreeze.optimize.StrongWolfeLineSearch.$anonfun$minimizeWithBound$7(StrongWolfe.scala:152)\nscala.collection.immutable.Range.foreach$mVc$sp(Range.scala:158)\nbreeze.optimize.StrongWolfeLineSearch.minimizeWithBound(StrongWolfe.scala:151)\nbreeze.optimize.StrongWolfeLineSearch.minimize(StrongWolfe.scala:62)\nbreeze.optimize.LBFGS.determineStepSize(LBFGS.scala:82)\nbreeze.optimize.LBFGS.determineStepSize(LBFGS.scala:38)\nbreeze.optimize.FirstOrderMinimizer.$anonfun$infiniteIterations$1(FirstOrderMinimizer.scala:61)\nscala.collection.Iterator$$anon$7.next(Iterator.scala:140)\nbreeze.util.IteratorImplicits$RichIterator$$anon$2.next(Implicits.scala:74)\norg.apache.spark.ml.classification.LogisticRegression.trainImpl(LogisticRegression.scala:971)\norg.apache.spark.ml.classification.LogisticRegression.$anonfun$train$1(LogisticRegression.scala:627)\norg.apache.spark.ml.util.Instrumentation$.$anonfun$instrumented$1(Instrumentation.scala:191)\nscala.util.Try$.apply(Try.scala:213)","Accumulables":[],"Resource Profile Id":0}],"Stage IDs":[4],"Properties":{"spark.rdd.scope":"{\"id\":\"28\",\"name\":\"treeAggregate\"}","spark.rdd.scope.noOverride":"true"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":4,"Stage Attempt ID":0,"Stage Name":"treeAggregate at RDDLossFunction.scala:61","Number of Tasks":2,"RDD Info":[{"RDD ID":17,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"28\",\"name\":\"treeAggregate\"}","Callsite":"treeAggregate at RDDLossFunction.scala:61","Parent IDs":[13],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":6,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"4\",\"name\":\"LocalTableScan\"}","Callsite":"rdd at Predictor.scala:81","Parent IDs":[5],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":13,"Name":"training blocks (blockSizeInMB=1.0)","Scope":"{\"id\":\"16\",\"name\":\"mapPartitions\"}","Callsite":"mapPartitions at Instance.scala:186","Parent IDs":[12],"Storage Level":{"Use Disk":true,"Use Memory":true,"Deserialized":true,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":10,"Name":"training instances","Scope":"{\"id\":\"6\",\"name\":\"map\"}","Callsite":"map at Predictor.scala:81","Parent IDs":[9],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":9,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"5\",\"name\":\"mapPartitions\"}","Callsite":"rdd at Predictor.scala:81","Parent IDs":[8],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":7,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"3\",\"name\":\"DeserializeToObject\"}","Callsite":"rdd at Predictor.scala:81","Parent IDs":[6],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":12,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"15\",\"name\":\"mapPartitions\"}","Callsite":"mapPartitions at LogisticRegression.scala:944","Parent IDs":[10],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":5,"Name":"ParallelCollectionRDD","Scope":"{\"id\":\"4\",\"name\":\"LocalTableScan\"}","Callsite":"rdd at Predictor.scala:81","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":8,"Name":"SQLExecutionRDD","Callsite":"rdd at Predictor.scala:81","Parent IDs":[7],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.rdd.RDD.treeAggregate(RDD.scala:1222)\norg.apache.spark.ml.optim.loss.RDDLossFunction.calculate(RDDLossFunction.scala:61)\norg.apache.spark.ml.optim.loss.RDDLossFunction.calculate(RDDLossFunction.scala:47)\nbreeze.optimize.CachedDiffFunction.calculate(CachedDiffFunction.scala:24)\nbreeze.optimize.LineSearch$$anon$1.calculate(LineSearch.scala:52)\nbreeze.optimize.LineSearch$$anon$1.calculate(LineSearch.scala:31)\nbreeze.optimize.StrongWolfeLineSearch.phi$1(StrongWolfe.scala:76)\nbreeze.optimize.StrongWolfeLineSearch.$anonfun$minimizeWithBound$7(StrongWolfe.scala:152)\nscala.collection.immutable.Range.foreach$mVc$sp(Range.scala:158)\nbreeze.optimize.StrongWolfeLineSearch.minimizeWithBound(StrongWolfe.scala:151)\nbreeze.optimize.StrongWolfeLineSearch.minimize(StrongWolfe.scala:62)\nbreeze.optimize.LBFGS.determineStepSize(LBFGS.scala:82)\nbreeze.optimize.LBFGS.determineStepSize(LBFGS.scala:38)\nbreeze.optimize.FirstOrderMinimizer.$anonfun$infiniteIterations$1(FirstOrderMinimizer.scala:61)\nscala.collection.Iterator$$anon$7.next(Iterator.scala:140)\nbreeze.util.IteratorImplicits$RichIterator$$anon$2.next(Implicits.scala:74)\norg.apache.spark.ml.classification.LogisticRegression.trainImpl(LogisticRegression.scala:971)\norg.apache.spark.ml.classification.LogisticRegression.$anonfun$train$1(LogisticRegression.scala:627)\norg.apache.spark.ml.util.Instrumentation$.$anonfun$instrumented$1(Instrumentation.scala:191)\nscala.util.Try$.apply(Try.scala:213)","Submission Time":1641575650577,"Accumulables":[],"Resource Profile Id":0},"Properties":{"resource.executor.cores":"2","spark.rdd.scope":"{\"id\":\"28\",\"name\":\"treeAggregate\"}","spark.rdd.scope.noOverride":"true"}}
{"Event":"SparkListenerTaskStart","Stage ID":4,"Stage Attempt ID":0,"Task Info":{"Task ID":8,"Index":0,"Attempt":0,"Launch Time":1641575650582,"Executor ID":"1","Host":"host-name","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskStart","Stage ID":4,"Stage Attempt ID":0,"Task Info":{"Task ID":9,"Index":1,"Attempt":0,"Launch Time":1641575650583,"Executor ID":"1","Host":"host-name","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":4,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":8,"Index":0,"Attempt":0,"Launch Time":1641575650582,"Executor ID":"1","Host":"host-name","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1641575650612,"Failed":false,"Killed":false,"Accumulables":[{"ID":102,"Name":"internal.metrics.executorDeserializeTime","Update":12,"Value":12,"Internal":true,"Count Failed Values":true},{"ID":103,"Name":"internal.metrics.executorDeserializeCpuTime","Update":8318087,"Value":8318087,"Internal":true,"Count Failed Values":true},{"ID":104,"Name":"internal.metrics.executorRunTime","Update":11,"Value":11,"Internal":true,"Count Failed Values":true},{"ID":105,"Name":"internal.metrics.executorCpuTime","Update":1432901,"Value":1432901,"Internal":true,"Count Failed Values":true},{"ID":106,"Name":"internal.metrics.resultSize","Update":10154,"Value":10154,"Internal":true,"Count Failed Values":true},{"ID":123,"Name":"internal.metrics.input.bytesRead","Update":312,"Value":312,"Internal":true,"Count Failed Values":true},{"ID":124,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0},"Task Metrics":{"Executor Deserialize Time":12,"Executor Deserialize CPU Time":8318087,"Executor Run Time":11,"Executor CPU Time":1432901,"Peak Execution Memory":0,"Result Size":10154,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":312,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":4,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":9,"Index":1,"Attempt":0,"Launch Time":1641575650583,"Executor ID":"1","Host":"host-name","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1641575650612,"Failed":false,"Killed":false,"Accumulables":[{"ID":102,"Name":"internal.metrics.executorDeserializeTime","Update":12,"Value":24,"Internal":true,"Count Failed Values":true},{"ID":103,"Name":"internal.metrics.executorDeserializeCpuTime","Update":3486493,"Value":11804580,"Internal":true,"Count Failed Values":true},{"ID":104,"Name":"internal.metrics.executorRunTime","Update":11,"Value":22,"Internal":true,"Count Failed Values":true},{"ID":105,"Name":"internal.metrics.executorCpuTime","Update":6610156,"Value":8043057,"Internal":true,"Count Failed Values":true},{"ID":106,"Name":"internal.metrics.resultSize","Update":10154,"Value":20308,"Internal":true,"Count Failed Values":true},{"ID":123,"Name":"internal.metrics.input.bytesRead","Update":288,"Value":600,"Internal":true,"Count Failed Values":true},{"ID":124,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":2,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0},"Task Metrics":{"Executor Deserialize Time":12,"Executor Deserialize CPU Time":3486493,"Executor Run Time":11,"Executor CPU Time":6610156,"Peak Execution Memory":0,"Result Size":10154,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":288,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":4,"Stage Attempt ID":0,"Stage Name":"treeAggregate at RDDLossFunction.scala:61","Number of Tasks":2,"RDD Info":[{"RDD ID":17,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"28\",\"name\":\"treeAggregate\"}","Callsite":"treeAggregate at RDDLossFunction.scala:61","Parent IDs":[13],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":6,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"4\",\"name\":\"LocalTableScan\"}","Callsite":"rdd at Predictor.scala:81","Parent IDs":[5],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":13,"Name":"training blocks (blockSizeInMB=1.0)","Scope":"{\"id\":\"16\",\"name\":\"mapPartitions\"}","Callsite":"mapPartitions at Instance.scala:186","Parent IDs":[12],"Storage Level":{"Use Disk":true,"Use Memory":true,"Deserialized":true,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":10,"Name":"training instances","Scope":"{\"id\":\"6\",\"name\":\"map\"}","Callsite":"map at Predictor.scala:81","Parent IDs":[9],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":9,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"5\",\"name\":\"mapPartitions\"}","Callsite":"rdd at Predictor.scala:81","Parent IDs":[8],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":7,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"3\",\"name\":\"DeserializeToObject\"}","Callsite":"rdd at Predictor.scala:81","Parent IDs":[6],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":12,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"15\",\"name\":\"mapPartitions\"}","Callsite":"mapPartitions at LogisticRegression.scala:944","Parent IDs":[10],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":5,"Name":"ParallelCollectionRDD","Scope":"{\"id\":\"4\",\"name\":\"LocalTableScan\"}","Callsite":"rdd at Predictor.scala:81","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":8,"Name":"SQLExecutionRDD","Callsite":"rdd at Predictor.scala:81","Parent IDs":[7],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.rdd.RDD.treeAggregate(RDD.scala:1222)\norg.apache.spark.ml.optim.loss.RDDLossFunction.calculate(RDDLossFunction.scala:61)\norg.apache.spark.ml.optim.loss.RDDLossFunction.calculate(RDDLossFunction.scala:47)\nbreeze.optimize.CachedDiffFunction.calculate(CachedDiffFunction.scala:24)\nbreeze.optimize.LineSearch$$anon$1.calculate(LineSearch.scala:52)\nbreeze.optimize.LineSearch$$anon$1.calculate(LineSearch.scala:31)\nbreeze.optimize.StrongWolfeLineSearch.phi$1(StrongWolfe.scala:76)\nbreeze.optimize.StrongWolfeLineSearch.$anonfun$minimizeWithBound$7(StrongWolfe.scala:152)\nscala.collection.immutable.Range.foreach$mVc$sp(Range.scala:158)\nbreeze.optimize.StrongWolfeLineSearch.minimizeWithBound(StrongWolfe.scala:151)\nbreeze.optimize.StrongWolfeLineSearch.minimize(StrongWolfe.scala:62)\nbreeze.optimize.LBFGS.determineStepSize(LBFGS.scala:82)\nbreeze.optimize.LBFGS.determineStepSize(LBFGS.scala:38)\nbreeze.optimize.FirstOrderMinimizer.$anonfun$infiniteIterations$1(FirstOrderMinimizer.scala:61)\nscala.collection.Iterator$$anon$7.next(Iterator.scala:140)\nbreeze.util.IteratorImplicits$RichIterator$$anon$2.next(Implicits.scala:74)\norg.apache.spark.ml.classification.LogisticRegression.trainImpl(LogisticRegression.scala:971)\norg.apache.spark.ml.classification.LogisticRegression.$anonfun$train$1(LogisticRegression.scala:627)\norg.apache.spark.ml.util.Instrumentation$.$anonfun$instrumented$1(Instrumentation.scala:191)\nscala.util.Try$.apply(Try.scala:213)","Submission Time":1641575650577,"Completion Time":1641575650613,"Accumulables":[{"ID":102,"Name":"internal.metrics.executorDeserializeTime","Value":24,"Internal":true,"Count Failed Values":true},{"ID":103,"Name":"internal.metrics.executorDeserializeCpuTime","Value":11804580,"Internal":true,"Count Failed Values":true},{"ID":104,"Name":"internal.metrics.executorRunTime","Value":22,"Internal":true,"Count Failed Values":true},{"ID":105,"Name":"internal.metrics.executorCpuTime","Value":8043057,"Internal":true,"Count Failed Values":true},{"ID":106,"Name":"internal.metrics.resultSize","Value":20308,"Internal":true,"Count Failed Values":true},{"ID":123,"Name":"internal.metrics.input.bytesRead","Value":600,"Internal":true,"Count Failed Values":true},{"ID":124,"Name":"internal.metrics.input.recordsRead","Value":2,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0}}
{"Event":"SparkListenerJobEnd","Job ID":4,"Completion Time":1641575650614,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"SparkListenerJobStart","Job ID":5,"Submission Time":1641575650642,"Stage Infos":[{"Stage ID":5,"Stage Attempt ID":0,"Stage Name":"treeAggregate at RDDLossFunction.scala:61","Number of Tasks":2,"RDD Info":[{"RDD ID":18,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"31\",\"name\":\"treeAggregate\"}","Callsite":"treeAggregate at RDDLossFunction.scala:61","Parent IDs":[13],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":6,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"4\",\"name\":\"LocalTableScan\"}","Callsite":"rdd at Predictor.scala:81","Parent IDs":[5],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":13,"Name":"training blocks (blockSizeInMB=1.0)","Scope":"{\"id\":\"16\",\"name\":\"mapPartitions\"}","Callsite":"mapPartitions at Instance.scala:186","Parent IDs":[12],"Storage Level":{"Use Disk":true,"Use Memory":true,"Deserialized":true,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":10,"Name":"training instances","Scope":"{\"id\":\"6\",\"name\":\"map\"}","Callsite":"map at Predictor.scala:81","Parent IDs":[9],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":9,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"5\",\"name\":\"mapPartitions\"}","Callsite":"rdd at Predictor.scala:81","Parent IDs":[8],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":7,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"3\",\"name\":\"DeserializeToObject\"}","Callsite":"rdd at Predictor.scala:81","Parent IDs":[6],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":12,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"15\",\"name\":\"mapPartitions\"}","Callsite":"mapPartitions at LogisticRegression.scala:944","Parent IDs":[10],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":5,"Name":"ParallelCollectionRDD","Scope":"{\"id\":\"4\",\"name\":\"LocalTableScan\"}","Callsite":"rdd at Predictor.scala:81","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":8,"Name":"SQLExecutionRDD","Callsite":"rdd at Predictor.scala:81","Parent IDs":[7],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.rdd.RDD.treeAggregate(RDD.scala:1222)\norg.apache.spark.ml.optim.loss.RDDLossFunction.calculate(RDDLossFunction.scala:61)\norg.apache.spark.ml.optim.loss.RDDLossFunction.calculate(RDDLossFunction.scala:47)\nbreeze.optimize.CachedDiffFunction.calculate(CachedDiffFunction.scala:24)\nbreeze.optimize.LineSearch$$anon$1.calculate(LineSearch.scala:52)\nbreeze.optimize.LineSearch$$anon$1.calculate(LineSearch.scala:31)\nbreeze.optimize.StrongWolfeLineSearch.phi$1(StrongWolfe.scala:76)\nbreeze.optimize.StrongWolfeLineSearch.$anonfun$minimizeWithBound$7(StrongWolfe.scala:152)\nscala.collection.immutable.Range.foreach$mVc$sp(Range.scala:158)\nbreeze.optimize.StrongWolfeLineSearch.minimizeWithBound(StrongWolfe.scala:151)\nbreeze.optimize.StrongWolfeLineSearch.minimize(StrongWolfe.scala:62)\nbreeze.optimize.LBFGS.determineStepSize(LBFGS.scala:82)\nbreeze.optimize.LBFGS.determineStepSize(LBFGS.scala:38)\nbreeze.optimize.FirstOrderMinimizer.$anonfun$infiniteIterations$1(FirstOrderMinimizer.scala:61)\nscala.collection.Iterator$$anon$7.next(Iterator.scala:140)\nbreeze.util.IteratorImplicits$RichIterator$$anon$2.next(Implicits.scala:74)\norg.apache.spark.ml.classification.LogisticRegression.trainImpl(LogisticRegression.scala:971)\norg.apache.spark.ml.classification.LogisticRegression.$anonfun$train$1(LogisticRegression.scala:627)\norg.apache.spark.ml.util.Instrumentation$.$anonfun$instrumented$1(Instrumentation.scala:191)\nscala.util.Try$.apply(Try.scala:213)","Accumulables":[],"Resource Profile Id":0}],"Stage IDs":[5],"Properties":{"spark.rdd.scope":"{\"id\":\"31\",\"name\":\"treeAggregate\"}","spark.rdd.scope.noOverride":"true"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":5,"Stage Attempt ID":0,"Stage Name":"treeAggregate at RDDLossFunction.scala:61","Number of Tasks":2,"RDD Info":[{"RDD ID":18,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"31\",\"name\":\"treeAggregate\"}","Callsite":"treeAggregate at RDDLossFunction.scala:61","Parent IDs":[13],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":6,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"4\",\"name\":\"LocalTableScan\"}","Callsite":"rdd at Predictor.scala:81","Parent IDs":[5],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":13,"Name":"training blocks (blockSizeInMB=1.0)","Scope":"{\"id\":\"16\",\"name\":\"mapPartitions\"}","Callsite":"mapPartitions at Instance.scala:186","Parent IDs":[12],"Storage Level":{"Use Disk":true,"Use Memory":true,"Deserialized":true,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":10,"Name":"training instances","Scope":"{\"id\":\"6\",\"name\":\"map\"}","Callsite":"map at Predictor.scala:81","Parent IDs":[9],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":9,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"5\",\"name\":\"mapPartitions\"}","Callsite":"rdd at Predictor.scala:81","Parent IDs":[8],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":7,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"3\",\"name\":\"DeserializeToObject\"}","Callsite":"rdd at Predictor.scala:81","Parent IDs":[6],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":12,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"15\",\"name\":\"mapPartitions\"}","Callsite":"mapPartitions at LogisticRegression.scala:944","Parent IDs":[10],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":5,"Name":"ParallelCollectionRDD","Scope":"{\"id\":\"4\",\"name\":\"LocalTableScan\"}","Callsite":"rdd at Predictor.scala:81","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":8,"Name":"SQLExecutionRDD","Callsite":"rdd at Predictor.scala:81","Parent IDs":[7],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.rdd.RDD.treeAggregate(RDD.scala:1222)\norg.apache.spark.ml.optim.loss.RDDLossFunction.calculate(RDDLossFunction.scala:61)\norg.apache.spark.ml.optim.loss.RDDLossFunction.calculate(RDDLossFunction.scala:47)\nbreeze.optimize.CachedDiffFunction.calculate(CachedDiffFunction.scala:24)\nbreeze.optimize.LineSearch$$anon$1.calculate(LineSearch.scala:52)\nbreeze.optimize.LineSearch$$anon$1.calculate(LineSearch.scala:31)\nbreeze.optimize.StrongWolfeLineSearch.phi$1(StrongWolfe.scala:76)\nbreeze.optimize.StrongWolfeLineSearch.$anonfun$minimizeWithBound$7(StrongWolfe.scala:152)\nscala.collection.immutable.Range.foreach$mVc$sp(Range.scala:158)\nbreeze.optimize.StrongWolfeLineSearch.minimizeWithBound(StrongWolfe.scala:151)\nbreeze.optimize.StrongWolfeLineSearch.minimize(StrongWolfe.scala:62)\nbreeze.optimize.LBFGS.determineStepSize(LBFGS.scala:82)\nbreeze.optimize.LBFGS.determineStepSize(LBFGS.scala:38)\nbreeze.optimize.FirstOrderMinimizer.$anonfun$infiniteIterations$1(FirstOrderMinimizer.scala:61)\nscala.collection.Iterator$$anon$7.next(Iterator.scala:140)\nbreeze.util.IteratorImplicits$RichIterator$$anon$2.next(Implicits.scala:74)\norg.apache.spark.ml.classification.LogisticRegression.trainImpl(LogisticRegression.scala:971)\norg.apache.spark.ml.classification.LogisticRegression.$anonfun$train$1(LogisticRegression.scala:627)\norg.apache.spark.ml.util.Instrumentation$.$anonfun$instrumented$1(Instrumentation.scala:191)\nscala.util.Try$.apply(Try.scala:213)","Submission Time":1641575650643,"Accumulables":[],"Resource Profile Id":0},"Properties":{"resource.executor.cores":"2","spark.rdd.scope":"{\"id\":\"31\",\"name\":\"treeAggregate\"}","spark.rdd.scope.noOverride":"true"}}
{"Event":"SparkListenerTaskStart","Stage ID":5,"Stage Attempt ID":0,"Task Info":{"Task ID":10,"Index":0,"Attempt":0,"Launch Time":1641575650651,"Executor ID":"1","Host":"host-name","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskStart","Stage ID":5,"Stage Attempt ID":0,"Task Info":{"Task ID":11,"Index":1,"Attempt":0,"Launch Time":1641575650651,"Executor ID":"1","Host":"host-name","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":5,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":10,"Index":0,"Attempt":0,"Launch Time":1641575650651,"Executor ID":"1","Host":"host-name","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1641575650682,"Failed":false,"Killed":false,"Accumulables":[{"ID":127,"Name":"internal.metrics.executorDeserializeTime","Update":13,"Value":13,"Internal":true,"Count Failed Values":true},{"ID":128,"Name":"internal.metrics.executorDeserializeCpuTime","Update":4161986,"Value":4161986,"Internal":true,"Count Failed Values":true},{"ID":129,"Name":"internal.metrics.executorRunTime","Update":11,"Value":11,"Internal":true,"Count Failed Values":true},{"ID":130,"Name":"internal.metrics.executorCpuTime","Update":1541665,"Value":1541665,"Internal":true,"Count Failed Values":true},{"ID":131,"Name":"internal.metrics.resultSize","Update":10154,"Value":10154,"Internal":true,"Count Failed Values":true},{"ID":148,"Name":"internal.metrics.input.bytesRead","Update":312,"Value":312,"Internal":true,"Count Failed Values":true},{"ID":149,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0},"Task Metrics":{"Executor Deserialize Time":13,"Executor Deserialize CPU Time":4161986,"Executor Run Time":11,"Executor CPU Time":1541665,"Peak Execution Memory":0,"Result Size":10154,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":312,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":5,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":11,"Index":1,"Attempt":0,"Launch Time":1641575650651,"Executor ID":"1","Host":"host-name","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1641575650683,"Failed":false,"Killed":false,"Accumulables":[{"ID":127,"Name":"internal.metrics.executorDeserializeTime","Update":13,"Value":26,"Internal":true,"Count Failed Values":true},{"ID":128,"Name":"internal.metrics.executorDeserializeCpuTime","Update":8823958,"Value":12985944,"Internal":true,"Count Failed Values":true},{"ID":129,"Name":"internal.metrics.executorRunTime","Update":11,"Value":22,"Internal":true,"Count Failed Values":true},{"ID":130,"Name":"internal.metrics.executorCpuTime","Update":6218362,"Value":7760027,"Internal":true,"Count Failed Values":true},{"ID":131,"Name":"internal.metrics.resultSize","Update":10154,"Value":20308,"Internal":true,"Count Failed Values":true},{"ID":148,"Name":"internal.metrics.input.bytesRead","Update":288,"Value":600,"Internal":true,"Count Failed Values":true},{"ID":149,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":2,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0},"Task Metrics":{"Executor Deserialize Time":13,"Executor Deserialize CPU Time":8823958,"Executor Run Time":11,"Executor CPU Time":6218362,"Peak Execution Memory":0,"Result Size":10154,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":288,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":5,"Stage Attempt ID":0,"Stage Name":"treeAggregate at RDDLossFunction.scala:61","Number of Tasks":2,"RDD Info":[{"RDD ID":18,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"31\",\"name\":\"treeAggregate\"}","Callsite":"treeAggregate at RDDLossFunction.scala:61","Parent IDs":[13],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":6,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"4\",\"name\":\"LocalTableScan\"}","Callsite":"rdd at Predictor.scala:81","Parent IDs":[5],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":13,"Name":"training blocks (blockSizeInMB=1.0)","Scope":"{\"id\":\"16\",\"name\":\"mapPartitions\"}","Callsite":"mapPartitions at Instance.scala:186","Parent IDs":[12],"Storage Level":{"Use Disk":true,"Use Memory":true,"Deserialized":true,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":10,"Name":"training instances","Scope":"{\"id\":\"6\",\"name\":\"map\"}","Callsite":"map at Predictor.scala:81","Parent IDs":[9],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":9,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"5\",\"name\":\"mapPartitions\"}","Callsite":"rdd at Predictor.scala:81","Parent IDs":[8],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":7,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"3\",\"name\":\"DeserializeToObject\"}","Callsite":"rdd at Predictor.scala:81","Parent IDs":[6],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":12,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"15\",\"name\":\"mapPartitions\"}","Callsite":"mapPartitions at LogisticRegression.scala:944","Parent IDs":[10],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":5,"Name":"ParallelCollectionRDD","Scope":"{\"id\":\"4\",\"name\":\"LocalTableScan\"}","Callsite":"rdd at Predictor.scala:81","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":8,"Name":"SQLExecutionRDD","Callsite":"rdd at Predictor.scala:81","Parent IDs":[7],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.rdd.RDD.treeAggregate(RDD.scala:1222)\norg.apache.spark.ml.optim.loss.RDDLossFunction.calculate(RDDLossFunction.scala:61)\norg.apache.spark.ml.optim.loss.RDDLossFunction.calculate(RDDLossFunction.scala:47)\nbreeze.optimize.CachedDiffFunction.calculate(CachedDiffFunction.scala:24)\nbreeze.optimize.LineSearch$$anon$1.calculate(LineSearch.scala:52)\nbreeze.optimize.LineSearch$$anon$1.calculate(LineSearch.scala:31)\nbreeze.optimize.StrongWolfeLineSearch.phi$1(StrongWolfe.scala:76)\nbreeze.optimize.StrongWolfeLineSearch.$anonfun$minimizeWithBound$7(StrongWolfe.scala:152)\nscala.collection.immutable.Range.foreach$mVc$sp(Range.scala:158)\nbreeze.optimize.StrongWolfeLineSearch.minimizeWithBound(StrongWolfe.scala:151)\nbreeze.optimize.StrongWolfeLineSearch.minimize(StrongWolfe.scala:62)\nbreeze.optimize.LBFGS.determineStepSize(LBFGS.scala:82)\nbreeze.optimize.LBFGS.determineStepSize(LBFGS.scala:38)\nbreeze.optimize.FirstOrderMinimizer.$anonfun$infiniteIterations$1(FirstOrderMinimizer.scala:61)\nscala.collection.Iterator$$anon$7.next(Iterator.scala:140)\nbreeze.util.IteratorImplicits$RichIterator$$anon$2.next(Implicits.scala:74)\norg.apache.spark.ml.classification.LogisticRegression.trainImpl(LogisticRegression.scala:971)\norg.apache.spark.ml.classification.LogisticRegression.$anonfun$train$1(LogisticRegression.scala:627)\norg.apache.spark.ml.util.Instrumentation$.$anonfun$instrumented$1(Instrumentation.scala:191)\nscala.util.Try$.apply(Try.scala:213)","Submission Time":1641575650643,"Completion Time":1641575650683,"Accumulables":[{"ID":127,"Name":"internal.metrics.executorDeserializeTime","Value":26,"Internal":true,"Count Failed Values":true},{"ID":128,"Name":"internal.metrics.executorDeserializeCpuTime","Value":12985944,"Internal":true,"Count Failed Values":true},{"ID":129,"Name":"internal.metrics.executorRunTime","Value":22,"Internal":true,"Count Failed Values":true},{"ID":130,"Name":"internal.metrics.executorCpuTime","Value":7760027,"Internal":true,"Count Failed Values":true},{"ID":131,"Name":"internal.metrics.resultSize","Value":20308,"Internal":true,"Count Failed Values":true},{"ID":148,"Name":"internal.metrics.input.bytesRead","Value":600,"Internal":true,"Count Failed Values":true},{"ID":149,"Name":"internal.metrics.input.recordsRead","Value":2,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0}}
{"Event":"SparkListenerJobEnd","Job ID":5,"Completion Time":1641575650684,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"SparkListenerJobStart","Job ID":6,"Submission Time":1641575650703,"Stage Infos":[{"Stage ID":6,"Stage Attempt ID":0,"Stage Name":"treeAggregate at RDDLossFunction.scala:61","Number of Tasks":2,"RDD Info":[{"RDD ID":19,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"34\",\"name\":\"treeAggregate\"}","Callsite":"treeAggregate at RDDLossFunction.scala:61","Parent IDs":[13],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":6,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"4\",\"name\":\"LocalTableScan\"}","Callsite":"rdd at Predictor.scala:81","Parent IDs":[5],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":13,"Name":"training blocks (blockSizeInMB=1.0)","Scope":"{\"id\":\"16\",\"name\":\"mapPartitions\"}","Callsite":"mapPartitions at Instance.scala:186","Parent IDs":[12],"Storage Level":{"Use Disk":true,"Use Memory":true,"Deserialized":true,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":10,"Name":"training instances","Scope":"{\"id\":\"6\",\"name\":\"map\"}","Callsite":"map at Predictor.scala:81","Parent IDs":[9],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":9,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"5\",\"name\":\"mapPartitions\"}","Callsite":"rdd at Predictor.scala:81","Parent IDs":[8],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":7,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"3\",\"name\":\"DeserializeToObject\"}","Callsite":"rdd at Predictor.scala:81","Parent IDs":[6],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":12,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"15\",\"name\":\"mapPartitions\"}","Callsite":"mapPartitions at LogisticRegression.scala:944","Parent IDs":[10],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":5,"Name":"ParallelCollectionRDD","Scope":"{\"id\":\"4\",\"name\":\"LocalTableScan\"}","Callsite":"rdd at Predictor.scala:81","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":8,"Name":"SQLExecutionRDD","Callsite":"rdd at Predictor.scala:81","Parent IDs":[7],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.rdd.RDD.treeAggregate(RDD.scala:1222)\norg.apache.spark.ml.optim.loss.RDDLossFunction.calculate(RDDLossFunction.scala:61)\norg.apache.spark.ml.optim.loss.RDDLossFunction.calculate(RDDLossFunction.scala:47)\nbreeze.optimize.CachedDiffFunction.calculate(CachedDiffFunction.scala:24)\nbreeze.optimize.LineSearch$$anon$1.calculate(LineSearch.scala:52)\nbreeze.optimize.LineSearch$$anon$1.calculate(LineSearch.scala:31)\nbreeze.optimize.StrongWolfeLineSearch.phi$1(StrongWolfe.scala:76)\nbreeze.optimize.StrongWolfeLineSearch.$anonfun$minimizeWithBound$7(StrongWolfe.scala:152)\nscala.collection.immutable.Range.foreach$mVc$sp(Range.scala:158)\nbreeze.optimize.StrongWolfeLineSearch.minimizeWithBound(StrongWolfe.scala:151)\nbreeze.optimize.StrongWolfeLineSearch.minimize(StrongWolfe.scala:62)\nbreeze.optimize.LBFGS.determineStepSize(LBFGS.scala:82)\nbreeze.optimize.LBFGS.determineStepSize(LBFGS.scala:38)\nbreeze.optimize.FirstOrderMinimizer.$anonfun$infiniteIterations$1(FirstOrderMinimizer.scala:61)\nscala.collection.Iterator$$anon$7.next(Iterator.scala:140)\nbreeze.util.IteratorImplicits$RichIterator$$anon$2.next(Implicits.scala:74)\norg.apache.spark.ml.classification.LogisticRegression.trainImpl(LogisticRegression.scala:971)\norg.apache.spark.ml.classification.LogisticRegression.$anonfun$train$1(LogisticRegression.scala:627)\norg.apache.spark.ml.util.Instrumentation$.$anonfun$instrumented$1(Instrumentation.scala:191)\nscala.util.Try$.apply(Try.scala:213)","Accumulables":[],"Resource Profile Id":0}],"Stage IDs":[6],"Properties":{"spark.rdd.scope":"{\"id\":\"34\",\"name\":\"treeAggregate\"}","spark.rdd.scope.noOverride":"true"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":6,"Stage Attempt ID":0,"Stage Name":"treeAggregate at RDDLossFunction.scala:61","Number of Tasks":2,"RDD Info":[{"RDD ID":19,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"34\",\"name\":\"treeAggregate\"}","Callsite":"treeAggregate at RDDLossFunction.scala:61","Parent IDs":[13],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":6,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"4\",\"name\":\"LocalTableScan\"}","Callsite":"rdd at Predictor.scala:81","Parent IDs":[5],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":13,"Name":"training blocks (blockSizeInMB=1.0)","Scope":"{\"id\":\"16\",\"name\":\"mapPartitions\"}","Callsite":"mapPartitions at Instance.scala:186","Parent IDs":[12],"Storage Level":{"Use Disk":true,"Use Memory":true,"Deserialized":true,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":10,"Name":"training instances","Scope":"{\"id\":\"6\",\"name\":\"map\"}","Callsite":"map at Predictor.scala:81","Parent IDs":[9],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":9,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"5\",\"name\":\"mapPartitions\"}","Callsite":"rdd at Predictor.scala:81","Parent IDs":[8],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":7,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"3\",\"name\":\"DeserializeToObject\"}","Callsite":"rdd at Predictor.scala:81","Parent IDs":[6],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":12,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"15\",\"name\":\"mapPartitions\"}","Callsite":"mapPartitions at LogisticRegression.scala:944","Parent IDs":[10],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":5,"Name":"ParallelCollectionRDD","Scope":"{\"id\":\"4\",\"name\":\"LocalTableScan\"}","Callsite":"rdd at Predictor.scala:81","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":8,"Name":"SQLExecutionRDD","Callsite":"rdd at Predictor.scala:81","Parent IDs":[7],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.rdd.RDD.treeAggregate(RDD.scala:1222)\norg.apache.spark.ml.optim.loss.RDDLossFunction.calculate(RDDLossFunction.scala:61)\norg.apache.spark.ml.optim.loss.RDDLossFunction.calculate(RDDLossFunction.scala:47)\nbreeze.optimize.CachedDiffFunction.calculate(CachedDiffFunction.scala:24)\nbreeze.optimize.LineSearch$$anon$1.calculate(LineSearch.scala:52)\nbreeze.optimize.LineSearch$$anon$1.calculate(LineSearch.scala:31)\nbreeze.optimize.StrongWolfeLineSearch.phi$1(StrongWolfe.scala:76)\nbreeze.optimize.StrongWolfeLineSearch.$anonfun$minimizeWithBound$7(StrongWolfe.scala:152)\nscala.collection.immutable.Range.foreach$mVc$sp(Range.scala:158)\nbreeze.optimize.StrongWolfeLineSearch.minimizeWithBound(StrongWolfe.scala:151)\nbreeze.optimize.StrongWolfeLineSearch.minimize(StrongWolfe.scala:62)\nbreeze.optimize.LBFGS.determineStepSize(LBFGS.scala:82)\nbreeze.optimize.LBFGS.determineStepSize(LBFGS.scala:38)\nbreeze.optimize.FirstOrderMinimizer.$anonfun$infiniteIterations$1(FirstOrderMinimizer.scala:61)\nscala.collection.Iterator$$anon$7.next(Iterator.scala:140)\nbreeze.util.IteratorImplicits$RichIterator$$anon$2.next(Implicits.scala:74)\norg.apache.spark.ml.classification.LogisticRegression.trainImpl(LogisticRegression.scala:971)\norg.apache.spark.ml.classification.LogisticRegression.$anonfun$train$1(LogisticRegression.scala:627)\norg.apache.spark.ml.util.Instrumentation$.$anonfun$instrumented$1(Instrumentation.scala:191)\nscala.util.Try$.apply(Try.scala:213)","Submission Time":1641575650705,"Accumulables":[],"Resource Profile Id":0},"Properties":{"resource.executor.cores":"2","spark.rdd.scope":"{\"id\":\"34\",\"name\":\"treeAggregate\"}","spark.rdd.scope.noOverride":"true"}}
{"Event":"SparkListenerTaskStart","Stage ID":6,"Stage Attempt ID":0,"Task Info":{"Task ID":12,"Index":0,"Attempt":0,"Launch Time":1641575650711,"Executor ID":"1","Host":"host-name","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskStart","Stage ID":6,"Stage Attempt ID":0,"Task Info":{"Task ID":13,"Index":1,"Attempt":0,"Launch Time":1641575650711,"Executor ID":"1","Host":"host-name","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":6,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":12,"Index":0,"Attempt":0,"Launch Time":1641575650711,"Executor ID":"1","Host":"host-name","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1641575650743,"Failed":false,"Killed":false,"Accumulables":[{"ID":152,"Name":"internal.metrics.executorDeserializeTime","Update":13,"Value":13,"Internal":true,"Count Failed Values":true},{"ID":153,"Name":"internal.metrics.executorDeserializeCpuTime","Update":8446620,"Value":8446620,"Internal":true,"Count Failed Values":true},{"ID":154,"Name":"internal.metrics.executorRunTime","Update":11,"Value":11,"Internal":true,"Count Failed Values":true},{"ID":155,"Name":"internal.metrics.executorCpuTime","Update":6755203,"Value":6755203,"Internal":true,"Count Failed Values":true},{"ID":156,"Name":"internal.metrics.resultSize","Update":10154,"Value":10154,"Internal":true,"Count Failed Values":true},{"ID":173,"Name":"internal.metrics.input.bytesRead","Update":312,"Value":312,"Internal":true,"Count Failed Values":true},{"ID":174,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0},"Task Metrics":{"Executor Deserialize Time":13,"Executor Deserialize CPU Time":8446620,"Executor Run Time":11,"Executor CPU Time":6755203,"Peak Execution Memory":0,"Result Size":10154,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":312,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":6,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":13,"Index":1,"Attempt":0,"Launch Time":1641575650711,"Executor ID":"1","Host":"host-name","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1641575650743,"Failed":false,"Killed":false,"Accumulables":[{"ID":152,"Name":"internal.metrics.executorDeserializeTime","Update":12,"Value":25,"Internal":true,"Count Failed Values":true},{"ID":153,"Name":"internal.metrics.executorDeserializeCpuTime","Update":3823330,"Value":12269950,"Internal":true,"Count Failed Values":true},{"ID":154,"Name":"internal.metrics.executorRunTime","Update":11,"Value":22,"Internal":true,"Count Failed Values":true},{"ID":155,"Name":"internal.metrics.executorCpuTime","Update":1801210,"Value":8556413,"Internal":true,"Count Failed Values":true},{"ID":156,"Name":"internal.metrics.resultSize","Update":10154,"Value":20308,"Internal":true,"Count Failed Values":true},{"ID":173,"Name":"internal.metrics.input.bytesRead","Update":288,"Value":600,"Internal":true,"Count Failed Values":true},{"ID":174,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":2,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0},"Task Metrics":{"Executor Deserialize Time":12,"Executor Deserialize CPU Time":3823330,"Executor Run Time":11,"Executor CPU Time":1801210,"Peak Execution Memory":0,"Result Size":10154,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":288,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":6,"Stage Attempt ID":0,"Stage Name":"treeAggregate at RDDLossFunction.scala:61","Number of Tasks":2,"RDD Info":[{"RDD ID":19,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"34\",\"name\":\"treeAggregate\"}","Callsite":"treeAggregate at RDDLossFunction.scala:61","Parent IDs":[13],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":6,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"4\",\"name\":\"LocalTableScan\"}","Callsite":"rdd at Predictor.scala:81","Parent IDs":[5],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":13,"Name":"training blocks (blockSizeInMB=1.0)","Scope":"{\"id\":\"16\",\"name\":\"mapPartitions\"}","Callsite":"mapPartitions at Instance.scala:186","Parent IDs":[12],"Storage Level":{"Use Disk":true,"Use Memory":true,"Deserialized":true,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":10,"Name":"training instances","Scope":"{\"id\":\"6\",\"name\":\"map\"}","Callsite":"map at Predictor.scala:81","Parent IDs":[9],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":9,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"5\",\"name\":\"mapPartitions\"}","Callsite":"rdd at Predictor.scala:81","Parent IDs":[8],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":7,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"3\",\"name\":\"DeserializeToObject\"}","Callsite":"rdd at Predictor.scala:81","Parent IDs":[6],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":12,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"15\",\"name\":\"mapPartitions\"}","Callsite":"mapPartitions at LogisticRegression.scala:944","Parent IDs":[10],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":5,"Name":"ParallelCollectionRDD","Scope":"{\"id\":\"4\",\"name\":\"LocalTableScan\"}","Callsite":"rdd at Predictor.scala:81","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":8,"Name":"SQLExecutionRDD","Callsite":"rdd at Predictor.scala:81","Parent IDs":[7],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.rdd.RDD.treeAggregate(RDD.scala:1222)\norg.apache.spark.ml.optim.loss.RDDLossFunction.calculate(RDDLossFunction.scala:61)\norg.apache.spark.ml.optim.loss.RDDLossFunction.calculate(RDDLossFunction.scala:47)\nbreeze.optimize.CachedDiffFunction.calculate(CachedDiffFunction.scala:24)\nbreeze.optimize.LineSearch$$anon$1.calculate(LineSearch.scala:52)\nbreeze.optimize.LineSearch$$anon$1.calculate(LineSearch.scala:31)\nbreeze.optimize.StrongWolfeLineSearch.phi$1(StrongWolfe.scala:76)\nbreeze.optimize.StrongWolfeLineSearch.$anonfun$minimizeWithBound$7(StrongWolfe.scala:152)\nscala.collection.immutable.Range.foreach$mVc$sp(Range.scala:158)\nbreeze.optimize.StrongWolfeLineSearch.minimizeWithBound(StrongWolfe.scala:151)\nbreeze.optimize.StrongWolfeLineSearch.minimize(StrongWolfe.scala:62)\nbreeze.optimize.LBFGS.determineStepSize(LBFGS.scala:82)\nbreeze.optimize.LBFGS.determineStepSize(LBFGS.scala:38)\nbreeze.optimize.FirstOrderMinimizer.$anonfun$infiniteIterations$1(FirstOrderMinimizer.scala:61)\nscala.collection.Iterator$$anon$7.next(Iterator.scala:140)\nbreeze.util.IteratorImplicits$RichIterator$$anon$2.next(Implicits.scala:74)\norg.apache.spark.ml.classification.LogisticRegression.trainImpl(LogisticRegression.scala:971)\norg.apache.spark.ml.classification.LogisticRegression.$anonfun$train$1(LogisticRegression.scala:627)\norg.apache.spark.ml.util.Instrumentation$.$anonfun$instrumented$1(Instrumentation.scala:191)\nscala.util.Try$.apply(Try.scala:213)","Submission Time":1641575650705,"Completion Time":1641575650745,"Accumulables":[{"ID":152,"Name":"internal.metrics.executorDeserializeTime","Value":25,"Internal":true,"Count Failed Values":true},{"ID":153,"Name":"internal.metrics.executorDeserializeCpuTime","Value":12269950,"Internal":true,"Count Failed Values":true},{"ID":154,"Name":"internal.metrics.executorRunTime","Value":22,"Internal":true,"Count Failed Values":true},{"ID":155,"Name":"internal.metrics.executorCpuTime","Value":8556413,"Internal":true,"Count Failed Values":true},{"ID":156,"Name":"internal.metrics.resultSize","Value":20308,"Internal":true,"Count Failed Values":true},{"ID":173,"Name":"internal.metrics.input.bytesRead","Value":600,"Internal":true,"Count Failed Values":true},{"ID":174,"Name":"internal.metrics.input.recordsRead","Value":2,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0}}
{"Event":"SparkListenerJobEnd","Job ID":6,"Completion Time":1641575650746,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"SparkListenerJobStart","Job ID":7,"Submission Time":1641575650772,"Stage Infos":[{"Stage ID":7,"Stage Attempt ID":0,"Stage Name":"treeAggregate at RDDLossFunction.scala:61","Number of Tasks":2,"RDD Info":[{"RDD ID":20,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"37\",\"name\":\"treeAggregate\"}","Callsite":"treeAggregate at RDDLossFunction.scala:61","Parent IDs":[13],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":6,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"4\",\"name\":\"LocalTableScan\"}","Callsite":"rdd at Predictor.scala:81","Parent IDs":[5],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":13,"Name":"training blocks (blockSizeInMB=1.0)","Scope":"{\"id\":\"16\",\"name\":\"mapPartitions\"}","Callsite":"mapPartitions at Instance.scala:186","Parent IDs":[12],"Storage Level":{"Use Disk":true,"Use Memory":true,"Deserialized":true,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":10,"Name":"training instances","Scope":"{\"id\":\"6\",\"name\":\"map\"}","Callsite":"map at Predictor.scala:81","Parent IDs":[9],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":9,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"5\",\"name\":\"mapPartitions\"}","Callsite":"rdd at Predictor.scala:81","Parent IDs":[8],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":7,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"3\",\"name\":\"DeserializeToObject\"}","Callsite":"rdd at Predictor.scala:81","Parent IDs":[6],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":12,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"15\",\"name\":\"mapPartitions\"}","Callsite":"mapPartitions at LogisticRegression.scala:944","Parent IDs":[10],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":5,"Name":"ParallelCollectionRDD","Scope":"{\"id\":\"4\",\"name\":\"LocalTableScan\"}","Callsite":"rdd at Predictor.scala:81","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":8,"Name":"SQLExecutionRDD","Callsite":"rdd at Predictor.scala:81","Parent IDs":[7],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.rdd.RDD.treeAggregate(RDD.scala:1222)\norg.apache.spark.ml.optim.loss.RDDLossFunction.calculate(RDDLossFunction.scala:61)\norg.apache.spark.ml.optim.loss.RDDLossFunction.calculate(RDDLossFunction.scala:47)\nbreeze.optimize.CachedDiffFunction.calculate(CachedDiffFunction.scala:24)\nbreeze.optimize.LineSearch$$anon$1.calculate(LineSearch.scala:52)\nbreeze.optimize.LineSearch$$anon$1.calculate(LineSearch.scala:31)\nbreeze.optimize.StrongWolfeLineSearch.phi$1(StrongWolfe.scala:76)\nbreeze.optimize.StrongWolfeLineSearch.$anonfun$minimizeWithBound$7(StrongWolfe.scala:152)\nscala.collection.immutable.Range.foreach$mVc$sp(Range.scala:158)\nbreeze.optimize.StrongWolfeLineSearch.minimizeWithBound(StrongWolfe.scala:151)\nbreeze.optimize.StrongWolfeLineSearch.minimize(StrongWolfe.scala:62)\nbreeze.optimize.LBFGS.determineStepSize(LBFGS.scala:82)\nbreeze.optimize.LBFGS.determineStepSize(LBFGS.scala:38)\nbreeze.optimize.FirstOrderMinimizer.$anonfun$infiniteIterations$1(FirstOrderMinimizer.scala:61)\nscala.collection.Iterator$$anon$7.next(Iterator.scala:140)\nbreeze.util.IteratorImplicits$RichIterator$$anon$2.next(Implicits.scala:74)\norg.apache.spark.ml.classification.LogisticRegression.trainImpl(LogisticRegression.scala:971)\norg.apache.spark.ml.classification.LogisticRegression.$anonfun$train$1(LogisticRegression.scala:627)\norg.apache.spark.ml.util.Instrumentation$.$anonfun$instrumented$1(Instrumentation.scala:191)\nscala.util.Try$.apply(Try.scala:213)","Accumulables":[],"Resource Profile Id":0}],"Stage IDs":[7],"Properties":{"spark.rdd.scope":"{\"id\":\"37\",\"name\":\"treeAggregate\"}","spark.rdd.scope.noOverride":"true"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":7,"Stage Attempt ID":0,"Stage Name":"treeAggregate at RDDLossFunction.scala:61","Number of Tasks":2,"RDD Info":[{"RDD ID":20,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"37\",\"name\":\"treeAggregate\"}","Callsite":"treeAggregate at RDDLossFunction.scala:61","Parent IDs":[13],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":6,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"4\",\"name\":\"LocalTableScan\"}","Callsite":"rdd at Predictor.scala:81","Parent IDs":[5],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":13,"Name":"training blocks (blockSizeInMB=1.0)","Scope":"{\"id\":\"16\",\"name\":\"mapPartitions\"}","Callsite":"mapPartitions at Instance.scala:186","Parent IDs":[12],"Storage Level":{"Use Disk":true,"Use Memory":true,"Deserialized":true,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":10,"Name":"training instances","Scope":"{\"id\":\"6\",\"name\":\"map\"}","Callsite":"map at Predictor.scala:81","Parent IDs":[9],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":9,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"5\",\"name\":\"mapPartitions\"}","Callsite":"rdd at Predictor.scala:81","Parent IDs":[8],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":7,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"3\",\"name\":\"DeserializeToObject\"}","Callsite":"rdd at Predictor.scala:81","Parent IDs":[6],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":12,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"15\",\"name\":\"mapPartitions\"}","Callsite":"mapPartitions at LogisticRegression.scala:944","Parent IDs":[10],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":5,"Name":"ParallelCollectionRDD","Scope":"{\"id\":\"4\",\"name\":\"LocalTableScan\"}","Callsite":"rdd at Predictor.scala:81","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":8,"Name":"SQLExecutionRDD","Callsite":"rdd at Predictor.scala:81","Parent IDs":[7],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.rdd.RDD.treeAggregate(RDD.scala:1222)\norg.apache.spark.ml.optim.loss.RDDLossFunction.calculate(RDDLossFunction.scala:61)\norg.apache.spark.ml.optim.loss.RDDLossFunction.calculate(RDDLossFunction.scala:47)\nbreeze.optimize.CachedDiffFunction.calculate(CachedDiffFunction.scala:24)\nbreeze.optimize.LineSearch$$anon$1.calculate(LineSearch.scala:52)\nbreeze.optimize.LineSearch$$anon$1.calculate(LineSearch.scala:31)\nbreeze.optimize.StrongWolfeLineSearch.phi$1(StrongWolfe.scala:76)\nbreeze.optimize.StrongWolfeLineSearch.$anonfun$minimizeWithBound$7(StrongWolfe.scala:152)\nscala.collection.immutable.Range.foreach$mVc$sp(Range.scala:158)\nbreeze.optimize.StrongWolfeLineSearch.minimizeWithBound(StrongWolfe.scala:151)\nbreeze.optimize.StrongWolfeLineSearch.minimize(StrongWolfe.scala:62)\nbreeze.optimize.LBFGS.determineStepSize(LBFGS.scala:82)\nbreeze.optimize.LBFGS.determineStepSize(LBFGS.scala:38)\nbreeze.optimize.FirstOrderMinimizer.$anonfun$infiniteIterations$1(FirstOrderMinimizer.scala:61)\nscala.collection.Iterator$$anon$7.next(Iterator.scala:140)\nbreeze.util.IteratorImplicits$RichIterator$$anon$2.next(Implicits.scala:74)\norg.apache.spark.ml.classification.LogisticRegression.trainImpl(LogisticRegression.scala:971)\norg.apache.spark.ml.classification.LogisticRegression.$anonfun$train$1(LogisticRegression.scala:627)\norg.apache.spark.ml.util.Instrumentation$.$anonfun$instrumented$1(Instrumentation.scala:191)\nscala.util.Try$.apply(Try.scala:213)","Submission Time":1641575650774,"Accumulables":[],"Resource Profile Id":0},"Properties":{"resource.executor.cores":"2","spark.rdd.scope":"{\"id\":\"37\",\"name\":\"treeAggregate\"}","spark.rdd.scope.noOverride":"true"}}
{"Event":"SparkListenerTaskStart","Stage ID":7,"Stage Attempt ID":0,"Task Info":{"Task ID":14,"Index":0,"Attempt":0,"Launch Time":1641575650779,"Executor ID":"1","Host":"host-name","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskStart","Stage ID":7,"Stage Attempt ID":0,"Task Info":{"Task ID":15,"Index":1,"Attempt":0,"Launch Time":1641575650780,"Executor ID":"1","Host":"host-name","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":7,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":15,"Index":1,"Attempt":0,"Launch Time":1641575650780,"Executor ID":"1","Host":"host-name","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1641575650812,"Failed":false,"Killed":false,"Accumulables":[{"ID":177,"Name":"internal.metrics.executorDeserializeTime","Update":14,"Value":14,"Internal":true,"Count Failed Values":true},{"ID":178,"Name":"internal.metrics.executorDeserializeCpuTime","Update":4575762,"Value":4575762,"Internal":true,"Count Failed Values":true},{"ID":179,"Name":"internal.metrics.executorRunTime","Update":11,"Value":11,"Internal":true,"Count Failed Values":true},{"ID":180,"Name":"internal.metrics.executorCpuTime","Update":2130301,"Value":2130301,"Internal":true,"Count Failed Values":true},{"ID":181,"Name":"internal.metrics.resultSize","Update":10154,"Value":10154,"Internal":true,"Count Failed Values":true},{"ID":198,"Name":"internal.metrics.input.bytesRead","Update":288,"Value":288,"Internal":true,"Count Failed Values":true},{"ID":199,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0},"Task Metrics":{"Executor Deserialize Time":14,"Executor Deserialize CPU Time":4575762,"Executor Run Time":11,"Executor CPU Time":2130301,"Peak Execution Memory":0,"Result Size":10154,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":288,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":7,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":14,"Index":0,"Attempt":0,"Launch Time":1641575650779,"Executor ID":"1","Host":"host-name","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1641575650813,"Failed":false,"Killed":false,"Accumulables":[{"ID":177,"Name":"internal.metrics.executorDeserializeTime","Update":14,"Value":28,"Internal":true,"Count Failed Values":true},{"ID":178,"Name":"internal.metrics.executorDeserializeCpuTime","Update":8451850,"Value":13027612,"Internal":true,"Count Failed Values":true},{"ID":179,"Name":"internal.metrics.executorRunTime","Update":12,"Value":23,"Internal":true,"Count Failed Values":true},{"ID":180,"Name":"internal.metrics.executorCpuTime","Update":7289637,"Value":9419938,"Internal":true,"Count Failed Values":true},{"ID":181,"Name":"internal.metrics.resultSize","Update":10154,"Value":20308,"Internal":true,"Count Failed Values":true},{"ID":198,"Name":"internal.metrics.input.bytesRead","Update":312,"Value":600,"Internal":true,"Count Failed Values":true},{"ID":199,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":2,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0},"Task Metrics":{"Executor Deserialize Time":14,"Executor Deserialize CPU Time":8451850,"Executor Run Time":12,"Executor CPU Time":7289637,"Peak Execution Memory":0,"Result Size":10154,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":312,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":7,"Stage Attempt ID":0,"Stage Name":"treeAggregate at RDDLossFunction.scala:61","Number of Tasks":2,"RDD Info":[{"RDD ID":20,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"37\",\"name\":\"treeAggregate\"}","Callsite":"treeAggregate at RDDLossFunction.scala:61","Parent IDs":[13],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":6,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"4\",\"name\":\"LocalTableScan\"}","Callsite":"rdd at Predictor.scala:81","Parent IDs":[5],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":13,"Name":"training blocks (blockSizeInMB=1.0)","Scope":"{\"id\":\"16\",\"name\":\"mapPartitions\"}","Callsite":"mapPartitions at Instance.scala:186","Parent IDs":[12],"Storage Level":{"Use Disk":true,"Use Memory":true,"Deserialized":true,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":10,"Name":"training instances","Scope":"{\"id\":\"6\",\"name\":\"map\"}","Callsite":"map at Predictor.scala:81","Parent IDs":[9],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":9,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"5\",\"name\":\"mapPartitions\"}","Callsite":"rdd at Predictor.scala:81","Parent IDs":[8],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":7,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"3\",\"name\":\"DeserializeToObject\"}","Callsite":"rdd at Predictor.scala:81","Parent IDs":[6],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":12,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"15\",\"name\":\"mapPartitions\"}","Callsite":"mapPartitions at LogisticRegression.scala:944","Parent IDs":[10],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":5,"Name":"ParallelCollectionRDD","Scope":"{\"id\":\"4\",\"name\":\"LocalTableScan\"}","Callsite":"rdd at Predictor.scala:81","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":8,"Name":"SQLExecutionRDD","Callsite":"rdd at Predictor.scala:81","Parent IDs":[7],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.rdd.RDD.treeAggregate(RDD.scala:1222)\norg.apache.spark.ml.optim.loss.RDDLossFunction.calculate(RDDLossFunction.scala:61)\norg.apache.spark.ml.optim.loss.RDDLossFunction.calculate(RDDLossFunction.scala:47)\nbreeze.optimize.CachedDiffFunction.calculate(CachedDiffFunction.scala:24)\nbreeze.optimize.LineSearch$$anon$1.calculate(LineSearch.scala:52)\nbreeze.optimize.LineSearch$$anon$1.calculate(LineSearch.scala:31)\nbreeze.optimize.StrongWolfeLineSearch.phi$1(StrongWolfe.scala:76)\nbreeze.optimize.StrongWolfeLineSearch.$anonfun$minimizeWithBound$7(StrongWolfe.scala:152)\nscala.collection.immutable.Range.foreach$mVc$sp(Range.scala:158)\nbreeze.optimize.StrongWolfeLineSearch.minimizeWithBound(StrongWolfe.scala:151)\nbreeze.optimize.StrongWolfeLineSearch.minimize(StrongWolfe.scala:62)\nbreeze.optimize.LBFGS.determineStepSize(LBFGS.scala:82)\nbreeze.optimize.LBFGS.determineStepSize(LBFGS.scala:38)\nbreeze.optimize.FirstOrderMinimizer.$anonfun$infiniteIterations$1(FirstOrderMinimizer.scala:61)\nscala.collection.Iterator$$anon$7.next(Iterator.scala:140)\nbreeze.util.IteratorImplicits$RichIterator$$anon$2.next(Implicits.scala:74)\norg.apache.spark.ml.classification.LogisticRegression.trainImpl(LogisticRegression.scala:971)\norg.apache.spark.ml.classification.LogisticRegression.$anonfun$train$1(LogisticRegression.scala:627)\norg.apache.spark.ml.util.Instrumentation$.$anonfun$instrumented$1(Instrumentation.scala:191)\nscala.util.Try$.apply(Try.scala:213)","Submission Time":1641575650774,"Completion Time":1641575650814,"Accumulables":[{"ID":177,"Name":"internal.metrics.executorDeserializeTime","Value":28,"Internal":true,"Count Failed Values":true},{"ID":178,"Name":"internal.metrics.executorDeserializeCpuTime","Value":13027612,"Internal":true,"Count Failed Values":true},{"ID":179,"Name":"internal.metrics.executorRunTime","Value":23,"Internal":true,"Count Failed Values":true},{"ID":180,"Name":"internal.metrics.executorCpuTime","Value":9419938,"Internal":true,"Count Failed Values":true},{"ID":181,"Name":"internal.metrics.resultSize","Value":20308,"Internal":true,"Count Failed Values":true},{"ID":198,"Name":"internal.metrics.input.bytesRead","Value":600,"Internal":true,"Count Failed Values":true},{"ID":199,"Name":"internal.metrics.input.recordsRead","Value":2,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0}}
{"Event":"SparkListenerJobEnd","Job ID":7,"Completion Time":1641575650814,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"SparkListenerJobStart","Job ID":8,"Submission Time":1641575650839,"Stage Infos":[{"Stage ID":8,"Stage Attempt ID":0,"Stage Name":"treeAggregate at RDDLossFunction.scala:61","Number of Tasks":2,"RDD Info":[{"RDD ID":21,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"40\",\"name\":\"treeAggregate\"}","Callsite":"treeAggregate at RDDLossFunction.scala:61","Parent IDs":[13],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":6,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"4\",\"name\":\"LocalTableScan\"}","Callsite":"rdd at Predictor.scala:81","Parent IDs":[5],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":13,"Name":"training blocks (blockSizeInMB=1.0)","Scope":"{\"id\":\"16\",\"name\":\"mapPartitions\"}","Callsite":"mapPartitions at Instance.scala:186","Parent IDs":[12],"Storage Level":{"Use Disk":true,"Use Memory":true,"Deserialized":true,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":10,"Name":"training instances","Scope":"{\"id\":\"6\",\"name\":\"map\"}","Callsite":"map at Predictor.scala:81","Parent IDs":[9],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":9,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"5\",\"name\":\"mapPartitions\"}","Callsite":"rdd at Predictor.scala:81","Parent IDs":[8],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":7,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"3\",\"name\":\"DeserializeToObject\"}","Callsite":"rdd at Predictor.scala:81","Parent IDs":[6],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":12,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"15\",\"name\":\"mapPartitions\"}","Callsite":"mapPartitions at LogisticRegression.scala:944","Parent IDs":[10],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":5,"Name":"ParallelCollectionRDD","Scope":"{\"id\":\"4\",\"name\":\"LocalTableScan\"}","Callsite":"rdd at Predictor.scala:81","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":8,"Name":"SQLExecutionRDD","Callsite":"rdd at Predictor.scala:81","Parent IDs":[7],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.rdd.RDD.treeAggregate(RDD.scala:1222)\norg.apache.spark.ml.optim.loss.RDDLossFunction.calculate(RDDLossFunction.scala:61)\norg.apache.spark.ml.optim.loss.RDDLossFunction.calculate(RDDLossFunction.scala:47)\nbreeze.optimize.CachedDiffFunction.calculate(CachedDiffFunction.scala:24)\nbreeze.optimize.LineSearch$$anon$1.calculate(LineSearch.scala:52)\nbreeze.optimize.LineSearch$$anon$1.calculate(LineSearch.scala:31)\nbreeze.optimize.StrongWolfeLineSearch.phi$1(StrongWolfe.scala:76)\nbreeze.optimize.StrongWolfeLineSearch.$anonfun$minimizeWithBound$7(StrongWolfe.scala:152)\nscala.collection.immutable.Range.foreach$mVc$sp(Range.scala:158)\nbreeze.optimize.StrongWolfeLineSearch.minimizeWithBound(StrongWolfe.scala:151)\nbreeze.optimize.StrongWolfeLineSearch.minimize(StrongWolfe.scala:62)\nbreeze.optimize.LBFGS.determineStepSize(LBFGS.scala:82)\nbreeze.optimize.LBFGS.determineStepSize(LBFGS.scala:38)\nbreeze.optimize.FirstOrderMinimizer.$anonfun$infiniteIterations$1(FirstOrderMinimizer.scala:61)\nscala.collection.Iterator$$anon$7.next(Iterator.scala:140)\nbreeze.util.IteratorImplicits$RichIterator$$anon$2.next(Implicits.scala:74)\norg.apache.spark.ml.classification.LogisticRegression.trainImpl(LogisticRegression.scala:971)\norg.apache.spark.ml.classification.LogisticRegression.$anonfun$train$1(LogisticRegression.scala:627)\norg.apache.spark.ml.util.Instrumentation$.$anonfun$instrumented$1(Instrumentation.scala:191)\nscala.util.Try$.apply(Try.scala:213)","Accumulables":[],"Resource Profile Id":0}],"Stage IDs":[8],"Properties":{"spark.rdd.scope":"{\"id\":\"40\",\"name\":\"treeAggregate\"}","spark.rdd.scope.noOverride":"true"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":8,"Stage Attempt ID":0,"Stage Name":"treeAggregate at RDDLossFunction.scala:61","Number of Tasks":2,"RDD Info":[{"RDD ID":21,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"40\",\"name\":\"treeAggregate\"}","Callsite":"treeAggregate at RDDLossFunction.scala:61","Parent IDs":[13],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":6,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"4\",\"name\":\"LocalTableScan\"}","Callsite":"rdd at Predictor.scala:81","Parent IDs":[5],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":13,"Name":"training blocks (blockSizeInMB=1.0)","Scope":"{\"id\":\"16\",\"name\":\"mapPartitions\"}","Callsite":"mapPartitions at Instance.scala:186","Parent IDs":[12],"Storage Level":{"Use Disk":true,"Use Memory":true,"Deserialized":true,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":10,"Name":"training instances","Scope":"{\"id\":\"6\",\"name\":\"map\"}","Callsite":"map at Predictor.scala:81","Parent IDs":[9],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":9,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"5\",\"name\":\"mapPartitions\"}","Callsite":"rdd at Predictor.scala:81","Parent IDs":[8],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":7,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"3\",\"name\":\"DeserializeToObject\"}","Callsite":"rdd at Predictor.scala:81","Parent IDs":[6],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":12,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"15\",\"name\":\"mapPartitions\"}","Callsite":"mapPartitions at LogisticRegression.scala:944","Parent IDs":[10],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":5,"Name":"ParallelCollectionRDD","Scope":"{\"id\":\"4\",\"name\":\"LocalTableScan\"}","Callsite":"rdd at Predictor.scala:81","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":8,"Name":"SQLExecutionRDD","Callsite":"rdd at Predictor.scala:81","Parent IDs":[7],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.rdd.RDD.treeAggregate(RDD.scala:1222)\norg.apache.spark.ml.optim.loss.RDDLossFunction.calculate(RDDLossFunction.scala:61)\norg.apache.spark.ml.optim.loss.RDDLossFunction.calculate(RDDLossFunction.scala:47)\nbreeze.optimize.CachedDiffFunction.calculate(CachedDiffFunction.scala:24)\nbreeze.optimize.LineSearch$$anon$1.calculate(LineSearch.scala:52)\nbreeze.optimize.LineSearch$$anon$1.calculate(LineSearch.scala:31)\nbreeze.optimize.StrongWolfeLineSearch.phi$1(StrongWolfe.scala:76)\nbreeze.optimize.StrongWolfeLineSearch.$anonfun$minimizeWithBound$7(StrongWolfe.scala:152)\nscala.collection.immutable.Range.foreach$mVc$sp(Range.scala:158)\nbreeze.optimize.StrongWolfeLineSearch.minimizeWithBound(StrongWolfe.scala:151)\nbreeze.optimize.StrongWolfeLineSearch.minimize(StrongWolfe.scala:62)\nbreeze.optimize.LBFGS.determineStepSize(LBFGS.scala:82)\nbreeze.optimize.LBFGS.determineStepSize(LBFGS.scala:38)\nbreeze.optimize.FirstOrderMinimizer.$anonfun$infiniteIterations$1(FirstOrderMinimizer.scala:61)\nscala.collection.Iterator$$anon$7.next(Iterator.scala:140)\nbreeze.util.IteratorImplicits$RichIterator$$anon$2.next(Implicits.scala:74)\norg.apache.spark.ml.classification.LogisticRegression.trainImpl(LogisticRegression.scala:971)\norg.apache.spark.ml.classification.LogisticRegression.$anonfun$train$1(LogisticRegression.scala:627)\norg.apache.spark.ml.util.Instrumentation$.$anonfun$instrumented$1(Instrumentation.scala:191)\nscala.util.Try$.apply(Try.scala:213)","Submission Time":1641575650840,"Accumulables":[],"Resource Profile Id":0},"Properties":{"resource.executor.cores":"2","spark.rdd.scope":"{\"id\":\"40\",\"name\":\"treeAggregate\"}","spark.rdd.scope.noOverride":"true"}}
{"Event":"SparkListenerTaskStart","Stage ID":8,"Stage Attempt ID":0,"Task Info":{"Task ID":16,"Index":0,"Attempt":0,"Launch Time":1641575650846,"Executor ID":"1","Host":"host-name","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskStart","Stage ID":8,"Stage Attempt ID":0,"Task Info":{"Task ID":17,"Index":1,"Attempt":0,"Launch Time":1641575650846,"Executor ID":"1","Host":"host-name","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":8,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":16,"Index":0,"Attempt":0,"Launch Time":1641575650846,"Executor ID":"1","Host":"host-name","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1641575650876,"Failed":false,"Killed":false,"Accumulables":[{"ID":202,"Name":"internal.metrics.executorDeserializeTime","Update":13,"Value":13,"Internal":true,"Count Failed Values":true},{"ID":203,"Name":"internal.metrics.executorDeserializeCpuTime","Update":8451944,"Value":8451944,"Internal":true,"Count Failed Values":true},{"ID":204,"Name":"internal.metrics.executorRunTime","Update":11,"Value":11,"Internal":true,"Count Failed Values":true},{"ID":205,"Name":"internal.metrics.executorCpuTime","Update":6521323,"Value":6521323,"Internal":true,"Count Failed Values":true},{"ID":206,"Name":"internal.metrics.resultSize","Update":10154,"Value":10154,"Internal":true,"Count Failed Values":true},{"ID":223,"Name":"internal.metrics.input.bytesRead","Update":312,"Value":312,"Internal":true,"Count Failed Values":true},{"ID":224,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0},"Task Metrics":{"Executor Deserialize Time":13,"Executor Deserialize CPU Time":8451944,"Executor Run Time":11,"Executor CPU Time":6521323,"Peak Execution Memory":0,"Result Size":10154,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":312,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":8,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":17,"Index":1,"Attempt":0,"Launch Time":1641575650846,"Executor ID":"1","Host":"host-name","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1641575650876,"Failed":false,"Killed":false,"Accumulables":[{"ID":202,"Name":"internal.metrics.executorDeserializeTime","Update":12,"Value":25,"Internal":true,"Count Failed Values":true},{"ID":203,"Name":"internal.metrics.executorDeserializeCpuTime","Update":3945000,"Value":12396944,"Internal":true,"Count Failed Values":true},{"ID":204,"Name":"internal.metrics.executorRunTime","Update":12,"Value":23,"Internal":true,"Count Failed Values":true},{"ID":205,"Name":"internal.metrics.executorCpuTime","Update":2214459,"Value":8735782,"Internal":true,"Count Failed Values":true},{"ID":206,"Name":"internal.metrics.resultSize","Update":10154,"Value":20308,"Internal":true,"Count Failed Values":true},{"ID":223,"Name":"internal.metrics.input.bytesRead","Update":288,"Value":600,"Internal":true,"Count Failed Values":true},{"ID":224,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":2,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0},"Task Metrics":{"Executor Deserialize Time":12,"Executor Deserialize CPU Time":3945000,"Executor Run Time":12,"Executor CPU Time":2214459,"Peak Execution Memory":0,"Result Size":10154,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":288,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":8,"Stage Attempt ID":0,"Stage Name":"treeAggregate at RDDLossFunction.scala:61","Number of Tasks":2,"RDD Info":[{"RDD ID":21,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"40\",\"name\":\"treeAggregate\"}","Callsite":"treeAggregate at RDDLossFunction.scala:61","Parent IDs":[13],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":6,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"4\",\"name\":\"LocalTableScan\"}","Callsite":"rdd at Predictor.scala:81","Parent IDs":[5],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":13,"Name":"training blocks (blockSizeInMB=1.0)","Scope":"{\"id\":\"16\",\"name\":\"mapPartitions\"}","Callsite":"mapPartitions at Instance.scala:186","Parent IDs":[12],"Storage Level":{"Use Disk":true,"Use Memory":true,"Deserialized":true,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":10,"Name":"training instances","Scope":"{\"id\":\"6\",\"name\":\"map\"}","Callsite":"map at Predictor.scala:81","Parent IDs":[9],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":9,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"5\",\"name\":\"mapPartitions\"}","Callsite":"rdd at Predictor.scala:81","Parent IDs":[8],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":7,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"3\",\"name\":\"DeserializeToObject\"}","Callsite":"rdd at Predictor.scala:81","Parent IDs":[6],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":12,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"15\",\"name\":\"mapPartitions\"}","Callsite":"mapPartitions at LogisticRegression.scala:944","Parent IDs":[10],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":5,"Name":"ParallelCollectionRDD","Scope":"{\"id\":\"4\",\"name\":\"LocalTableScan\"}","Callsite":"rdd at Predictor.scala:81","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":8,"Name":"SQLExecutionRDD","Callsite":"rdd at Predictor.scala:81","Parent IDs":[7],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.rdd.RDD.treeAggregate(RDD.scala:1222)\norg.apache.spark.ml.optim.loss.RDDLossFunction.calculate(RDDLossFunction.scala:61)\norg.apache.spark.ml.optim.loss.RDDLossFunction.calculate(RDDLossFunction.scala:47)\nbreeze.optimize.CachedDiffFunction.calculate(CachedDiffFunction.scala:24)\nbreeze.optimize.LineSearch$$anon$1.calculate(LineSearch.scala:52)\nbreeze.optimize.LineSearch$$anon$1.calculate(LineSearch.scala:31)\nbreeze.optimize.StrongWolfeLineSearch.phi$1(StrongWolfe.scala:76)\nbreeze.optimize.StrongWolfeLineSearch.$anonfun$minimizeWithBound$7(StrongWolfe.scala:152)\nscala.collection.immutable.Range.foreach$mVc$sp(Range.scala:158)\nbreeze.optimize.StrongWolfeLineSearch.minimizeWithBound(StrongWolfe.scala:151)\nbreeze.optimize.StrongWolfeLineSearch.minimize(StrongWolfe.scala:62)\nbreeze.optimize.LBFGS.determineStepSize(LBFGS.scala:82)\nbreeze.optimize.LBFGS.determineStepSize(LBFGS.scala:38)\nbreeze.optimize.FirstOrderMinimizer.$anonfun$infiniteIterations$1(FirstOrderMinimizer.scala:61)\nscala.collection.Iterator$$anon$7.next(Iterator.scala:140)\nbreeze.util.IteratorImplicits$RichIterator$$anon$2.next(Implicits.scala:74)\norg.apache.spark.ml.classification.LogisticRegression.trainImpl(LogisticRegression.scala:971)\norg.apache.spark.ml.classification.LogisticRegression.$anonfun$train$1(LogisticRegression.scala:627)\norg.apache.spark.ml.util.Instrumentation$.$anonfun$instrumented$1(Instrumentation.scala:191)\nscala.util.Try$.apply(Try.scala:213)","Submission Time":1641575650840,"Completion Time":1641575650880,"Accumulables":[{"ID":202,"Name":"internal.metrics.executorDeserializeTime","Value":25,"Internal":true,"Count Failed Values":true},{"ID":203,"Name":"internal.metrics.executorDeserializeCpuTime","Value":12396944,"Internal":true,"Count Failed Values":true},{"ID":204,"Name":"internal.metrics.executorRunTime","Value":23,"Internal":true,"Count Failed Values":true},{"ID":205,"Name":"internal.metrics.executorCpuTime","Value":8735782,"Internal":true,"Count Failed Values":true},{"ID":206,"Name":"internal.metrics.resultSize","Value":20308,"Internal":true,"Count Failed Values":true},{"ID":223,"Name":"internal.metrics.input.bytesRead","Value":600,"Internal":true,"Count Failed Values":true},{"ID":224,"Name":"internal.metrics.input.recordsRead","Value":2,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0}}
{"Event":"SparkListenerJobEnd","Job ID":8,"Completion Time":1641575650881,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"SparkListenerJobStart","Job ID":9,"Submission Time":1641575650900,"Stage Infos":[{"Stage ID":9,"Stage Attempt ID":0,"Stage Name":"treeAggregate at RDDLossFunction.scala:61","Number of Tasks":2,"RDD Info":[{"RDD ID":22,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"43\",\"name\":\"treeAggregate\"}","Callsite":"treeAggregate at RDDLossFunction.scala:61","Parent IDs":[13],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":6,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"4\",\"name\":\"LocalTableScan\"}","Callsite":"rdd at Predictor.scala:81","Parent IDs":[5],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":13,"Name":"training blocks (blockSizeInMB=1.0)","Scope":"{\"id\":\"16\",\"name\":\"mapPartitions\"}","Callsite":"mapPartitions at Instance.scala:186","Parent IDs":[12],"Storage Level":{"Use Disk":true,"Use Memory":true,"Deserialized":true,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":10,"Name":"training instances","Scope":"{\"id\":\"6\",\"name\":\"map\"}","Callsite":"map at Predictor.scala:81","Parent IDs":[9],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":9,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"5\",\"name\":\"mapPartitions\"}","Callsite":"rdd at Predictor.scala:81","Parent IDs":[8],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":7,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"3\",\"name\":\"DeserializeToObject\"}","Callsite":"rdd at Predictor.scala:81","Parent IDs":[6],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":12,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"15\",\"name\":\"mapPartitions\"}","Callsite":"mapPartitions at LogisticRegression.scala:944","Parent IDs":[10],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":5,"Name":"ParallelCollectionRDD","Scope":"{\"id\":\"4\",\"name\":\"LocalTableScan\"}","Callsite":"rdd at Predictor.scala:81","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":8,"Name":"SQLExecutionRDD","Callsite":"rdd at Predictor.scala:81","Parent IDs":[7],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.rdd.RDD.treeAggregate(RDD.scala:1222)\norg.apache.spark.ml.optim.loss.RDDLossFunction.calculate(RDDLossFunction.scala:61)\norg.apache.spark.ml.optim.loss.RDDLossFunction.calculate(RDDLossFunction.scala:47)\nbreeze.optimize.CachedDiffFunction.calculate(CachedDiffFunction.scala:24)\nbreeze.optimize.LineSearch$$anon$1.calculate(LineSearch.scala:52)\nbreeze.optimize.LineSearch$$anon$1.calculate(LineSearch.scala:31)\nbreeze.optimize.StrongWolfeLineSearch.phi$1(StrongWolfe.scala:76)\nbreeze.optimize.StrongWolfeLineSearch.$anonfun$minimizeWithBound$7(StrongWolfe.scala:152)\nscala.collection.immutable.Range.foreach$mVc$sp(Range.scala:158)\nbreeze.optimize.StrongWolfeLineSearch.minimizeWithBound(StrongWolfe.scala:151)\nbreeze.optimize.StrongWolfeLineSearch.minimize(StrongWolfe.scala:62)\nbreeze.optimize.LBFGS.determineStepSize(LBFGS.scala:82)\nbreeze.optimize.LBFGS.determineStepSize(LBFGS.scala:38)\nbreeze.optimize.FirstOrderMinimizer.$anonfun$infiniteIterations$1(FirstOrderMinimizer.scala:61)\nscala.collection.Iterator$$anon$7.next(Iterator.scala:140)\nbreeze.util.IteratorImplicits$RichIterator$$anon$2.next(Implicits.scala:74)\norg.apache.spark.ml.classification.LogisticRegression.trainImpl(LogisticRegression.scala:971)\norg.apache.spark.ml.classification.LogisticRegression.$anonfun$train$1(LogisticRegression.scala:627)\norg.apache.spark.ml.util.Instrumentation$.$anonfun$instrumented$1(Instrumentation.scala:191)\nscala.util.Try$.apply(Try.scala:213)","Accumulables":[],"Resource Profile Id":0}],"Stage IDs":[9],"Properties":{"spark.rdd.scope":"{\"id\":\"43\",\"name\":\"treeAggregate\"}","spark.rdd.scope.noOverride":"true"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":9,"Stage Attempt ID":0,"Stage Name":"treeAggregate at RDDLossFunction.scala:61","Number of Tasks":2,"RDD Info":[{"RDD ID":22,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"43\",\"name\":\"treeAggregate\"}","Callsite":"treeAggregate at RDDLossFunction.scala:61","Parent IDs":[13],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":6,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"4\",\"name\":\"LocalTableScan\"}","Callsite":"rdd at Predictor.scala:81","Parent IDs":[5],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":13,"Name":"training blocks (blockSizeInMB=1.0)","Scope":"{\"id\":\"16\",\"name\":\"mapPartitions\"}","Callsite":"mapPartitions at Instance.scala:186","Parent IDs":[12],"Storage Level":{"Use Disk":true,"Use Memory":true,"Deserialized":true,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":10,"Name":"training instances","Scope":"{\"id\":\"6\",\"name\":\"map\"}","Callsite":"map at Predictor.scala:81","Parent IDs":[9],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":9,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"5\",\"name\":\"mapPartitions\"}","Callsite":"rdd at Predictor.scala:81","Parent IDs":[8],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":7,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"3\",\"name\":\"DeserializeToObject\"}","Callsite":"rdd at Predictor.scala:81","Parent IDs":[6],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":12,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"15\",\"name\":\"mapPartitions\"}","Callsite":"mapPartitions at LogisticRegression.scala:944","Parent IDs":[10],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":5,"Name":"ParallelCollectionRDD","Scope":"{\"id\":\"4\",\"name\":\"LocalTableScan\"}","Callsite":"rdd at Predictor.scala:81","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":8,"Name":"SQLExecutionRDD","Callsite":"rdd at Predictor.scala:81","Parent IDs":[7],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.rdd.RDD.treeAggregate(RDD.scala:1222)\norg.apache.spark.ml.optim.loss.RDDLossFunction.calculate(RDDLossFunction.scala:61)\norg.apache.spark.ml.optim.loss.RDDLossFunction.calculate(RDDLossFunction.scala:47)\nbreeze.optimize.CachedDiffFunction.calculate(CachedDiffFunction.scala:24)\nbreeze.optimize.LineSearch$$anon$1.calculate(LineSearch.scala:52)\nbreeze.optimize.LineSearch$$anon$1.calculate(LineSearch.scala:31)\nbreeze.optimize.StrongWolfeLineSearch.phi$1(StrongWolfe.scala:76)\nbreeze.optimize.StrongWolfeLineSearch.$anonfun$minimizeWithBound$7(StrongWolfe.scala:152)\nscala.collection.immutable.Range.foreach$mVc$sp(Range.scala:158)\nbreeze.optimize.StrongWolfeLineSearch.minimizeWithBound(StrongWolfe.scala:151)\nbreeze.optimize.StrongWolfeLineSearch.minimize(StrongWolfe.scala:62)\nbreeze.optimize.LBFGS.determineStepSize(LBFGS.scala:82)\nbreeze.optimize.LBFGS.determineStepSize(LBFGS.scala:38)\nbreeze.optimize.FirstOrderMinimizer.$anonfun$infiniteIterations$1(FirstOrderMinimizer.scala:61)\nscala.collection.Iterator$$anon$7.next(Iterator.scala:140)\nbreeze.util.IteratorImplicits$RichIterator$$anon$2.next(Implicits.scala:74)\norg.apache.spark.ml.classification.LogisticRegression.trainImpl(LogisticRegression.scala:971)\norg.apache.spark.ml.classification.LogisticRegression.$anonfun$train$1(LogisticRegression.scala:627)\norg.apache.spark.ml.util.Instrumentation$.$anonfun$instrumented$1(Instrumentation.scala:191)\nscala.util.Try$.apply(Try.scala:213)","Submission Time":1641575650902,"Accumulables":[],"Resource Profile Id":0},"Properties":{"resource.executor.cores":"2","spark.rdd.scope":"{\"id\":\"43\",\"name\":\"treeAggregate\"}","spark.rdd.scope.noOverride":"true"}}
{"Event":"SparkListenerTaskStart","Stage ID":9,"Stage Attempt ID":0,"Task Info":{"Task ID":18,"Index":0,"Attempt":0,"Launch Time":1641575650907,"Executor ID":"1","Host":"host-name","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskStart","Stage ID":9,"Stage Attempt ID":0,"Task Info":{"Task ID":19,"Index":1,"Attempt":0,"Launch Time":1641575650907,"Executor ID":"1","Host":"host-name","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":9,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":19,"Index":1,"Attempt":0,"Launch Time":1641575650907,"Executor ID":"1","Host":"host-name","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1641575650937,"Failed":false,"Killed":false,"Accumulables":[{"ID":227,"Name":"internal.metrics.executorDeserializeTime","Update":10,"Value":10,"Internal":true,"Count Failed Values":true},{"ID":228,"Name":"internal.metrics.executorDeserializeCpuTime","Update":7082224,"Value":7082224,"Internal":true,"Count Failed Values":true},{"ID":229,"Name":"internal.metrics.executorRunTime","Update":11,"Value":11,"Internal":true,"Count Failed Values":true},{"ID":230,"Name":"internal.metrics.executorCpuTime","Update":6744302,"Value":6744302,"Internal":true,"Count Failed Values":true},{"ID":231,"Name":"internal.metrics.resultSize","Update":10154,"Value":10154,"Internal":true,"Count Failed Values":true},{"ID":248,"Name":"internal.metrics.input.bytesRead","Update":288,"Value":288,"Internal":true,"Count Failed Values":true},{"ID":249,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0},"Task Metrics":{"Executor Deserialize Time":10,"Executor Deserialize CPU Time":7082224,"Executor Run Time":11,"Executor CPU Time":6744302,"Peak Execution Memory":0,"Result Size":10154,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":288,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":9,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":18,"Index":0,"Attempt":0,"Launch Time":1641575650907,"Executor ID":"1","Host":"host-name","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1641575650937,"Failed":false,"Killed":false,"Accumulables":[{"ID":227,"Name":"internal.metrics.executorDeserializeTime","Update":11,"Value":21,"Internal":true,"Count Failed Values":true},{"ID":228,"Name":"internal.metrics.executorDeserializeCpuTime","Update":3456801,"Value":10539025,"Internal":true,"Count Failed Values":true},{"ID":229,"Name":"internal.metrics.executorRunTime","Update":11,"Value":22,"Internal":true,"Count Failed Values":true},{"ID":230,"Name":"internal.metrics.executorCpuTime","Update":2549620,"Value":9293922,"Internal":true,"Count Failed Values":true},{"ID":231,"Name":"internal.metrics.resultSize","Update":10154,"Value":20308,"Internal":true,"Count Failed Values":true},{"ID":248,"Name":"internal.metrics.input.bytesRead","Update":312,"Value":600,"Internal":true,"Count Failed Values":true},{"ID":249,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":2,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0},"Task Metrics":{"Executor Deserialize Time":11,"Executor Deserialize CPU Time":3456801,"Executor Run Time":11,"Executor CPU Time":2549620,"Peak Execution Memory":0,"Result Size":10154,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":312,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":9,"Stage Attempt ID":0,"Stage Name":"treeAggregate at RDDLossFunction.scala:61","Number of Tasks":2,"RDD Info":[{"RDD ID":22,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"43\",\"name\":\"treeAggregate\"}","Callsite":"treeAggregate at RDDLossFunction.scala:61","Parent IDs":[13],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":6,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"4\",\"name\":\"LocalTableScan\"}","Callsite":"rdd at Predictor.scala:81","Parent IDs":[5],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":13,"Name":"training blocks (blockSizeInMB=1.0)","Scope":"{\"id\":\"16\",\"name\":\"mapPartitions\"}","Callsite":"mapPartitions at Instance.scala:186","Parent IDs":[12],"Storage Level":{"Use Disk":true,"Use Memory":true,"Deserialized":true,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":10,"Name":"training instances","Scope":"{\"id\":\"6\",\"name\":\"map\"}","Callsite":"map at Predictor.scala:81","Parent IDs":[9],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":9,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"5\",\"name\":\"mapPartitions\"}","Callsite":"rdd at Predictor.scala:81","Parent IDs":[8],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":7,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"3\",\"name\":\"DeserializeToObject\"}","Callsite":"rdd at Predictor.scala:81","Parent IDs":[6],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":12,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"15\",\"name\":\"mapPartitions\"}","Callsite":"mapPartitions at LogisticRegression.scala:944","Parent IDs":[10],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":5,"Name":"ParallelCollectionRDD","Scope":"{\"id\":\"4\",\"name\":\"LocalTableScan\"}","Callsite":"rdd at Predictor.scala:81","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":8,"Name":"SQLExecutionRDD","Callsite":"rdd at Predictor.scala:81","Parent IDs":[7],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.rdd.RDD.treeAggregate(RDD.scala:1222)\norg.apache.spark.ml.optim.loss.RDDLossFunction.calculate(RDDLossFunction.scala:61)\norg.apache.spark.ml.optim.loss.RDDLossFunction.calculate(RDDLossFunction.scala:47)\nbreeze.optimize.CachedDiffFunction.calculate(CachedDiffFunction.scala:24)\nbreeze.optimize.LineSearch$$anon$1.calculate(LineSearch.scala:52)\nbreeze.optimize.LineSearch$$anon$1.calculate(LineSearch.scala:31)\nbreeze.optimize.StrongWolfeLineSearch.phi$1(StrongWolfe.scala:76)\nbreeze.optimize.StrongWolfeLineSearch.$anonfun$minimizeWithBound$7(StrongWolfe.scala:152)\nscala.collection.immutable.Range.foreach$mVc$sp(Range.scala:158)\nbreeze.optimize.StrongWolfeLineSearch.minimizeWithBound(StrongWolfe.scala:151)\nbreeze.optimize.StrongWolfeLineSearch.minimize(StrongWolfe.scala:62)\nbreeze.optimize.LBFGS.determineStepSize(LBFGS.scala:82)\nbreeze.optimize.LBFGS.determineStepSize(LBFGS.scala:38)\nbreeze.optimize.FirstOrderMinimizer.$anonfun$infiniteIterations$1(FirstOrderMinimizer.scala:61)\nscala.collection.Iterator$$anon$7.next(Iterator.scala:140)\nbreeze.util.IteratorImplicits$RichIterator$$anon$2.next(Implicits.scala:74)\norg.apache.spark.ml.classification.LogisticRegression.trainImpl(LogisticRegression.scala:971)\norg.apache.spark.ml.classification.LogisticRegression.$anonfun$train$1(LogisticRegression.scala:627)\norg.apache.spark.ml.util.Instrumentation$.$anonfun$instrumented$1(Instrumentation.scala:191)\nscala.util.Try$.apply(Try.scala:213)","Submission Time":1641575650902,"Completion Time":1641575650938,"Accumulables":[{"ID":227,"Name":"internal.metrics.executorDeserializeTime","Value":21,"Internal":true,"Count Failed Values":true},{"ID":228,"Name":"internal.metrics.executorDeserializeCpuTime","Value":10539025,"Internal":true,"Count Failed Values":true},{"ID":229,"Name":"internal.metrics.executorRunTime","Value":22,"Internal":true,"Count Failed Values":true},{"ID":230,"Name":"internal.metrics.executorCpuTime","Value":9293922,"Internal":true,"Count Failed Values":true},{"ID":231,"Name":"internal.metrics.resultSize","Value":20308,"Internal":true,"Count Failed Values":true},{"ID":248,"Name":"internal.metrics.input.bytesRead","Value":600,"Internal":true,"Count Failed Values":true},{"ID":249,"Name":"internal.metrics.input.recordsRead","Value":2,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0}}
{"Event":"SparkListenerJobEnd","Job ID":9,"Completion Time":1641575650938,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"SparkListenerJobStart","Job ID":10,"Submission Time":1641575650958,"Stage Infos":[{"Stage ID":10,"Stage Attempt ID":0,"Stage Name":"treeAggregate at RDDLossFunction.scala:61","Number of Tasks":2,"RDD Info":[{"RDD ID":23,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"46\",\"name\":\"treeAggregate\"}","Callsite":"treeAggregate at RDDLossFunction.scala:61","Parent IDs":[13],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":6,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"4\",\"name\":\"LocalTableScan\"}","Callsite":"rdd at Predictor.scala:81","Parent IDs":[5],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":13,"Name":"training blocks (blockSizeInMB=1.0)","Scope":"{\"id\":\"16\",\"name\":\"mapPartitions\"}","Callsite":"mapPartitions at Instance.scala:186","Parent IDs":[12],"Storage Level":{"Use Disk":true,"Use Memory":true,"Deserialized":true,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":10,"Name":"training instances","Scope":"{\"id\":\"6\",\"name\":\"map\"}","Callsite":"map at Predictor.scala:81","Parent IDs":[9],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":9,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"5\",\"name\":\"mapPartitions\"}","Callsite":"rdd at Predictor.scala:81","Parent IDs":[8],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":7,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"3\",\"name\":\"DeserializeToObject\"}","Callsite":"rdd at Predictor.scala:81","Parent IDs":[6],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":12,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"15\",\"name\":\"mapPartitions\"}","Callsite":"mapPartitions at LogisticRegression.scala:944","Parent IDs":[10],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":5,"Name":"ParallelCollectionRDD","Scope":"{\"id\":\"4\",\"name\":\"LocalTableScan\"}","Callsite":"rdd at Predictor.scala:81","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":8,"Name":"SQLExecutionRDD","Callsite":"rdd at Predictor.scala:81","Parent IDs":[7],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.rdd.RDD.treeAggregate(RDD.scala:1222)\norg.apache.spark.ml.optim.loss.RDDLossFunction.calculate(RDDLossFunction.scala:61)\norg.apache.spark.ml.optim.loss.RDDLossFunction.calculate(RDDLossFunction.scala:47)\nbreeze.optimize.CachedDiffFunction.calculate(CachedDiffFunction.scala:24)\nbreeze.optimize.LineSearch$$anon$1.calculate(LineSearch.scala:52)\nbreeze.optimize.LineSearch$$anon$1.calculate(LineSearch.scala:31)\nbreeze.optimize.StrongWolfeLineSearch.phi$1(StrongWolfe.scala:76)\nbreeze.optimize.StrongWolfeLineSearch.$anonfun$minimizeWithBound$7(StrongWolfe.scala:152)\nscala.collection.immutable.Range.foreach$mVc$sp(Range.scala:158)\nbreeze.optimize.StrongWolfeLineSearch.minimizeWithBound(StrongWolfe.scala:151)\nbreeze.optimize.StrongWolfeLineSearch.minimize(StrongWolfe.scala:62)\nbreeze.optimize.LBFGS.determineStepSize(LBFGS.scala:82)\nbreeze.optimize.LBFGS.determineStepSize(LBFGS.scala:38)\nbreeze.optimize.FirstOrderMinimizer.$anonfun$infiniteIterations$1(FirstOrderMinimizer.scala:61)\nscala.collection.Iterator$$anon$7.next(Iterator.scala:140)\nbreeze.util.IteratorImplicits$RichIterator$$anon$2.next(Implicits.scala:74)\norg.apache.spark.ml.classification.LogisticRegression.trainImpl(LogisticRegression.scala:971)\norg.apache.spark.ml.classification.LogisticRegression.$anonfun$train$1(LogisticRegression.scala:627)\norg.apache.spark.ml.util.Instrumentation$.$anonfun$instrumented$1(Instrumentation.scala:191)\nscala.util.Try$.apply(Try.scala:213)","Accumulables":[],"Resource Profile Id":0}],"Stage IDs":[10],"Properties":{"spark.rdd.scope":"{\"id\":\"46\",\"name\":\"treeAggregate\"}","spark.rdd.scope.noOverride":"true"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":10,"Stage Attempt ID":0,"Stage Name":"treeAggregate at RDDLossFunction.scala:61","Number of Tasks":2,"RDD Info":[{"RDD ID":23,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"46\",\"name\":\"treeAggregate\"}","Callsite":"treeAggregate at RDDLossFunction.scala:61","Parent IDs":[13],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":6,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"4\",\"name\":\"LocalTableScan\"}","Callsite":"rdd at Predictor.scala:81","Parent IDs":[5],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":13,"Name":"training blocks (blockSizeInMB=1.0)","Scope":"{\"id\":\"16\",\"name\":\"mapPartitions\"}","Callsite":"mapPartitions at Instance.scala:186","Parent IDs":[12],"Storage Level":{"Use Disk":true,"Use Memory":true,"Deserialized":true,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":10,"Name":"training instances","Scope":"{\"id\":\"6\",\"name\":\"map\"}","Callsite":"map at Predictor.scala:81","Parent IDs":[9],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":9,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"5\",\"name\":\"mapPartitions\"}","Callsite":"rdd at Predictor.scala:81","Parent IDs":[8],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":7,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"3\",\"name\":\"DeserializeToObject\"}","Callsite":"rdd at Predictor.scala:81","Parent IDs":[6],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":12,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"15\",\"name\":\"mapPartitions\"}","Callsite":"mapPartitions at LogisticRegression.scala:944","Parent IDs":[10],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":5,"Name":"ParallelCollectionRDD","Scope":"{\"id\":\"4\",\"name\":\"LocalTableScan\"}","Callsite":"rdd at Predictor.scala:81","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":8,"Name":"SQLExecutionRDD","Callsite":"rdd at Predictor.scala:81","Parent IDs":[7],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.rdd.RDD.treeAggregate(RDD.scala:1222)\norg.apache.spark.ml.optim.loss.RDDLossFunction.calculate(RDDLossFunction.scala:61)\norg.apache.spark.ml.optim.loss.RDDLossFunction.calculate(RDDLossFunction.scala:47)\nbreeze.optimize.CachedDiffFunction.calculate(CachedDiffFunction.scala:24)\nbreeze.optimize.LineSearch$$anon$1.calculate(LineSearch.scala:52)\nbreeze.optimize.LineSearch$$anon$1.calculate(LineSearch.scala:31)\nbreeze.optimize.StrongWolfeLineSearch.phi$1(StrongWolfe.scala:76)\nbreeze.optimize.StrongWolfeLineSearch.$anonfun$minimizeWithBound$7(StrongWolfe.scala:152)\nscala.collection.immutable.Range.foreach$mVc$sp(Range.scala:158)\nbreeze.optimize.StrongWolfeLineSearch.minimizeWithBound(StrongWolfe.scala:151)\nbreeze.optimize.StrongWolfeLineSearch.minimize(StrongWolfe.scala:62)\nbreeze.optimize.LBFGS.determineStepSize(LBFGS.scala:82)\nbreeze.optimize.LBFGS.determineStepSize(LBFGS.scala:38)\nbreeze.optimize.FirstOrderMinimizer.$anonfun$infiniteIterations$1(FirstOrderMinimizer.scala:61)\nscala.collection.Iterator$$anon$7.next(Iterator.scala:140)\nbreeze.util.IteratorImplicits$RichIterator$$anon$2.next(Implicits.scala:74)\norg.apache.spark.ml.classification.LogisticRegression.trainImpl(LogisticRegression.scala:971)\norg.apache.spark.ml.classification.LogisticRegression.$anonfun$train$1(LogisticRegression.scala:627)\norg.apache.spark.ml.util.Instrumentation$.$anonfun$instrumented$1(Instrumentation.scala:191)\nscala.util.Try$.apply(Try.scala:213)","Submission Time":1641575650959,"Accumulables":[],"Resource Profile Id":0},"Properties":{"resource.executor.cores":"2","spark.rdd.scope":"{\"id\":\"46\",\"name\":\"treeAggregate\"}","spark.rdd.scope.noOverride":"true"}}
{"Event":"SparkListenerTaskStart","Stage ID":10,"Stage Attempt ID":0,"Task Info":{"Task ID":20,"Index":0,"Attempt":0,"Launch Time":1641575651073,"Executor ID":"1","Host":"host-name","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskStart","Stage ID":10,"Stage Attempt ID":0,"Task Info":{"Task ID":21,"Index":1,"Attempt":0,"Launch Time":1641575651074,"Executor ID":"1","Host":"host-name","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":10,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":21,"Index":1,"Attempt":0,"Launch Time":1641575651074,"Executor ID":"1","Host":"host-name","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1641575651101,"Failed":false,"Killed":false,"Accumulables":[{"ID":252,"Name":"internal.metrics.executorDeserializeTime","Update":11,"Value":11,"Internal":true,"Count Failed Values":true},{"ID":253,"Name":"internal.metrics.executorDeserializeCpuTime","Update":6896800,"Value":6896800,"Internal":true,"Count Failed Values":true},{"ID":254,"Name":"internal.metrics.executorRunTime","Update":10,"Value":10,"Internal":true,"Count Failed Values":true},{"ID":255,"Name":"internal.metrics.executorCpuTime","Update":5916901,"Value":5916901,"Internal":true,"Count Failed Values":true},{"ID":256,"Name":"internal.metrics.resultSize","Update":10154,"Value":10154,"Internal":true,"Count Failed Values":true},{"ID":273,"Name":"internal.metrics.input.bytesRead","Update":288,"Value":288,"Internal":true,"Count Failed Values":true},{"ID":274,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0},"Task Metrics":{"Executor Deserialize Time":11,"Executor Deserialize CPU Time":6896800,"Executor Run Time":10,"Executor CPU Time":5916901,"Peak Execution Memory":0,"Result Size":10154,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":288,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":10,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":20,"Index":0,"Attempt":0,"Launch Time":1641575651073,"Executor ID":"1","Host":"host-name","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1641575651101,"Failed":false,"Killed":false,"Accumulables":[{"ID":252,"Name":"internal.metrics.executorDeserializeTime","Update":11,"Value":22,"Internal":true,"Count Failed Values":true},{"ID":253,"Name":"internal.metrics.executorDeserializeCpuTime","Update":3129442,"Value":10026242,"Internal":true,"Count Failed Values":true},{"ID":254,"Name":"internal.metrics.executorRunTime","Update":10,"Value":20,"Internal":true,"Count Failed Values":true},{"ID":255,"Name":"internal.metrics.executorCpuTime","Update":1438388,"Value":7355289,"Internal":true,"Count Failed Values":true},{"ID":256,"Name":"internal.metrics.resultSize","Update":10154,"Value":20308,"Internal":true,"Count Failed Values":true},{"ID":273,"Name":"internal.metrics.input.bytesRead","Update":312,"Value":600,"Internal":true,"Count Failed Values":true},{"ID":274,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":2,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0},"Task Metrics":{"Executor Deserialize Time":11,"Executor Deserialize CPU Time":3129442,"Executor Run Time":10,"Executor CPU Time":1438388,"Peak Execution Memory":0,"Result Size":10154,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":312,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":10,"Stage Attempt ID":0,"Stage Name":"treeAggregate at RDDLossFunction.scala:61","Number of Tasks":2,"RDD Info":[{"RDD ID":23,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"46\",\"name\":\"treeAggregate\"}","Callsite":"treeAggregate at RDDLossFunction.scala:61","Parent IDs":[13],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":6,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"4\",\"name\":\"LocalTableScan\"}","Callsite":"rdd at Predictor.scala:81","Parent IDs":[5],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":13,"Name":"training blocks (blockSizeInMB=1.0)","Scope":"{\"id\":\"16\",\"name\":\"mapPartitions\"}","Callsite":"mapPartitions at Instance.scala:186","Parent IDs":[12],"Storage Level":{"Use Disk":true,"Use Memory":true,"Deserialized":true,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":10,"Name":"training instances","Scope":"{\"id\":\"6\",\"name\":\"map\"}","Callsite":"map at Predictor.scala:81","Parent IDs":[9],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":9,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"5\",\"name\":\"mapPartitions\"}","Callsite":"rdd at Predictor.scala:81","Parent IDs":[8],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":7,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"3\",\"name\":\"DeserializeToObject\"}","Callsite":"rdd at Predictor.scala:81","Parent IDs":[6],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":12,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"15\",\"name\":\"mapPartitions\"}","Callsite":"mapPartitions at LogisticRegression.scala:944","Parent IDs":[10],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":5,"Name":"ParallelCollectionRDD","Scope":"{\"id\":\"4\",\"name\":\"LocalTableScan\"}","Callsite":"rdd at Predictor.scala:81","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":8,"Name":"SQLExecutionRDD","Callsite":"rdd at Predictor.scala:81","Parent IDs":[7],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.rdd.RDD.treeAggregate(RDD.scala:1222)\norg.apache.spark.ml.optim.loss.RDDLossFunction.calculate(RDDLossFunction.scala:61)\norg.apache.spark.ml.optim.loss.RDDLossFunction.calculate(RDDLossFunction.scala:47)\nbreeze.optimize.CachedDiffFunction.calculate(CachedDiffFunction.scala:24)\nbreeze.optimize.LineSearch$$anon$1.calculate(LineSearch.scala:52)\nbreeze.optimize.LineSearch$$anon$1.calculate(LineSearch.scala:31)\nbreeze.optimize.StrongWolfeLineSearch.phi$1(StrongWolfe.scala:76)\nbreeze.optimize.StrongWolfeLineSearch.$anonfun$minimizeWithBound$7(StrongWolfe.scala:152)\nscala.collection.immutable.Range.foreach$mVc$sp(Range.scala:158)\nbreeze.optimize.StrongWolfeLineSearch.minimizeWithBound(StrongWolfe.scala:151)\nbreeze.optimize.StrongWolfeLineSearch.minimize(StrongWolfe.scala:62)\nbreeze.optimize.LBFGS.determineStepSize(LBFGS.scala:82)\nbreeze.optimize.LBFGS.determineStepSize(LBFGS.scala:38)\nbreeze.optimize.FirstOrderMinimizer.$anonfun$infiniteIterations$1(FirstOrderMinimizer.scala:61)\nscala.collection.Iterator$$anon$7.next(Iterator.scala:140)\nbreeze.util.IteratorImplicits$RichIterator$$anon$2.next(Implicits.scala:74)\norg.apache.spark.ml.classification.LogisticRegression.trainImpl(LogisticRegression.scala:971)\norg.apache.spark.ml.classification.LogisticRegression.$anonfun$train$1(LogisticRegression.scala:627)\norg.apache.spark.ml.util.Instrumentation$.$anonfun$instrumented$1(Instrumentation.scala:191)\nscala.util.Try$.apply(Try.scala:213)","Submission Time":1641575650959,"Completion Time":1641575651102,"Accumulables":[{"ID":252,"Name":"internal.metrics.executorDeserializeTime","Value":22,"Internal":true,"Count Failed Values":true},{"ID":253,"Name":"internal.metrics.executorDeserializeCpuTime","Value":10026242,"Internal":true,"Count Failed Values":true},{"ID":254,"Name":"internal.metrics.executorRunTime","Value":20,"Internal":true,"Count Failed Values":true},{"ID":255,"Name":"internal.metrics.executorCpuTime","Value":7355289,"Internal":true,"Count Failed Values":true},{"ID":256,"Name":"internal.metrics.resultSize","Value":20308,"Internal":true,"Count Failed Values":true},{"ID":273,"Name":"internal.metrics.input.bytesRead","Value":600,"Internal":true,"Count Failed Values":true},{"ID":274,"Name":"internal.metrics.input.recordsRead","Value":2,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0}}
{"Event":"SparkListenerJobEnd","Job ID":10,"Completion Time":1641575651102,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"SparkListenerJobStart","Job ID":11,"Submission Time":1641575651127,"Stage Infos":[{"Stage ID":11,"Stage Attempt ID":0,"Stage Name":"treeAggregate at RDDLossFunction.scala:61","Number of Tasks":2,"RDD Info":[{"RDD ID":24,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"49\",\"name\":\"treeAggregate\"}","Callsite":"treeAggregate at RDDLossFunction.scala:61","Parent IDs":[13],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":6,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"4\",\"name\":\"LocalTableScan\"}","Callsite":"rdd at Predictor.scala:81","Parent IDs":[5],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":13,"Name":"training blocks (blockSizeInMB=1.0)","Scope":"{\"id\":\"16\",\"name\":\"mapPartitions\"}","Callsite":"mapPartitions at Instance.scala:186","Parent IDs":[12],"Storage Level":{"Use Disk":true,"Use Memory":true,"Deserialized":true,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":10,"Name":"training instances","Scope":"{\"id\":\"6\",\"name\":\"map\"}","Callsite":"map at Predictor.scala:81","Parent IDs":[9],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":9,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"5\",\"name\":\"mapPartitions\"}","Callsite":"rdd at Predictor.scala:81","Parent IDs":[8],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":7,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"3\",\"name\":\"DeserializeToObject\"}","Callsite":"rdd at Predictor.scala:81","Parent IDs":[6],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":12,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"15\",\"name\":\"mapPartitions\"}","Callsite":"mapPartitions at LogisticRegression.scala:944","Parent IDs":[10],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":5,"Name":"ParallelCollectionRDD","Scope":"{\"id\":\"4\",\"name\":\"LocalTableScan\"}","Callsite":"rdd at Predictor.scala:81","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":8,"Name":"SQLExecutionRDD","Callsite":"rdd at Predictor.scala:81","Parent IDs":[7],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.rdd.RDD.treeAggregate(RDD.scala:1222)\norg.apache.spark.ml.optim.loss.RDDLossFunction.calculate(RDDLossFunction.scala:61)\norg.apache.spark.ml.optim.loss.RDDLossFunction.calculate(RDDLossFunction.scala:47)\nbreeze.optimize.CachedDiffFunction.calculate(CachedDiffFunction.scala:24)\nbreeze.optimize.LineSearch$$anon$1.calculate(LineSearch.scala:52)\nbreeze.optimize.LineSearch$$anon$1.calculate(LineSearch.scala:31)\nbreeze.optimize.StrongWolfeLineSearch.phi$1(StrongWolfe.scala:76)\nbreeze.optimize.StrongWolfeLineSearch.$anonfun$minimizeWithBound$7(StrongWolfe.scala:152)\nscala.collection.immutable.Range.foreach$mVc$sp(Range.scala:158)\nbreeze.optimize.StrongWolfeLineSearch.minimizeWithBound(StrongWolfe.scala:151)\nbreeze.optimize.StrongWolfeLineSearch.minimize(StrongWolfe.scala:62)\nbreeze.optimize.LBFGS.determineStepSize(LBFGS.scala:82)\nbreeze.optimize.LBFGS.determineStepSize(LBFGS.scala:38)\nbreeze.optimize.FirstOrderMinimizer.$anonfun$infiniteIterations$1(FirstOrderMinimizer.scala:61)\nscala.collection.Iterator$$anon$7.next(Iterator.scala:140)\nbreeze.util.IteratorImplicits$RichIterator$$anon$2.next(Implicits.scala:74)\norg.apache.spark.ml.classification.LogisticRegression.trainImpl(LogisticRegression.scala:971)\norg.apache.spark.ml.classification.LogisticRegression.$anonfun$train$1(LogisticRegression.scala:627)\norg.apache.spark.ml.util.Instrumentation$.$anonfun$instrumented$1(Instrumentation.scala:191)\nscala.util.Try$.apply(Try.scala:213)","Accumulables":[],"Resource Profile Id":0}],"Stage IDs":[11],"Properties":{"spark.rdd.scope":"{\"id\":\"49\",\"name\":\"treeAggregate\"}","spark.rdd.scope.noOverride":"true"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":11,"Stage Attempt ID":0,"Stage Name":"treeAggregate at RDDLossFunction.scala:61","Number of Tasks":2,"RDD Info":[{"RDD ID":24,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"49\",\"name\":\"treeAggregate\"}","Callsite":"treeAggregate at RDDLossFunction.scala:61","Parent IDs":[13],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":6,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"4\",\"name\":\"LocalTableScan\"}","Callsite":"rdd at Predictor.scala:81","Parent IDs":[5],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":13,"Name":"training blocks (blockSizeInMB=1.0)","Scope":"{\"id\":\"16\",\"name\":\"mapPartitions\"}","Callsite":"mapPartitions at Instance.scala:186","Parent IDs":[12],"Storage Level":{"Use Disk":true,"Use Memory":true,"Deserialized":true,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":10,"Name":"training instances","Scope":"{\"id\":\"6\",\"name\":\"map\"}","Callsite":"map at Predictor.scala:81","Parent IDs":[9],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":9,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"5\",\"name\":\"mapPartitions\"}","Callsite":"rdd at Predictor.scala:81","Parent IDs":[8],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":7,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"3\",\"name\":\"DeserializeToObject\"}","Callsite":"rdd at Predictor.scala:81","Parent IDs":[6],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":12,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"15\",\"name\":\"mapPartitions\"}","Callsite":"mapPartitions at LogisticRegression.scala:944","Parent IDs":[10],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":5,"Name":"ParallelCollectionRDD","Scope":"{\"id\":\"4\",\"name\":\"LocalTableScan\"}","Callsite":"rdd at Predictor.scala:81","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":8,"Name":"SQLExecutionRDD","Callsite":"rdd at Predictor.scala:81","Parent IDs":[7],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.rdd.RDD.treeAggregate(RDD.scala:1222)\norg.apache.spark.ml.optim.loss.RDDLossFunction.calculate(RDDLossFunction.scala:61)\norg.apache.spark.ml.optim.loss.RDDLossFunction.calculate(RDDLossFunction.scala:47)\nbreeze.optimize.CachedDiffFunction.calculate(CachedDiffFunction.scala:24)\nbreeze.optimize.LineSearch$$anon$1.calculate(LineSearch.scala:52)\nbreeze.optimize.LineSearch$$anon$1.calculate(LineSearch.scala:31)\nbreeze.optimize.StrongWolfeLineSearch.phi$1(StrongWolfe.scala:76)\nbreeze.optimize.StrongWolfeLineSearch.$anonfun$minimizeWithBound$7(StrongWolfe.scala:152)\nscala.collection.immutable.Range.foreach$mVc$sp(Range.scala:158)\nbreeze.optimize.StrongWolfeLineSearch.minimizeWithBound(StrongWolfe.scala:151)\nbreeze.optimize.StrongWolfeLineSearch.minimize(StrongWolfe.scala:62)\nbreeze.optimize.LBFGS.determineStepSize(LBFGS.scala:82)\nbreeze.optimize.LBFGS.determineStepSize(LBFGS.scala:38)\nbreeze.optimize.FirstOrderMinimizer.$anonfun$infiniteIterations$1(FirstOrderMinimizer.scala:61)\nscala.collection.Iterator$$anon$7.next(Iterator.scala:140)\nbreeze.util.IteratorImplicits$RichIterator$$anon$2.next(Implicits.scala:74)\norg.apache.spark.ml.classification.LogisticRegression.trainImpl(LogisticRegression.scala:971)\norg.apache.spark.ml.classification.LogisticRegression.$anonfun$train$1(LogisticRegression.scala:627)\norg.apache.spark.ml.util.Instrumentation$.$anonfun$instrumented$1(Instrumentation.scala:191)\nscala.util.Try$.apply(Try.scala:213)","Submission Time":1641575651128,"Accumulables":[],"Resource Profile Id":0},"Properties":{"resource.executor.cores":"2","spark.rdd.scope":"{\"id\":\"49\",\"name\":\"treeAggregate\"}","spark.rdd.scope.noOverride":"true"}}
{"Event":"SparkListenerTaskStart","Stage ID":11,"Stage Attempt ID":0,"Task Info":{"Task ID":22,"Index":0,"Attempt":0,"Launch Time":1641575651134,"Executor ID":"1","Host":"host-name","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskStart","Stage ID":11,"Stage Attempt ID":0,"Task Info":{"Task ID":23,"Index":1,"Attempt":0,"Launch Time":1641575651134,"Executor ID":"1","Host":"host-name","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":11,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":22,"Index":0,"Attempt":0,"Launch Time":1641575651134,"Executor ID":"1","Host":"host-name","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1641575651160,"Failed":false,"Killed":false,"Accumulables":[{"ID":277,"Name":"internal.metrics.executorDeserializeTime","Update":11,"Value":11,"Internal":true,"Count Failed Values":true},{"ID":278,"Name":"internal.metrics.executorDeserializeCpuTime","Update":7276154,"Value":7276154,"Internal":true,"Count Failed Values":true},{"ID":279,"Name":"internal.metrics.executorRunTime","Update":9,"Value":9,"Internal":true,"Count Failed Values":true},{"ID":280,"Name":"internal.metrics.executorCpuTime","Update":1449051,"Value":1449051,"Internal":true,"Count Failed Values":true},{"ID":281,"Name":"internal.metrics.resultSize","Update":10154,"Value":10154,"Internal":true,"Count Failed Values":true},{"ID":298,"Name":"internal.metrics.input.bytesRead","Update":312,"Value":312,"Internal":true,"Count Failed Values":true},{"ID":299,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0},"Task Metrics":{"Executor Deserialize Time":11,"Executor Deserialize CPU Time":7276154,"Executor Run Time":9,"Executor CPU Time":1449051,"Peak Execution Memory":0,"Result Size":10154,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":312,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":11,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":23,"Index":1,"Attempt":0,"Launch Time":1641575651134,"Executor ID":"1","Host":"host-name","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1641575651160,"Failed":false,"Killed":false,"Accumulables":[{"ID":277,"Name":"internal.metrics.executorDeserializeTime","Update":11,"Value":22,"Internal":true,"Count Failed Values":true},{"ID":278,"Name":"internal.metrics.executorDeserializeCpuTime","Update":2856645,"Value":10132799,"Internal":true,"Count Failed Values":true},{"ID":279,"Name":"internal.metrics.executorRunTime","Update":9,"Value":18,"Internal":true,"Count Failed Values":true},{"ID":280,"Name":"internal.metrics.executorCpuTime","Update":5768608,"Value":7217659,"Internal":true,"Count Failed Values":true},{"ID":281,"Name":"internal.metrics.resultSize","Update":10154,"Value":20308,"Internal":true,"Count Failed Values":true},{"ID":298,"Name":"internal.metrics.input.bytesRead","Update":288,"Value":600,"Internal":true,"Count Failed Values":true},{"ID":299,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":2,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0},"Task Metrics":{"Executor Deserialize Time":11,"Executor Deserialize CPU Time":2856645,"Executor Run Time":9,"Executor CPU Time":5768608,"Peak Execution Memory":0,"Result Size":10154,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":288,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":11,"Stage Attempt ID":0,"Stage Name":"treeAggregate at RDDLossFunction.scala:61","Number of Tasks":2,"RDD Info":[{"RDD ID":24,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"49\",\"name\":\"treeAggregate\"}","Callsite":"treeAggregate at RDDLossFunction.scala:61","Parent IDs":[13],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":6,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"4\",\"name\":\"LocalTableScan\"}","Callsite":"rdd at Predictor.scala:81","Parent IDs":[5],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":13,"Name":"training blocks (blockSizeInMB=1.0)","Scope":"{\"id\":\"16\",\"name\":\"mapPartitions\"}","Callsite":"mapPartitions at Instance.scala:186","Parent IDs":[12],"Storage Level":{"Use Disk":true,"Use Memory":true,"Deserialized":true,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":10,"Name":"training instances","Scope":"{\"id\":\"6\",\"name\":\"map\"}","Callsite":"map at Predictor.scala:81","Parent IDs":[9],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":9,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"5\",\"name\":\"mapPartitions\"}","Callsite":"rdd at Predictor.scala:81","Parent IDs":[8],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":7,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"3\",\"name\":\"DeserializeToObject\"}","Callsite":"rdd at Predictor.scala:81","Parent IDs":[6],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":12,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"15\",\"name\":\"mapPartitions\"}","Callsite":"mapPartitions at LogisticRegression.scala:944","Parent IDs":[10],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":5,"Name":"ParallelCollectionRDD","Scope":"{\"id\":\"4\",\"name\":\"LocalTableScan\"}","Callsite":"rdd at Predictor.scala:81","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":8,"Name":"SQLExecutionRDD","Callsite":"rdd at Predictor.scala:81","Parent IDs":[7],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.rdd.RDD.treeAggregate(RDD.scala:1222)\norg.apache.spark.ml.optim.loss.RDDLossFunction.calculate(RDDLossFunction.scala:61)\norg.apache.spark.ml.optim.loss.RDDLossFunction.calculate(RDDLossFunction.scala:47)\nbreeze.optimize.CachedDiffFunction.calculate(CachedDiffFunction.scala:24)\nbreeze.optimize.LineSearch$$anon$1.calculate(LineSearch.scala:52)\nbreeze.optimize.LineSearch$$anon$1.calculate(LineSearch.scala:31)\nbreeze.optimize.StrongWolfeLineSearch.phi$1(StrongWolfe.scala:76)\nbreeze.optimize.StrongWolfeLineSearch.$anonfun$minimizeWithBound$7(StrongWolfe.scala:152)\nscala.collection.immutable.Range.foreach$mVc$sp(Range.scala:158)\nbreeze.optimize.StrongWolfeLineSearch.minimizeWithBound(StrongWolfe.scala:151)\nbreeze.optimize.StrongWolfeLineSearch.minimize(StrongWolfe.scala:62)\nbreeze.optimize.LBFGS.determineStepSize(LBFGS.scala:82)\nbreeze.optimize.LBFGS.determineStepSize(LBFGS.scala:38)\nbreeze.optimize.FirstOrderMinimizer.$anonfun$infiniteIterations$1(FirstOrderMinimizer.scala:61)\nscala.collection.Iterator$$anon$7.next(Iterator.scala:140)\nbreeze.util.IteratorImplicits$RichIterator$$anon$2.next(Implicits.scala:74)\norg.apache.spark.ml.classification.LogisticRegression.trainImpl(LogisticRegression.scala:971)\norg.apache.spark.ml.classification.LogisticRegression.$anonfun$train$1(LogisticRegression.scala:627)\norg.apache.spark.ml.util.Instrumentation$.$anonfun$instrumented$1(Instrumentation.scala:191)\nscala.util.Try$.apply(Try.scala:213)","Submission Time":1641575651128,"Completion Time":1641575651161,"Accumulables":[{"ID":277,"Name":"internal.metrics.executorDeserializeTime","Value":22,"Internal":true,"Count Failed Values":true},{"ID":278,"Name":"internal.metrics.executorDeserializeCpuTime","Value":10132799,"Internal":true,"Count Failed Values":true},{"ID":279,"Name":"internal.metrics.executorRunTime","Value":18,"Internal":true,"Count Failed Values":true},{"ID":280,"Name":"internal.metrics.executorCpuTime","Value":7217659,"Internal":true,"Count Failed Values":true},{"ID":281,"Name":"internal.metrics.resultSize","Value":20308,"Internal":true,"Count Failed Values":true},{"ID":298,"Name":"internal.metrics.input.bytesRead","Value":600,"Internal":true,"Count Failed Values":true},{"ID":299,"Name":"internal.metrics.input.recordsRead","Value":2,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0}}
{"Event":"SparkListenerJobEnd","Job ID":11,"Completion Time":1641575651161,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"SparkListenerUnpersistRDD","RDD ID":13}
{"Event":"SparkListenerJobStart","Job ID":12,"Submission Time":1641575652201,"Stage Infos":[{"Stage ID":12,"Stage Attempt ID":0,"Stage Name":"runJob at SparkHadoopWriter.scala:83","Number of Tasks":1,"RDD Info":[{"RDD ID":39,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"62\",\"name\":\"saveAsTextFile\"}","Callsite":"saveAsTextFile at ReadWrite.scala:413","Parent IDs":[38],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":38,"Name":"ParallelCollectionRDD","Scope":"{\"id\":\"61\",\"name\":\"parallelize\"}","Callsite":"parallelize at ReadWrite.scala:413","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.SparkContext.runJob(SparkContext.scala:2249)\norg.apache.spark.internal.io.SparkHadoopWriter$.write(SparkHadoopWriter.scala:83)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopDataset$1(PairRDDFunctions.scala:1090)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:414)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopDataset(PairRDDFunctions.scala:1088)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopFile$4(PairRDDFunctions.scala:1061)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:414)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1026)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopFile$3(PairRDDFunctions.scala:1008)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:414)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1007)","Accumulables":[],"Resource Profile Id":0}],"Stage IDs":[12],"Properties":{"spark.rdd.scope":"{\"id\":\"62\",\"name\":\"saveAsTextFile\"}","spark.rdd.scope.noOverride":"true"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":12,"Stage Attempt ID":0,"Stage Name":"runJob at SparkHadoopWriter.scala:83","Number of Tasks":1,"RDD Info":[{"RDD ID":39,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"62\",\"name\":\"saveAsTextFile\"}","Callsite":"saveAsTextFile at ReadWrite.scala:413","Parent IDs":[38],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":38,"Name":"ParallelCollectionRDD","Scope":"{\"id\":\"61\",\"name\":\"parallelize\"}","Callsite":"parallelize at ReadWrite.scala:413","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.SparkContext.runJob(SparkContext.scala:2249)\norg.apache.spark.internal.io.SparkHadoopWriter$.write(SparkHadoopWriter.scala:83)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopDataset$1(PairRDDFunctions.scala:1090)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:414)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopDataset(PairRDDFunctions.scala:1088)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopFile$4(PairRDDFunctions.scala:1061)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:414)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1026)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopFile$3(PairRDDFunctions.scala:1008)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:414)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1007)","Submission Time":1641575652202,"Accumulables":[],"Resource Profile Id":0},"Properties":{"resource.executor.cores":"2","spark.rdd.scope":"{\"id\":\"62\",\"name\":\"saveAsTextFile\"}","spark.rdd.scope.noOverride":"true"}}
{"Event":"SparkListenerTaskStart","Stage ID":12,"Stage Attempt ID":0,"Task Info":{"Task ID":24,"Index":0,"Attempt":0,"Launch Time":1641575652217,"Executor ID":"1","Host":"host-name","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerUnpersistRDD","RDD ID":13}
{"Event":"SparkListenerTaskEnd","Stage ID":12,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":24,"Index":0,"Attempt":0,"Launch Time":1641575652217,"Executor ID":"1","Host":"host-name","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1641575654170,"Failed":false,"Killed":false,"Accumulables":[{"ID":304,"Name":"internal.metrics.executorDeserializeTime","Update":47,"Value":47,"Internal":true,"Count Failed Values":true},{"ID":305,"Name":"internal.metrics.executorDeserializeCpuTime","Update":40301267,"Value":40301267,"Internal":true,"Count Failed Values":true},{"ID":306,"Name":"internal.metrics.executorRunTime","Update":1899,"Value":1899,"Internal":true,"Count Failed Values":true},{"ID":307,"Name":"internal.metrics.executorCpuTime","Update":385620953,"Value":385620953,"Internal":true,"Count Failed Values":true},{"ID":308,"Name":"internal.metrics.resultSize","Update":1201,"Value":1201,"Internal":true,"Count Failed Values":true},{"ID":309,"Name":"internal.metrics.jvmGCTime","Update":7,"Value":7,"Internal":true,"Count Failed Values":true},{"ID":327,"Name":"internal.metrics.output.bytesWritten","Update":239,"Value":239,"Internal":true,"Count Failed Values":true},{"ID":328,"Name":"internal.metrics.output.recordsWritten","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0},"Task Metrics":{"Executor Deserialize Time":47,"Executor Deserialize CPU Time":40301267,"Executor Run Time":1899,"Executor CPU Time":385620953,"Peak Execution Memory":0,"Result Size":1201,"JVM GC Time":7,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":0},"Output Metrics":{"Bytes Written":239,"Records Written":1},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":12,"Stage Attempt ID":0,"Stage Name":"runJob at SparkHadoopWriter.scala:83","Number of Tasks":1,"RDD Info":[{"RDD ID":39,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"62\",\"name\":\"saveAsTextFile\"}","Callsite":"saveAsTextFile at ReadWrite.scala:413","Parent IDs":[38],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":38,"Name":"ParallelCollectionRDD","Scope":"{\"id\":\"61\",\"name\":\"parallelize\"}","Callsite":"parallelize at ReadWrite.scala:413","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.SparkContext.runJob(SparkContext.scala:2249)\norg.apache.spark.internal.io.SparkHadoopWriter$.write(SparkHadoopWriter.scala:83)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopDataset$1(PairRDDFunctions.scala:1090)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:414)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopDataset(PairRDDFunctions.scala:1088)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopFile$4(PairRDDFunctions.scala:1061)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:414)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1026)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopFile$3(PairRDDFunctions.scala:1008)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:414)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1007)","Submission Time":1641575652202,"Completion Time":1641575654170,"Accumulables":[{"ID":304,"Name":"internal.metrics.executorDeserializeTime","Value":47,"Internal":true,"Count Failed Values":true},{"ID":305,"Name":"internal.metrics.executorDeserializeCpuTime","Value":40301267,"Internal":true,"Count Failed Values":true},{"ID":306,"Name":"internal.metrics.executorRunTime","Value":1899,"Internal":true,"Count Failed Values":true},{"ID":307,"Name":"internal.metrics.executorCpuTime","Value":385620953,"Internal":true,"Count Failed Values":true},{"ID":308,"Name":"internal.metrics.resultSize","Value":1201,"Internal":true,"Count Failed Values":true},{"ID":309,"Name":"internal.metrics.jvmGCTime","Value":7,"Internal":true,"Count Failed Values":true},{"ID":327,"Name":"internal.metrics.output.bytesWritten","Value":239,"Internal":true,"Count Failed Values":true},{"ID":328,"Name":"internal.metrics.output.recordsWritten","Value":1,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0}}
{"Event":"SparkListenerJobEnd","Job ID":12,"Completion Time":1641575654170,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"SparkListenerJobStart","Job ID":13,"Submission Time":1641575654868,"Stage Infos":[{"Stage ID":13,"Stage Attempt ID":0,"Stage Name":"runJob at SparkHadoopWriter.scala:83","Number of Tasks":1,"RDD Info":[{"RDD ID":41,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"66\",\"name\":\"saveAsTextFile\"}","Callsite":"saveAsTextFile at ReadWrite.scala:413","Parent IDs":[40],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":40,"Name":"ParallelCollectionRDD","Scope":"{\"id\":\"65\",\"name\":\"parallelize\"}","Callsite":"parallelize at ReadWrite.scala:413","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.SparkContext.runJob(SparkContext.scala:2249)\norg.apache.spark.internal.io.SparkHadoopWriter$.write(SparkHadoopWriter.scala:83)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopDataset$1(PairRDDFunctions.scala:1090)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:414)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopDataset(PairRDDFunctions.scala:1088)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopFile$4(PairRDDFunctions.scala:1061)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:414)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1026)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopFile$3(PairRDDFunctions.scala:1008)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:414)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1007)","Accumulables":[],"Resource Profile Id":0}],"Stage IDs":[13],"Properties":{"spark.rdd.scope":"{\"id\":\"66\",\"name\":\"saveAsTextFile\"}","spark.rdd.scope.noOverride":"true"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":13,"Stage Attempt ID":0,"Stage Name":"runJob at SparkHadoopWriter.scala:83","Number of Tasks":1,"RDD Info":[{"RDD ID":41,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"66\",\"name\":\"saveAsTextFile\"}","Callsite":"saveAsTextFile at ReadWrite.scala:413","Parent IDs":[40],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":40,"Name":"ParallelCollectionRDD","Scope":"{\"id\":\"65\",\"name\":\"parallelize\"}","Callsite":"parallelize at ReadWrite.scala:413","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.SparkContext.runJob(SparkContext.scala:2249)\norg.apache.spark.internal.io.SparkHadoopWriter$.write(SparkHadoopWriter.scala:83)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopDataset$1(PairRDDFunctions.scala:1090)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:414)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopDataset(PairRDDFunctions.scala:1088)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopFile$4(PairRDDFunctions.scala:1061)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:414)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1026)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopFile$3(PairRDDFunctions.scala:1008)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:414)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1007)","Submission Time":1641575654869,"Accumulables":[],"Resource Profile Id":0},"Properties":{"resource.executor.cores":"2","spark.rdd.scope":"{\"id\":\"66\",\"name\":\"saveAsTextFile\"}","spark.rdd.scope.noOverride":"true"}}
{"Event":"SparkListenerTaskStart","Stage ID":13,"Stage Attempt ID":0,"Task Info":{"Task ID":25,"Index":0,"Attempt":0,"Launch Time":1641575654881,"Executor ID":"1","Host":"host-name","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":13,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":25,"Index":0,"Attempt":0,"Launch Time":1641575654881,"Executor ID":"1","Host":"host-name","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1641575655287,"Failed":false,"Killed":false,"Accumulables":[{"ID":329,"Name":"internal.metrics.executorDeserializeTime","Update":14,"Value":14,"Internal":true,"Count Failed Values":true},{"ID":330,"Name":"internal.metrics.executorDeserializeCpuTime","Update":10208467,"Value":10208467,"Internal":true,"Count Failed Values":true},{"ID":331,"Name":"internal.metrics.executorRunTime","Update":383,"Value":383,"Internal":true,"Count Failed Values":true},{"ID":332,"Name":"internal.metrics.executorCpuTime","Update":30210956,"Value":30210956,"Internal":true,"Count Failed Values":true},{"ID":333,"Name":"internal.metrics.resultSize","Update":1158,"Value":1158,"Internal":true,"Count Failed Values":true},{"ID":352,"Name":"internal.metrics.output.bytesWritten","Update":234,"Value":234,"Internal":true,"Count Failed Values":true},{"ID":353,"Name":"internal.metrics.output.recordsWritten","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0},"Task Metrics":{"Executor Deserialize Time":14,"Executor Deserialize CPU Time":10208467,"Executor Run Time":383,"Executor CPU Time":30210956,"Peak Execution Memory":0,"Result Size":1158,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":0},"Output Metrics":{"Bytes Written":234,"Records Written":1},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":13,"Stage Attempt ID":0,"Stage Name":"runJob at SparkHadoopWriter.scala:83","Number of Tasks":1,"RDD Info":[{"RDD ID":41,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"66\",\"name\":\"saveAsTextFile\"}","Callsite":"saveAsTextFile at ReadWrite.scala:413","Parent IDs":[40],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":40,"Name":"ParallelCollectionRDD","Scope":"{\"id\":\"65\",\"name\":\"parallelize\"}","Callsite":"parallelize at ReadWrite.scala:413","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.SparkContext.runJob(SparkContext.scala:2249)\norg.apache.spark.internal.io.SparkHadoopWriter$.write(SparkHadoopWriter.scala:83)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopDataset$1(PairRDDFunctions.scala:1090)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:414)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopDataset(PairRDDFunctions.scala:1088)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopFile$4(PairRDDFunctions.scala:1061)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:414)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1026)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopFile$3(PairRDDFunctions.scala:1008)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:414)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1007)","Submission Time":1641575654869,"Completion Time":1641575655289,"Accumulables":[{"ID":329,"Name":"internal.metrics.executorDeserializeTime","Value":14,"Internal":true,"Count Failed Values":true},{"ID":330,"Name":"internal.metrics.executorDeserializeCpuTime","Value":10208467,"Internal":true,"Count Failed Values":true},{"ID":331,"Name":"internal.metrics.executorRunTime","Value":383,"Internal":true,"Count Failed Values":true},{"ID":332,"Name":"internal.metrics.executorCpuTime","Value":30210956,"Internal":true,"Count Failed Values":true},{"ID":333,"Name":"internal.metrics.resultSize","Value":1158,"Internal":true,"Count Failed Values":true},{"ID":352,"Name":"internal.metrics.output.bytesWritten","Value":234,"Internal":true,"Count Failed Values":true},{"ID":353,"Name":"internal.metrics.output.recordsWritten","Value":1,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0}}
{"Event":"SparkListenerJobEnd","Job ID":13,"Completion Time":1641575655290,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"SparkListenerJobStart","Job ID":14,"Submission Time":1641575655606,"Stage Infos":[{"Stage ID":14,"Stage Attempt ID":0,"Stage Name":"runJob at SparkHadoopWriter.scala:83","Number of Tasks":1,"RDD Info":[{"RDD ID":43,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"70\",\"name\":\"saveAsTextFile\"}","Callsite":"saveAsTextFile at ReadWrite.scala:413","Parent IDs":[42],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":42,"Name":"ParallelCollectionRDD","Scope":"{\"id\":\"69\",\"name\":\"parallelize\"}","Callsite":"parallelize at ReadWrite.scala:413","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.SparkContext.runJob(SparkContext.scala:2249)\norg.apache.spark.internal.io.SparkHadoopWriter$.write(SparkHadoopWriter.scala:83)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopDataset$1(PairRDDFunctions.scala:1090)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:414)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopDataset(PairRDDFunctions.scala:1088)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopFile$4(PairRDDFunctions.scala:1061)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:414)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1026)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopFile$3(PairRDDFunctions.scala:1008)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:414)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1007)","Accumulables":[],"Resource Profile Id":0}],"Stage IDs":[14],"Properties":{"spark.rdd.scope":"{\"id\":\"70\",\"name\":\"saveAsTextFile\"}","spark.rdd.scope.noOverride":"true"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":14,"Stage Attempt ID":0,"Stage Name":"runJob at SparkHadoopWriter.scala:83","Number of Tasks":1,"RDD Info":[{"RDD ID":43,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"70\",\"name\":\"saveAsTextFile\"}","Callsite":"saveAsTextFile at ReadWrite.scala:413","Parent IDs":[42],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":42,"Name":"ParallelCollectionRDD","Scope":"{\"id\":\"69\",\"name\":\"parallelize\"}","Callsite":"parallelize at ReadWrite.scala:413","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.SparkContext.runJob(SparkContext.scala:2249)\norg.apache.spark.internal.io.SparkHadoopWriter$.write(SparkHadoopWriter.scala:83)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopDataset$1(PairRDDFunctions.scala:1090)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:414)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopDataset(PairRDDFunctions.scala:1088)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopFile$4(PairRDDFunctions.scala:1061)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:414)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1026)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopFile$3(PairRDDFunctions.scala:1008)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:414)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1007)","Submission Time":1641575655608,"Accumulables":[],"Resource Profile Id":0},"Properties":{"resource.executor.cores":"2","spark.rdd.scope":"{\"id\":\"70\",\"name\":\"saveAsTextFile\"}","spark.rdd.scope.noOverride":"true"}}
{"Event":"SparkListenerTaskStart","Stage ID":14,"Stage Attempt ID":0,"Task Info":{"Task ID":26,"Index":0,"Attempt":0,"Launch Time":1641575655639,"Executor ID":"1","Host":"host-name","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":14,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":26,"Index":0,"Attempt":0,"Launch Time":1641575655639,"Executor ID":"1","Host":"host-name","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1641575655960,"Failed":false,"Killed":false,"Accumulables":[{"ID":354,"Name":"internal.metrics.executorDeserializeTime","Update":15,"Value":15,"Internal":true,"Count Failed Values":true},{"ID":355,"Name":"internal.metrics.executorDeserializeCpuTime","Update":10754782,"Value":10754782,"Internal":true,"Count Failed Values":true},{"ID":356,"Name":"internal.metrics.executorRunTime","Update":295,"Value":295,"Internal":true,"Count Failed Values":true},{"ID":357,"Name":"internal.metrics.executorCpuTime","Update":10682551,"Value":10682551,"Internal":true,"Count Failed Values":true},{"ID":358,"Name":"internal.metrics.resultSize","Update":1158,"Value":1158,"Internal":true,"Count Failed Values":true},{"ID":377,"Name":"internal.metrics.output.bytesWritten","Update":305,"Value":305,"Internal":true,"Count Failed Values":true},{"ID":378,"Name":"internal.metrics.output.recordsWritten","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0},"Task Metrics":{"Executor Deserialize Time":15,"Executor Deserialize CPU Time":10754782,"Executor Run Time":295,"Executor CPU Time":10682551,"Peak Execution Memory":0,"Result Size":1158,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":0},"Output Metrics":{"Bytes Written":305,"Records Written":1},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":14,"Stage Attempt ID":0,"Stage Name":"runJob at SparkHadoopWriter.scala:83","Number of Tasks":1,"RDD Info":[{"RDD ID":43,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"70\",\"name\":\"saveAsTextFile\"}","Callsite":"saveAsTextFile at ReadWrite.scala:413","Parent IDs":[42],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":42,"Name":"ParallelCollectionRDD","Scope":"{\"id\":\"69\",\"name\":\"parallelize\"}","Callsite":"parallelize at ReadWrite.scala:413","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.SparkContext.runJob(SparkContext.scala:2249)\norg.apache.spark.internal.io.SparkHadoopWriter$.write(SparkHadoopWriter.scala:83)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopDataset$1(PairRDDFunctions.scala:1090)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:414)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopDataset(PairRDDFunctions.scala:1088)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopFile$4(PairRDDFunctions.scala:1061)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:414)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1026)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopFile$3(PairRDDFunctions.scala:1008)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:414)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1007)","Submission Time":1641575655608,"Completion Time":1641575655961,"Accumulables":[{"ID":354,"Name":"internal.metrics.executorDeserializeTime","Value":15,"Internal":true,"Count Failed Values":true},{"ID":355,"Name":"internal.metrics.executorDeserializeCpuTime","Value":10754782,"Internal":true,"Count Failed Values":true},{"ID":356,"Name":"internal.metrics.executorRunTime","Value":295,"Internal":true,"Count Failed Values":true},{"ID":357,"Name":"internal.metrics.executorCpuTime","Value":10682551,"Internal":true,"Count Failed Values":true},{"ID":358,"Name":"internal.metrics.resultSize","Value":1158,"Internal":true,"Count Failed Values":true},{"ID":377,"Name":"internal.metrics.output.bytesWritten","Value":305,"Internal":true,"Count Failed Values":true},{"ID":378,"Name":"internal.metrics.output.recordsWritten","Value":1,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0}}
{"Event":"SparkListenerJobEnd","Job ID":14,"Completion Time":1641575655962,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"SparkListenerJobStart","Job ID":15,"Submission Time":1641575656304,"Stage Infos":[{"Stage ID":15,"Stage Attempt ID":0,"Stage Name":"runJob at SparkHadoopWriter.scala:83","Number of Tasks":1,"RDD Info":[{"RDD ID":45,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"74\",\"name\":\"saveAsTextFile\"}","Callsite":"saveAsTextFile at ReadWrite.scala:413","Parent IDs":[44],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":44,"Name":"ParallelCollectionRDD","Scope":"{\"id\":\"73\",\"name\":\"parallelize\"}","Callsite":"parallelize at ReadWrite.scala:413","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.SparkContext.runJob(SparkContext.scala:2249)\norg.apache.spark.internal.io.SparkHadoopWriter$.write(SparkHadoopWriter.scala:83)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopDataset$1(PairRDDFunctions.scala:1090)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:414)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopDataset(PairRDDFunctions.scala:1088)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopFile$4(PairRDDFunctions.scala:1061)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:414)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1026)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopFile$3(PairRDDFunctions.scala:1008)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:414)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1007)","Accumulables":[],"Resource Profile Id":0}],"Stage IDs":[15],"Properties":{"spark.rdd.scope":"{\"id\":\"74\",\"name\":\"saveAsTextFile\"}","spark.rdd.scope.noOverride":"true"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":15,"Stage Attempt ID":0,"Stage Name":"runJob at SparkHadoopWriter.scala:83","Number of Tasks":1,"RDD Info":[{"RDD ID":45,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"74\",\"name\":\"saveAsTextFile\"}","Callsite":"saveAsTextFile at ReadWrite.scala:413","Parent IDs":[44],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":44,"Name":"ParallelCollectionRDD","Scope":"{\"id\":\"73\",\"name\":\"parallelize\"}","Callsite":"parallelize at ReadWrite.scala:413","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.SparkContext.runJob(SparkContext.scala:2249)\norg.apache.spark.internal.io.SparkHadoopWriter$.write(SparkHadoopWriter.scala:83)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopDataset$1(PairRDDFunctions.scala:1090)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:414)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopDataset(PairRDDFunctions.scala:1088)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopFile$4(PairRDDFunctions.scala:1061)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:414)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1026)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopFile$3(PairRDDFunctions.scala:1008)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:414)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1007)","Submission Time":1641575656305,"Accumulables":[],"Resource Profile Id":0},"Properties":{"resource.executor.cores":"2","spark.rdd.scope":"{\"id\":\"74\",\"name\":\"saveAsTextFile\"}","spark.rdd.scope.noOverride":"true"}}
{"Event":"SparkListenerTaskStart","Stage ID":15,"Stage Attempt ID":0,"Task Info":{"Task ID":27,"Index":0,"Attempt":0,"Launch Time":1641575656323,"Executor ID":"1","Host":"host-name","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":15,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":27,"Index":0,"Attempt":0,"Launch Time":1641575656323,"Executor ID":"1","Host":"host-name","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1641575656557,"Failed":false,"Killed":false,"Accumulables":[{"ID":379,"Name":"internal.metrics.executorDeserializeTime","Update":14,"Value":14,"Internal":true,"Count Failed Values":true},{"ID":380,"Name":"internal.metrics.executorDeserializeCpuTime","Update":10976150,"Value":10976150,"Internal":true,"Count Failed Values":true},{"ID":381,"Name":"internal.metrics.executorRunTime","Update":212,"Value":212,"Internal":true,"Count Failed Values":true},{"ID":382,"Name":"internal.metrics.executorCpuTime","Update":10731463,"Value":10731463,"Internal":true,"Count Failed Values":true},{"ID":383,"Name":"internal.metrics.resultSize","Update":1158,"Value":1158,"Internal":true,"Count Failed Values":true},{"ID":402,"Name":"internal.metrics.output.bytesWritten","Update":533,"Value":533,"Internal":true,"Count Failed Values":true},{"ID":403,"Name":"internal.metrics.output.recordsWritten","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0},"Task Metrics":{"Executor Deserialize Time":14,"Executor Deserialize CPU Time":10976150,"Executor Run Time":212,"Executor CPU Time":10731463,"Peak Execution Memory":0,"Result Size":1158,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":0},"Output Metrics":{"Bytes Written":533,"Records Written":1},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":15,"Stage Attempt ID":0,"Stage Name":"runJob at SparkHadoopWriter.scala:83","Number of Tasks":1,"RDD Info":[{"RDD ID":45,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"74\",\"name\":\"saveAsTextFile\"}","Callsite":"saveAsTextFile at ReadWrite.scala:413","Parent IDs":[44],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":44,"Name":"ParallelCollectionRDD","Scope":"{\"id\":\"73\",\"name\":\"parallelize\"}","Callsite":"parallelize at ReadWrite.scala:413","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.SparkContext.runJob(SparkContext.scala:2249)\norg.apache.spark.internal.io.SparkHadoopWriter$.write(SparkHadoopWriter.scala:83)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopDataset$1(PairRDDFunctions.scala:1090)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:414)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopDataset(PairRDDFunctions.scala:1088)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopFile$4(PairRDDFunctions.scala:1061)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:414)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1026)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopFile$3(PairRDDFunctions.scala:1008)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:414)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1007)","Submission Time":1641575656305,"Completion Time":1641575656557,"Accumulables":[{"ID":379,"Name":"internal.metrics.executorDeserializeTime","Value":14,"Internal":true,"Count Failed Values":true},{"ID":380,"Name":"internal.metrics.executorDeserializeCpuTime","Value":10976150,"Internal":true,"Count Failed Values":true},{"ID":381,"Name":"internal.metrics.executorRunTime","Value":212,"Internal":true,"Count Failed Values":true},{"ID":382,"Name":"internal.metrics.executorCpuTime","Value":10731463,"Internal":true,"Count Failed Values":true},{"ID":383,"Name":"internal.metrics.resultSize","Value":1158,"Internal":true,"Count Failed Values":true},{"ID":402,"Name":"internal.metrics.output.bytesWritten","Value":533,"Internal":true,"Count Failed Values":true},{"ID":403,"Name":"internal.metrics.output.recordsWritten","Value":1,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0}}
{"Event":"SparkListenerJobEnd","Job ID":15,"Completion Time":1641575656558,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":0,"description":"parquet at LogisticRegression.scala:1288","details":"org.apache.spark.sql.DataFrameWriter.parquet(DataFrameWriter.scala:874)\norg.apache.spark.ml.classification.LogisticRegressionModel$LogisticRegressionModelWriter.saveImpl(LogisticRegression.scala:1288)\norg.apache.spark.ml.util.MLWriter.save(ReadWrite.scala:168)\norg.apache.spark.ml.Pipeline$SharedReadWrite$.$anonfun$saveImpl$5(Pipeline.scala:257)\norg.apache.spark.ml.MLEvents.withSaveInstanceEvent(events.scala:174)\norg.apache.spark.ml.MLEvents.withSaveInstanceEvent$(events.scala:169)\norg.apache.spark.ml.util.Instrumentation.withSaveInstanceEvent(Instrumentation.scala:42)\norg.apache.spark.ml.Pipeline$SharedReadWrite$.$anonfun$saveImpl$4(Pipeline.scala:257)\norg.apache.spark.ml.Pipeline$SharedReadWrite$.$anonfun$saveImpl$4$adapted(Pipeline.scala:254)\nscala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)\nscala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)\nscala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)\norg.apache.spark.ml.Pipeline$SharedReadWrite$.$anonfun$saveImpl$1(Pipeline.scala:254)\norg.apache.spark.ml.Pipeline$SharedReadWrite$.$anonfun$saveImpl$1$adapted(Pipeline.scala:247)\norg.apache.spark.ml.util.Instrumentation$.$anonfun$instrumented$1(Instrumentation.scala:191)\nscala.util.Try$.apply(Try.scala:213)\norg.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:191)\norg.apache.spark.ml.Pipeline$SharedReadWrite$.saveImpl(Pipeline.scala:247)\norg.apache.spark.ml.PipelineModel$PipelineModelWriter.saveImpl(Pipeline.scala:346)\norg.apache.spark.ml.util.MLWriter.save(ReadWrite.scala:168)","physicalPlanDescription":"== Physical Plan ==\nExecute InsertIntoHadoopFsRelationCommand (3)\n+- Exchange (2)\n   +- LocalTableScan (1)\n\n\n(1) LocalTableScan\nOutput [5]: [numClasses#103, numFeatures#104, interceptVector#105, coefficientMatrix#106, isMultinomial#107]\nArguments: [numClasses#103, numFeatures#104, interceptVector#105, coefficientMatrix#106, isMultinomial#107]\n\n(2) Exchange\nInput [5]: [numClasses#103, numFeatures#104, interceptVector#105, coefficientMatrix#106, isMultinomial#107]\nArguments: RoundRobinPartitioning(1), REPARTITION_WITH_NUM, [id=#37]\n\n(3) Execute InsertIntoHadoopFsRelationCommand\nInput [5]: [numClasses#103, numFeatures#104, interceptVector#105, coefficientMatrix#106, isMultinomial#107]\nArguments: hdfs://localhost:9000/tmp/spark-logistic-regression-model/stages/2_logreg_8b15d2f29345/data, false, Parquet, [path=/tmp/spark-logistic-regression-model/stages/2_logreg_8b15d2f29345/data], ErrorIfExists, [numClasses, numFeatures, interceptVector, coefficientMatrix, isMultinomial]\n\n","sparkPlanInfo":{"nodeName":"Execute InsertIntoHadoopFsRelationCommand","simpleString":"Execute InsertIntoHadoopFsRelationCommand hdfs://localhost:9000/tmp/spark-logistic-regression-model/stages/2_logreg_8b15d2f29345/data, false, Parquet, [path=/tmp/spark-logistic-regression-model/stages/2_logreg_8b15d2f29345/data], ErrorIfExists, [numClasses, numFeatures, interceptVector, coefficientMatrix, isMultinomial]","children":[{"nodeName":"Exchange","simpleString":"Exchange RoundRobinPartitioning(1), REPARTITION_WITH_NUM, [id=#37]","children":[{"nodeName":"LocalTableScan","simpleString":"LocalTableScan [numClasses#103, numFeatures#104, interceptVector#105, coefficientMatrix#106, isMultinomial#107]","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":441,"metricType":"sum"}]}],"metadata":{},"metrics":[{"name":"shuffle records written","accumulatorId":435,"metricType":"sum"},{"name":"shuffle write time","accumulatorId":436,"metricType":"nsTiming"},{"name":"records read","accumulatorId":433,"metricType":"sum"},{"name":"local bytes read","accumulatorId":431,"metricType":"size"},{"name":"fetch wait time","accumulatorId":432,"metricType":"timing"},{"name":"remote bytes read","accumulatorId":429,"metricType":"size"},{"name":"local blocks read","accumulatorId":428,"metricType":"sum"},{"name":"remote blocks read","accumulatorId":427,"metricType":"sum"},{"name":"data size","accumulatorId":426,"metricType":"size"},{"name":"remote bytes read to disk","accumulatorId":430,"metricType":"size"},{"name":"shuffle bytes written","accumulatorId":434,"metricType":"size"}]}],"metadata":{},"metrics":[{"name":"number of written files","accumulatorId":437,"metricType":"sum"},{"name":"written output","accumulatorId":438,"metricType":"size"},{"name":"number of output rows","accumulatorId":439,"metricType":"sum"},{"name":"number of dynamic part","accumulatorId":440,"metricType":"sum"}]},"time":1641575656910}
{"Event":"SparkListenerJobStart","Job ID":16,"Submission Time":1641575657136,"Stage Infos":[{"Stage ID":16,"Stage Attempt ID":0,"Stage Name":"parquet at LogisticRegression.scala:1288","Number of Tasks":1,"RDD Info":[{"RDD ID":48,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"78\",\"name\":\"Exchange\"}","Callsite":"parquet at LogisticRegression.scala:1288","Parent IDs":[47],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":47,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"79\",\"name\":\"LocalTableScan\"}","Callsite":"parquet at LogisticRegression.scala:1288","Parent IDs":[46],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":46,"Name":"ParallelCollectionRDD","Scope":"{\"id\":\"79\",\"name\":\"LocalTableScan\"}","Callsite":"parquet at LogisticRegression.scala:1288","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameWriter.parquet(DataFrameWriter.scala:874)\norg.apache.spark.ml.classification.LogisticRegressionModel$LogisticRegressionModelWriter.saveImpl(LogisticRegression.scala:1288)\norg.apache.spark.ml.util.MLWriter.save(ReadWrite.scala:168)\norg.apache.spark.ml.Pipeline$SharedReadWrite$.$anonfun$saveImpl$5(Pipeline.scala:257)\norg.apache.spark.ml.MLEvents.withSaveInstanceEvent(events.scala:174)\norg.apache.spark.ml.MLEvents.withSaveInstanceEvent$(events.scala:169)\norg.apache.spark.ml.util.Instrumentation.withSaveInstanceEvent(Instrumentation.scala:42)\norg.apache.spark.ml.Pipeline$SharedReadWrite$.$anonfun$saveImpl$4(Pipeline.scala:257)\norg.apache.spark.ml.Pipeline$SharedReadWrite$.$anonfun$saveImpl$4$adapted(Pipeline.scala:254)\nscala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)\nscala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)\nscala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)\norg.apache.spark.ml.Pipeline$SharedReadWrite$.$anonfun$saveImpl$1(Pipeline.scala:254)\norg.apache.spark.ml.Pipeline$SharedReadWrite$.$anonfun$saveImpl$1$adapted(Pipeline.scala:247)\norg.apache.spark.ml.util.Instrumentation$.$anonfun$instrumented$1(Instrumentation.scala:191)\nscala.util.Try$.apply(Try.scala:213)\norg.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:191)\norg.apache.spark.ml.Pipeline$SharedReadWrite$.saveImpl(Pipeline.scala:247)\norg.apache.spark.ml.PipelineModel$PipelineModelWriter.saveImpl(Pipeline.scala:346)\norg.apache.spark.ml.util.MLWriter.save(ReadWrite.scala:168)","Accumulables":[],"Resource Profile Id":0},{"Stage ID":17,"Stage Attempt ID":0,"Stage Name":"parquet at LogisticRegression.scala:1288","Number of Tasks":1,"RDD Info":[{"RDD ID":49,"Name":"ShuffledRowRDD","Scope":"{\"id\":\"78\",\"name\":\"Exchange\"}","Callsite":"parquet at LogisticRegression.scala:1288","Parent IDs":[48],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[16],"Details":"org.apache.spark.sql.DataFrameWriter.parquet(DataFrameWriter.scala:874)\norg.apache.spark.ml.classification.LogisticRegressionModel$LogisticRegressionModelWriter.saveImpl(LogisticRegression.scala:1288)\norg.apache.spark.ml.util.MLWriter.save(ReadWrite.scala:168)\norg.apache.spark.ml.Pipeline$SharedReadWrite$.$anonfun$saveImpl$5(Pipeline.scala:257)\norg.apache.spark.ml.MLEvents.withSaveInstanceEvent(events.scala:174)\norg.apache.spark.ml.MLEvents.withSaveInstanceEvent$(events.scala:169)\norg.apache.spark.ml.util.Instrumentation.withSaveInstanceEvent(Instrumentation.scala:42)\norg.apache.spark.ml.Pipeline$SharedReadWrite$.$anonfun$saveImpl$4(Pipeline.scala:257)\norg.apache.spark.ml.Pipeline$SharedReadWrite$.$anonfun$saveImpl$4$adapted(Pipeline.scala:254)\nscala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)\nscala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)\nscala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)\norg.apache.spark.ml.Pipeline$SharedReadWrite$.$anonfun$saveImpl$1(Pipeline.scala:254)\norg.apache.spark.ml.Pipeline$SharedReadWrite$.$anonfun$saveImpl$1$adapted(Pipeline.scala:247)\norg.apache.spark.ml.util.Instrumentation$.$anonfun$instrumented$1(Instrumentation.scala:191)\nscala.util.Try$.apply(Try.scala:213)\norg.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:191)\norg.apache.spark.ml.Pipeline$SharedReadWrite$.saveImpl(Pipeline.scala:247)\norg.apache.spark.ml.PipelineModel$PipelineModelWriter.saveImpl(Pipeline.scala:346)\norg.apache.spark.ml.util.MLWriter.save(ReadWrite.scala:168)","Accumulables":[],"Resource Profile Id":0}],"Stage IDs":[16,17],"Properties":{"spark.sql.warehouse.dir":"file:/home/user/Benchmark/spark-warehouse","spark.driver.host":"host-name","spark.history.fs.logDirectory":"file:/home/user/logs","spark.eventLog.enabled":"true","spark.driver.port":"41119","__fetch_continuous_blocks_in_batch_enabled":"true","spark.jars":"file:/home/user/Benchmark/spark-3.1.2/examples/target/original-spark-examples_2.12-3.1.2.jar","spark.app.name":"PipelineExample","spark.rdd.scope":"{\"id\":\"77\",\"name\":\"Execute InsertIntoHadoopFsRelationCommand\"}","spark.driver.memory":"1g","spark.executor.instances":"1","spark.rdd.scope.noOverride":"true","spark.submit.pyFiles":"","spark.app.startTime":"1641575630976","spark.executor.id":"driver","spark.app.initial.jar.urls":"spark://host-name:41119/jars/original-spark-examples_2.12-3.1.2.jar","spark.submit.deployMode":"client","spark.master":"yarn","spark.ui.filters":"org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter","spark.executor.memory":"1g","spark.eventLog.dir":"file:/home/user/logs","spark.sql.execution.id":"0","spark.executor.cores":"2","spark.driver.appUIAddress":"http://host-name:4040","spark.org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter.param.PROXY_HOSTS":"host-name","spark.org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter.param.PROXY_URI_BASES":"http://host-name:8088/proxy/application_1641567765635_0075","spark.app.id":"application_1641567765635_0075"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":16,"Stage Attempt ID":0,"Stage Name":"parquet at LogisticRegression.scala:1288","Number of Tasks":1,"RDD Info":[{"RDD ID":48,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"78\",\"name\":\"Exchange\"}","Callsite":"parquet at LogisticRegression.scala:1288","Parent IDs":[47],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":47,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"79\",\"name\":\"LocalTableScan\"}","Callsite":"parquet at LogisticRegression.scala:1288","Parent IDs":[46],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":46,"Name":"ParallelCollectionRDD","Scope":"{\"id\":\"79\",\"name\":\"LocalTableScan\"}","Callsite":"parquet at LogisticRegression.scala:1288","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameWriter.parquet(DataFrameWriter.scala:874)\norg.apache.spark.ml.classification.LogisticRegressionModel$LogisticRegressionModelWriter.saveImpl(LogisticRegression.scala:1288)\norg.apache.spark.ml.util.MLWriter.save(ReadWrite.scala:168)\norg.apache.spark.ml.Pipeline$SharedReadWrite$.$anonfun$saveImpl$5(Pipeline.scala:257)\norg.apache.spark.ml.MLEvents.withSaveInstanceEvent(events.scala:174)\norg.apache.spark.ml.MLEvents.withSaveInstanceEvent$(events.scala:169)\norg.apache.spark.ml.util.Instrumentation.withSaveInstanceEvent(Instrumentation.scala:42)\norg.apache.spark.ml.Pipeline$SharedReadWrite$.$anonfun$saveImpl$4(Pipeline.scala:257)\norg.apache.spark.ml.Pipeline$SharedReadWrite$.$anonfun$saveImpl$4$adapted(Pipeline.scala:254)\nscala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)\nscala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)\nscala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)\norg.apache.spark.ml.Pipeline$SharedReadWrite$.$anonfun$saveImpl$1(Pipeline.scala:254)\norg.apache.spark.ml.Pipeline$SharedReadWrite$.$anonfun$saveImpl$1$adapted(Pipeline.scala:247)\norg.apache.spark.ml.util.Instrumentation$.$anonfun$instrumented$1(Instrumentation.scala:191)\nscala.util.Try$.apply(Try.scala:213)\norg.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:191)\norg.apache.spark.ml.Pipeline$SharedReadWrite$.saveImpl(Pipeline.scala:247)\norg.apache.spark.ml.PipelineModel$PipelineModelWriter.saveImpl(Pipeline.scala:346)\norg.apache.spark.ml.util.MLWriter.save(ReadWrite.scala:168)","Submission Time":1641575657139,"Accumulables":[],"Resource Profile Id":0},"Properties":{"spark.sql.warehouse.dir":"file:/home/user/Benchmark/spark-warehouse","spark.driver.host":"host-name","spark.history.fs.logDirectory":"file:/home/user/logs","spark.eventLog.enabled":"true","resource.executor.cores":"2","spark.driver.port":"41119","__fetch_continuous_blocks_in_batch_enabled":"true","spark.jars":"file:/home/user/Benchmark/spark-3.1.2/examples/target/original-spark-examples_2.12-3.1.2.jar","spark.app.name":"PipelineExample","spark.rdd.scope":"{\"id\":\"77\",\"name\":\"Execute InsertIntoHadoopFsRelationCommand\"}","spark.driver.memory":"1g","spark.executor.instances":"1","spark.rdd.scope.noOverride":"true","spark.submit.pyFiles":"","spark.app.startTime":"1641575630976","spark.executor.id":"driver","spark.app.initial.jar.urls":"spark://host-name:41119/jars/original-spark-examples_2.12-3.1.2.jar","spark.submit.deployMode":"client","spark.master":"yarn","spark.ui.filters":"org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter","spark.executor.memory":"1g","spark.eventLog.dir":"file:/home/user/logs","spark.sql.execution.id":"0","spark.executor.cores":"2","spark.driver.appUIAddress":"http://host-name:4040","spark.org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter.param.PROXY_HOSTS":"host-name","spark.org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter.param.PROXY_URI_BASES":"http://host-name:8088/proxy/application_1641567765635_0075","spark.app.id":"application_1641567765635_0075"}}
{"Event":"SparkListenerTaskStart","Stage ID":16,"Stage Attempt ID":0,"Task Info":{"Task ID":28,"Index":0,"Attempt":0,"Launch Time":1641575657149,"Executor ID":"1","Host":"host-name","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":16,"Stage Attempt ID":0,"Task Type":"ShuffleMapTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":28,"Index":0,"Attempt":0,"Launch Time":1641575657149,"Executor ID":"1","Host":"host-name","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1641575657223,"Failed":false,"Killed":false,"Accumulables":[{"ID":426,"Name":"data size","Update":"368","Value":"368","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":434,"Name":"shuffle bytes written","Update":"263","Value":"263","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":435,"Name":"shuffle records written","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":436,"Name":"shuffle write time","Update":"6438982","Value":"6438982","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":441,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":442,"Name":"internal.metrics.executorDeserializeTime","Update":32,"Value":32,"Internal":true,"Count Failed Values":true},{"ID":443,"Name":"internal.metrics.executorDeserializeCpuTime","Update":28454982,"Value":28454982,"Internal":true,"Count Failed Values":true},{"ID":444,"Name":"internal.metrics.executorRunTime","Update":34,"Value":34,"Internal":true,"Count Failed Values":true},{"ID":445,"Name":"internal.metrics.executorCpuTime","Update":34967490,"Value":34967490,"Internal":true,"Count Failed Values":true},{"ID":446,"Name":"internal.metrics.resultSize","Update":1613,"Value":1613,"Internal":true,"Count Failed Values":true},{"ID":460,"Name":"internal.metrics.shuffle.write.bytesWritten","Update":263,"Value":263,"Internal":true,"Count Failed Values":true},{"ID":461,"Name":"internal.metrics.shuffle.write.recordsWritten","Update":1,"Value":1,"Internal":true,"Count Failed Values":true},{"ID":462,"Name":"internal.metrics.shuffle.write.writeTime","Update":6438982,"Value":6438982,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0},"Task Metrics":{"Executor Deserialize Time":32,"Executor Deserialize CPU Time":28454982,"Executor Run Time":34,"Executor CPU Time":34967490,"Peak Execution Memory":0,"Result Size":1613,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":263,"Shuffle Write Time":6438982,"Shuffle Records Written":1},"Input Metrics":{"Bytes Read":0,"Records Read":0},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":16,"Stage Attempt ID":0,"Stage Name":"parquet at LogisticRegression.scala:1288","Number of Tasks":1,"RDD Info":[{"RDD ID":48,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"78\",\"name\":\"Exchange\"}","Callsite":"parquet at LogisticRegression.scala:1288","Parent IDs":[47],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":47,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"79\",\"name\":\"LocalTableScan\"}","Callsite":"parquet at LogisticRegression.scala:1288","Parent IDs":[46],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":46,"Name":"ParallelCollectionRDD","Scope":"{\"id\":\"79\",\"name\":\"LocalTableScan\"}","Callsite":"parquet at LogisticRegression.scala:1288","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameWriter.parquet(DataFrameWriter.scala:874)\norg.apache.spark.ml.classification.LogisticRegressionModel$LogisticRegressionModelWriter.saveImpl(LogisticRegression.scala:1288)\norg.apache.spark.ml.util.MLWriter.save(ReadWrite.scala:168)\norg.apache.spark.ml.Pipeline$SharedReadWrite$.$anonfun$saveImpl$5(Pipeline.scala:257)\norg.apache.spark.ml.MLEvents.withSaveInstanceEvent(events.scala:174)\norg.apache.spark.ml.MLEvents.withSaveInstanceEvent$(events.scala:169)\norg.apache.spark.ml.util.Instrumentation.withSaveInstanceEvent(Instrumentation.scala:42)\norg.apache.spark.ml.Pipeline$SharedReadWrite$.$anonfun$saveImpl$4(Pipeline.scala:257)\norg.apache.spark.ml.Pipeline$SharedReadWrite$.$anonfun$saveImpl$4$adapted(Pipeline.scala:254)\nscala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)\nscala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)\nscala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)\norg.apache.spark.ml.Pipeline$SharedReadWrite$.$anonfun$saveImpl$1(Pipeline.scala:254)\norg.apache.spark.ml.Pipeline$SharedReadWrite$.$anonfun$saveImpl$1$adapted(Pipeline.scala:247)\norg.apache.spark.ml.util.Instrumentation$.$anonfun$instrumented$1(Instrumentation.scala:191)\nscala.util.Try$.apply(Try.scala:213)\norg.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:191)\norg.apache.spark.ml.Pipeline$SharedReadWrite$.saveImpl(Pipeline.scala:247)\norg.apache.spark.ml.PipelineModel$PipelineModelWriter.saveImpl(Pipeline.scala:346)\norg.apache.spark.ml.util.MLWriter.save(ReadWrite.scala:168)","Submission Time":1641575657139,"Completion Time":1641575657225,"Accumulables":[{"ID":426,"Name":"data size","Value":"368","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":434,"Name":"shuffle bytes written","Value":"263","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":435,"Name":"shuffle records written","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":436,"Name":"shuffle write time","Value":"6438982","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":441,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":442,"Name":"internal.metrics.executorDeserializeTime","Value":32,"Internal":true,"Count Failed Values":true},{"ID":443,"Name":"internal.metrics.executorDeserializeCpuTime","Value":28454982,"Internal":true,"Count Failed Values":true},{"ID":444,"Name":"internal.metrics.executorRunTime","Value":34,"Internal":true,"Count Failed Values":true},{"ID":445,"Name":"internal.metrics.executorCpuTime","Value":34967490,"Internal":true,"Count Failed Values":true},{"ID":446,"Name":"internal.metrics.resultSize","Value":1613,"Internal":true,"Count Failed Values":true},{"ID":460,"Name":"internal.metrics.shuffle.write.bytesWritten","Value":263,"Internal":true,"Count Failed Values":true},{"ID":461,"Name":"internal.metrics.shuffle.write.recordsWritten","Value":1,"Internal":true,"Count Failed Values":true},{"ID":462,"Name":"internal.metrics.shuffle.write.writeTime","Value":6438982,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":17,"Stage Attempt ID":0,"Stage Name":"parquet at LogisticRegression.scala:1288","Number of Tasks":1,"RDD Info":[{"RDD ID":49,"Name":"ShuffledRowRDD","Scope":"{\"id\":\"78\",\"name\":\"Exchange\"}","Callsite":"parquet at LogisticRegression.scala:1288","Parent IDs":[48],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[16],"Details":"org.apache.spark.sql.DataFrameWriter.parquet(DataFrameWriter.scala:874)\norg.apache.spark.ml.classification.LogisticRegressionModel$LogisticRegressionModelWriter.saveImpl(LogisticRegression.scala:1288)\norg.apache.spark.ml.util.MLWriter.save(ReadWrite.scala:168)\norg.apache.spark.ml.Pipeline$SharedReadWrite$.$anonfun$saveImpl$5(Pipeline.scala:257)\norg.apache.spark.ml.MLEvents.withSaveInstanceEvent(events.scala:174)\norg.apache.spark.ml.MLEvents.withSaveInstanceEvent$(events.scala:169)\norg.apache.spark.ml.util.Instrumentation.withSaveInstanceEvent(Instrumentation.scala:42)\norg.apache.spark.ml.Pipeline$SharedReadWrite$.$anonfun$saveImpl$4(Pipeline.scala:257)\norg.apache.spark.ml.Pipeline$SharedReadWrite$.$anonfun$saveImpl$4$adapted(Pipeline.scala:254)\nscala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)\nscala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)\nscala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)\norg.apache.spark.ml.Pipeline$SharedReadWrite$.$anonfun$saveImpl$1(Pipeline.scala:254)\norg.apache.spark.ml.Pipeline$SharedReadWrite$.$anonfun$saveImpl$1$adapted(Pipeline.scala:247)\norg.apache.spark.ml.util.Instrumentation$.$anonfun$instrumented$1(Instrumentation.scala:191)\nscala.util.Try$.apply(Try.scala:213)\norg.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:191)\norg.apache.spark.ml.Pipeline$SharedReadWrite$.saveImpl(Pipeline.scala:247)\norg.apache.spark.ml.PipelineModel$PipelineModelWriter.saveImpl(Pipeline.scala:346)\norg.apache.spark.ml.util.MLWriter.save(ReadWrite.scala:168)","Submission Time":1641575657232,"Accumulables":[],"Resource Profile Id":0},"Properties":{"spark.sql.warehouse.dir":"file:/home/user/Benchmark/spark-warehouse","spark.driver.host":"host-name","spark.history.fs.logDirectory":"file:/home/user/logs","spark.eventLog.enabled":"true","resource.executor.cores":"2","spark.driver.port":"41119","__fetch_continuous_blocks_in_batch_enabled":"true","spark.jars":"file:/home/user/Benchmark/spark-3.1.2/examples/target/original-spark-examples_2.12-3.1.2.jar","spark.app.name":"PipelineExample","spark.rdd.scope":"{\"id\":\"77\",\"name\":\"Execute InsertIntoHadoopFsRelationCommand\"}","spark.driver.memory":"1g","spark.executor.instances":"1","spark.rdd.scope.noOverride":"true","spark.submit.pyFiles":"","spark.app.startTime":"1641575630976","spark.executor.id":"driver","spark.app.initial.jar.urls":"spark://host-name:41119/jars/original-spark-examples_2.12-3.1.2.jar","spark.submit.deployMode":"client","spark.master":"yarn","spark.ui.filters":"org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter","spark.executor.memory":"1g","spark.eventLog.dir":"file:/home/user/logs","spark.sql.execution.id":"0","spark.executor.cores":"2","spark.driver.appUIAddress":"http://host-name:4040","spark.org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter.param.PROXY_HOSTS":"host-name","spark.org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter.param.PROXY_URI_BASES":"http://host-name:8088/proxy/application_1641567765635_0075","spark.app.id":"application_1641567765635_0075"}}
{"Event":"SparkListenerTaskStart","Stage ID":17,"Stage Attempt ID":0,"Task Info":{"Task ID":29,"Index":0,"Attempt":0,"Launch Time":1641575657250,"Executor ID":"1","Host":"host-name","Locality":"NODE_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":17,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":29,"Index":0,"Attempt":0,"Launch Time":1641575657250,"Executor ID":"1","Host":"host-name","Locality":"NODE_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1641575658078,"Failed":false,"Killed":false,"Accumulables":[{"ID":428,"Name":"local blocks read","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":431,"Name":"local bytes read","Update":"263","Value":"263","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":432,"Name":"fetch wait time","Update":"0","Value":"0","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":433,"Name":"records read","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":467,"Name":"internal.metrics.executorDeserializeTime","Update":40,"Value":40,"Internal":true,"Count Failed Values":true},{"ID":468,"Name":"internal.metrics.executorDeserializeCpuTime","Update":35962555,"Value":35962555,"Internal":true,"Count Failed Values":true},{"ID":469,"Name":"internal.metrics.executorRunTime","Update":760,"Value":760,"Internal":true,"Count Failed Values":true},{"ID":470,"Name":"internal.metrics.executorCpuTime","Update":431923642,"Value":431923642,"Internal":true,"Count Failed Values":true},{"ID":471,"Name":"internal.metrics.resultSize","Update":3407,"Value":3407,"Internal":true,"Count Failed Values":true},{"ID":473,"Name":"internal.metrics.resultSerializationTime","Update":6,"Value":6,"Internal":true,"Count Failed Values":true},{"ID":478,"Name":"internal.metrics.shuffle.read.remoteBlocksFetched","Update":0,"Value":0,"Internal":true,"Count Failed Values":true},{"ID":479,"Name":"internal.metrics.shuffle.read.localBlocksFetched","Update":1,"Value":1,"Internal":true,"Count Failed Values":true},{"ID":480,"Name":"internal.metrics.shuffle.read.remoteBytesRead","Update":0,"Value":0,"Internal":true,"Count Failed Values":true},{"ID":481,"Name":"internal.metrics.shuffle.read.remoteBytesReadToDisk","Update":0,"Value":0,"Internal":true,"Count Failed Values":true},{"ID":482,"Name":"internal.metrics.shuffle.read.localBytesRead","Update":263,"Value":263,"Internal":true,"Count Failed Values":true},{"ID":483,"Name":"internal.metrics.shuffle.read.fetchWaitTime","Update":0,"Value":0,"Internal":true,"Count Failed Values":true},{"ID":484,"Name":"internal.metrics.shuffle.read.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true},{"ID":490,"Name":"internal.metrics.output.bytesWritten","Update":4366,"Value":4366,"Internal":true,"Count Failed Values":true},{"ID":491,"Name":"internal.metrics.output.recordsWritten","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0},"Task Metrics":{"Executor Deserialize Time":40,"Executor Deserialize CPU Time":35962555,"Executor Run Time":760,"Executor CPU Time":431923642,"Peak Execution Memory":0,"Result Size":3407,"JVM GC Time":0,"Result Serialization Time":6,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":1,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":263,"Total Records Read":1},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":0},"Output Metrics":{"Bytes Written":4366,"Records Written":1},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":17,"Stage Attempt ID":0,"Stage Name":"parquet at LogisticRegression.scala:1288","Number of Tasks":1,"RDD Info":[{"RDD ID":49,"Name":"ShuffledRowRDD","Scope":"{\"id\":\"78\",\"name\":\"Exchange\"}","Callsite":"parquet at LogisticRegression.scala:1288","Parent IDs":[48],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[16],"Details":"org.apache.spark.sql.DataFrameWriter.parquet(DataFrameWriter.scala:874)\norg.apache.spark.ml.classification.LogisticRegressionModel$LogisticRegressionModelWriter.saveImpl(LogisticRegression.scala:1288)\norg.apache.spark.ml.util.MLWriter.save(ReadWrite.scala:168)\norg.apache.spark.ml.Pipeline$SharedReadWrite$.$anonfun$saveImpl$5(Pipeline.scala:257)\norg.apache.spark.ml.MLEvents.withSaveInstanceEvent(events.scala:174)\norg.apache.spark.ml.MLEvents.withSaveInstanceEvent$(events.scala:169)\norg.apache.spark.ml.util.Instrumentation.withSaveInstanceEvent(Instrumentation.scala:42)\norg.apache.spark.ml.Pipeline$SharedReadWrite$.$anonfun$saveImpl$4(Pipeline.scala:257)\norg.apache.spark.ml.Pipeline$SharedReadWrite$.$anonfun$saveImpl$4$adapted(Pipeline.scala:254)\nscala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)\nscala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)\nscala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)\norg.apache.spark.ml.Pipeline$SharedReadWrite$.$anonfun$saveImpl$1(Pipeline.scala:254)\norg.apache.spark.ml.Pipeline$SharedReadWrite$.$anonfun$saveImpl$1$adapted(Pipeline.scala:247)\norg.apache.spark.ml.util.Instrumentation$.$anonfun$instrumented$1(Instrumentation.scala:191)\nscala.util.Try$.apply(Try.scala:213)\norg.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:191)\norg.apache.spark.ml.Pipeline$SharedReadWrite$.saveImpl(Pipeline.scala:247)\norg.apache.spark.ml.PipelineModel$PipelineModelWriter.saveImpl(Pipeline.scala:346)\norg.apache.spark.ml.util.MLWriter.save(ReadWrite.scala:168)","Submission Time":1641575657232,"Completion Time":1641575658080,"Accumulables":[{"ID":428,"Name":"local blocks read","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":431,"Name":"local bytes read","Value":"263","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":432,"Name":"fetch wait time","Value":"0","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":433,"Name":"records read","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":467,"Name":"internal.metrics.executorDeserializeTime","Value":40,"Internal":true,"Count Failed Values":true},{"ID":468,"Name":"internal.metrics.executorDeserializeCpuTime","Value":35962555,"Internal":true,"Count Failed Values":true},{"ID":469,"Name":"internal.metrics.executorRunTime","Value":760,"Internal":true,"Count Failed Values":true},{"ID":470,"Name":"internal.metrics.executorCpuTime","Value":431923642,"Internal":true,"Count Failed Values":true},{"ID":471,"Name":"internal.metrics.resultSize","Value":3407,"Internal":true,"Count Failed Values":true},{"ID":473,"Name":"internal.metrics.resultSerializationTime","Value":6,"Internal":true,"Count Failed Values":true},{"ID":478,"Name":"internal.metrics.shuffle.read.remoteBlocksFetched","Value":0,"Internal":true,"Count Failed Values":true},{"ID":479,"Name":"internal.metrics.shuffle.read.localBlocksFetched","Value":1,"Internal":true,"Count Failed Values":true},{"ID":480,"Name":"internal.metrics.shuffle.read.remoteBytesRead","Value":0,"Internal":true,"Count Failed Values":true},{"ID":481,"Name":"internal.metrics.shuffle.read.remoteBytesReadToDisk","Value":0,"Internal":true,"Count Failed Values":true},{"ID":482,"Name":"internal.metrics.shuffle.read.localBytesRead","Value":263,"Internal":true,"Count Failed Values":true},{"ID":483,"Name":"internal.metrics.shuffle.read.fetchWaitTime","Value":0,"Internal":true,"Count Failed Values":true},{"ID":484,"Name":"internal.metrics.shuffle.read.recordsRead","Value":1,"Internal":true,"Count Failed Values":true},{"ID":490,"Name":"internal.metrics.output.bytesWritten","Value":4366,"Internal":true,"Count Failed Values":true},{"ID":491,"Name":"internal.metrics.output.recordsWritten","Value":1,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0}}
{"Event":"SparkListenerJobEnd","Job ID":16,"Completion Time":1641575658080,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":0,"accumUpdates":[[437,1],[438,4366],[439,1],[440,0]]}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":0,"time":1641575658296}
{"Event":"SparkListenerJobStart","Job ID":17,"Submission Time":1641575658368,"Stage Infos":[{"Stage ID":18,"Stage Attempt ID":0,"Stage Name":"runJob at SparkHadoopWriter.scala:83","Number of Tasks":1,"RDD Info":[{"RDD ID":53,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"85\",\"name\":\"saveAsTextFile\"}","Callsite":"saveAsTextFile at ReadWrite.scala:413","Parent IDs":[52],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":52,"Name":"ParallelCollectionRDD","Scope":"{\"id\":\"84\",\"name\":\"parallelize\"}","Callsite":"parallelize at ReadWrite.scala:413","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.SparkContext.runJob(SparkContext.scala:2249)\norg.apache.spark.internal.io.SparkHadoopWriter$.write(SparkHadoopWriter.scala:83)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopDataset$1(PairRDDFunctions.scala:1090)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:414)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopDataset(PairRDDFunctions.scala:1088)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopFile$4(PairRDDFunctions.scala:1061)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:414)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1026)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopFile$3(PairRDDFunctions.scala:1008)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:414)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1007)","Accumulables":[],"Resource Profile Id":0}],"Stage IDs":[18],"Properties":{"__fetch_continuous_blocks_in_batch_enabled":"true","spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"85\",\"name\":\"saveAsTextFile\"}"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":18,"Stage Attempt ID":0,"Stage Name":"runJob at SparkHadoopWriter.scala:83","Number of Tasks":1,"RDD Info":[{"RDD ID":53,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"85\",\"name\":\"saveAsTextFile\"}","Callsite":"saveAsTextFile at ReadWrite.scala:413","Parent IDs":[52],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":52,"Name":"ParallelCollectionRDD","Scope":"{\"id\":\"84\",\"name\":\"parallelize\"}","Callsite":"parallelize at ReadWrite.scala:413","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.SparkContext.runJob(SparkContext.scala:2249)\norg.apache.spark.internal.io.SparkHadoopWriter$.write(SparkHadoopWriter.scala:83)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopDataset$1(PairRDDFunctions.scala:1090)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:414)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopDataset(PairRDDFunctions.scala:1088)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopFile$4(PairRDDFunctions.scala:1061)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:414)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1026)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopFile$3(PairRDDFunctions.scala:1008)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:414)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1007)","Submission Time":1641575658369,"Accumulables":[],"Resource Profile Id":0},"Properties":{"__fetch_continuous_blocks_in_batch_enabled":"true","resource.executor.cores":"2","spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"85\",\"name\":\"saveAsTextFile\"}"}}
{"Event":"SparkListenerTaskStart","Stage ID":18,"Stage Attempt ID":0,"Task Info":{"Task ID":30,"Index":0,"Attempt":0,"Launch Time":1641575658380,"Executor ID":"1","Host":"host-name","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":18,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":30,"Index":0,"Attempt":0,"Launch Time":1641575658380,"Executor ID":"1","Host":"host-name","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1641575658705,"Failed":false,"Killed":false,"Accumulables":[{"ID":492,"Name":"internal.metrics.executorDeserializeTime","Update":12,"Value":12,"Internal":true,"Count Failed Values":true},{"ID":493,"Name":"internal.metrics.executorDeserializeCpuTime","Update":8827640,"Value":8827640,"Internal":true,"Count Failed Values":true},{"ID":494,"Name":"internal.metrics.executorRunTime","Update":308,"Value":308,"Internal":true,"Count Failed Values":true},{"ID":495,"Name":"internal.metrics.executorCpuTime","Update":6087329,"Value":6087329,"Internal":true,"Count Failed Values":true},{"ID":496,"Name":"internal.metrics.resultSize","Update":1158,"Value":1158,"Internal":true,"Count Failed Values":true},{"ID":515,"Name":"internal.metrics.output.bytesWritten","Update":234,"Value":234,"Internal":true,"Count Failed Values":true},{"ID":516,"Name":"internal.metrics.output.recordsWritten","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0},"Task Metrics":{"Executor Deserialize Time":12,"Executor Deserialize CPU Time":8827640,"Executor Run Time":308,"Executor CPU Time":6087329,"Peak Execution Memory":0,"Result Size":1158,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":0},"Output Metrics":{"Bytes Written":234,"Records Written":1},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":18,"Stage Attempt ID":0,"Stage Name":"runJob at SparkHadoopWriter.scala:83","Number of Tasks":1,"RDD Info":[{"RDD ID":53,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"85\",\"name\":\"saveAsTextFile\"}","Callsite":"saveAsTextFile at ReadWrite.scala:413","Parent IDs":[52],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":52,"Name":"ParallelCollectionRDD","Scope":"{\"id\":\"84\",\"name\":\"parallelize\"}","Callsite":"parallelize at ReadWrite.scala:413","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.SparkContext.runJob(SparkContext.scala:2249)\norg.apache.spark.internal.io.SparkHadoopWriter$.write(SparkHadoopWriter.scala:83)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopDataset$1(PairRDDFunctions.scala:1090)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:414)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopDataset(PairRDDFunctions.scala:1088)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopFile$4(PairRDDFunctions.scala:1061)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:414)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1026)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopFile$3(PairRDDFunctions.scala:1008)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:414)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1007)","Submission Time":1641575658369,"Completion Time":1641575658705,"Accumulables":[{"ID":492,"Name":"internal.metrics.executorDeserializeTime","Value":12,"Internal":true,"Count Failed Values":true},{"ID":493,"Name":"internal.metrics.executorDeserializeCpuTime","Value":8827640,"Internal":true,"Count Failed Values":true},{"ID":494,"Name":"internal.metrics.executorRunTime","Value":308,"Internal":true,"Count Failed Values":true},{"ID":495,"Name":"internal.metrics.executorCpuTime","Value":6087329,"Internal":true,"Count Failed Values":true},{"ID":496,"Name":"internal.metrics.resultSize","Value":1158,"Internal":true,"Count Failed Values":true},{"ID":515,"Name":"internal.metrics.output.bytesWritten","Value":234,"Internal":true,"Count Failed Values":true},{"ID":516,"Name":"internal.metrics.output.recordsWritten","Value":1,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0}}
{"Event":"SparkListenerJobEnd","Job ID":17,"Completion Time":1641575658706,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"SparkListenerJobStart","Job ID":18,"Submission Time":1641575658979,"Stage Infos":[{"Stage ID":19,"Stage Attempt ID":0,"Stage Name":"runJob at SparkHadoopWriter.scala:83","Number of Tasks":1,"RDD Info":[{"RDD ID":55,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"89\",\"name\":\"saveAsTextFile\"}","Callsite":"saveAsTextFile at ReadWrite.scala:413","Parent IDs":[54],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":54,"Name":"ParallelCollectionRDD","Scope":"{\"id\":\"88\",\"name\":\"parallelize\"}","Callsite":"parallelize at ReadWrite.scala:413","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.SparkContext.runJob(SparkContext.scala:2249)\norg.apache.spark.internal.io.SparkHadoopWriter$.write(SparkHadoopWriter.scala:83)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopDataset$1(PairRDDFunctions.scala:1090)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:414)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopDataset(PairRDDFunctions.scala:1088)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopFile$4(PairRDDFunctions.scala:1061)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:414)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1026)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopFile$3(PairRDDFunctions.scala:1008)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:414)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1007)","Accumulables":[],"Resource Profile Id":0}],"Stage IDs":[19],"Properties":{"__fetch_continuous_blocks_in_batch_enabled":"true","spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"89\",\"name\":\"saveAsTextFile\"}"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":19,"Stage Attempt ID":0,"Stage Name":"runJob at SparkHadoopWriter.scala:83","Number of Tasks":1,"RDD Info":[{"RDD ID":55,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"89\",\"name\":\"saveAsTextFile\"}","Callsite":"saveAsTextFile at ReadWrite.scala:413","Parent IDs":[54],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":54,"Name":"ParallelCollectionRDD","Scope":"{\"id\":\"88\",\"name\":\"parallelize\"}","Callsite":"parallelize at ReadWrite.scala:413","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.SparkContext.runJob(SparkContext.scala:2249)\norg.apache.spark.internal.io.SparkHadoopWriter$.write(SparkHadoopWriter.scala:83)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopDataset$1(PairRDDFunctions.scala:1090)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:414)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopDataset(PairRDDFunctions.scala:1088)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopFile$4(PairRDDFunctions.scala:1061)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:414)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1026)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopFile$3(PairRDDFunctions.scala:1008)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:414)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1007)","Submission Time":1641575658981,"Accumulables":[],"Resource Profile Id":0},"Properties":{"__fetch_continuous_blocks_in_batch_enabled":"true","resource.executor.cores":"2","spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"89\",\"name\":\"saveAsTextFile\"}"}}
{"Event":"SparkListenerTaskStart","Stage ID":19,"Stage Attempt ID":0,"Task Info":{"Task ID":31,"Index":0,"Attempt":0,"Launch Time":1641575659004,"Executor ID":"1","Host":"host-name","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":19,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":31,"Index":0,"Attempt":0,"Launch Time":1641575659004,"Executor ID":"1","Host":"host-name","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1641575659255,"Failed":false,"Killed":false,"Accumulables":[{"ID":517,"Name":"internal.metrics.executorDeserializeTime","Update":14,"Value":14,"Internal":true,"Count Failed Values":true},{"ID":518,"Name":"internal.metrics.executorDeserializeCpuTime","Update":10922718,"Value":10922718,"Internal":true,"Count Failed Values":true},{"ID":519,"Name":"internal.metrics.executorRunTime","Update":231,"Value":231,"Internal":true,"Count Failed Values":true},{"ID":520,"Name":"internal.metrics.executorCpuTime","Update":10696819,"Value":10696819,"Internal":true,"Count Failed Values":true},{"ID":521,"Name":"internal.metrics.resultSize","Update":1201,"Value":1201,"Internal":true,"Count Failed Values":true},{"ID":522,"Name":"internal.metrics.jvmGCTime","Update":8,"Value":8,"Internal":true,"Count Failed Values":true},{"ID":540,"Name":"internal.metrics.output.bytesWritten","Update":234,"Value":234,"Internal":true,"Count Failed Values":true},{"ID":541,"Name":"internal.metrics.output.recordsWritten","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0},"Task Metrics":{"Executor Deserialize Time":14,"Executor Deserialize CPU Time":10922718,"Executor Run Time":231,"Executor CPU Time":10696819,"Peak Execution Memory":0,"Result Size":1201,"JVM GC Time":8,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":0},"Output Metrics":{"Bytes Written":234,"Records Written":1},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":19,"Stage Attempt ID":0,"Stage Name":"runJob at SparkHadoopWriter.scala:83","Number of Tasks":1,"RDD Info":[{"RDD ID":55,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"89\",\"name\":\"saveAsTextFile\"}","Callsite":"saveAsTextFile at ReadWrite.scala:413","Parent IDs":[54],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":54,"Name":"ParallelCollectionRDD","Scope":"{\"id\":\"88\",\"name\":\"parallelize\"}","Callsite":"parallelize at ReadWrite.scala:413","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.SparkContext.runJob(SparkContext.scala:2249)\norg.apache.spark.internal.io.SparkHadoopWriter$.write(SparkHadoopWriter.scala:83)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopDataset$1(PairRDDFunctions.scala:1090)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:414)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopDataset(PairRDDFunctions.scala:1088)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopFile$4(PairRDDFunctions.scala:1061)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:414)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1026)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopFile$3(PairRDDFunctions.scala:1008)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:414)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1007)","Submission Time":1641575658981,"Completion Time":1641575659255,"Accumulables":[{"ID":517,"Name":"internal.metrics.executorDeserializeTime","Value":14,"Internal":true,"Count Failed Values":true},{"ID":518,"Name":"internal.metrics.executorDeserializeCpuTime","Value":10922718,"Internal":true,"Count Failed Values":true},{"ID":519,"Name":"internal.metrics.executorRunTime","Value":231,"Internal":true,"Count Failed Values":true},{"ID":520,"Name":"internal.metrics.executorCpuTime","Value":10696819,"Internal":true,"Count Failed Values":true},{"ID":521,"Name":"internal.metrics.resultSize","Value":1201,"Internal":true,"Count Failed Values":true},{"ID":522,"Name":"internal.metrics.jvmGCTime","Value":8,"Internal":true,"Count Failed Values":true},{"ID":540,"Name":"internal.metrics.output.bytesWritten","Value":234,"Internal":true,"Count Failed Values":true},{"ID":541,"Name":"internal.metrics.output.recordsWritten","Value":1,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0}}
{"Event":"SparkListenerJobEnd","Job ID":18,"Completion Time":1641575659255,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"SparkListenerJobStart","Job ID":19,"Submission Time":1641575659585,"Stage Infos":[{"Stage ID":20,"Stage Attempt ID":0,"Stage Name":"runJob at SparkHadoopWriter.scala:83","Number of Tasks":1,"RDD Info":[{"RDD ID":57,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"93\",\"name\":\"saveAsTextFile\"}","Callsite":"saveAsTextFile at ReadWrite.scala:413","Parent IDs":[56],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":56,"Name":"ParallelCollectionRDD","Scope":"{\"id\":\"92\",\"name\":\"parallelize\"}","Callsite":"parallelize at ReadWrite.scala:413","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.SparkContext.runJob(SparkContext.scala:2249)\norg.apache.spark.internal.io.SparkHadoopWriter$.write(SparkHadoopWriter.scala:83)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopDataset$1(PairRDDFunctions.scala:1090)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:414)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopDataset(PairRDDFunctions.scala:1088)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopFile$4(PairRDDFunctions.scala:1061)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:414)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1026)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopFile$3(PairRDDFunctions.scala:1008)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:414)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1007)","Accumulables":[],"Resource Profile Id":0}],"Stage IDs":[20],"Properties":{"__fetch_continuous_blocks_in_batch_enabled":"true","spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"93\",\"name\":\"saveAsTextFile\"}"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":20,"Stage Attempt ID":0,"Stage Name":"runJob at SparkHadoopWriter.scala:83","Number of Tasks":1,"RDD Info":[{"RDD ID":57,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"93\",\"name\":\"saveAsTextFile\"}","Callsite":"saveAsTextFile at ReadWrite.scala:413","Parent IDs":[56],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":56,"Name":"ParallelCollectionRDD","Scope":"{\"id\":\"92\",\"name\":\"parallelize\"}","Callsite":"parallelize at ReadWrite.scala:413","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.SparkContext.runJob(SparkContext.scala:2249)\norg.apache.spark.internal.io.SparkHadoopWriter$.write(SparkHadoopWriter.scala:83)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopDataset$1(PairRDDFunctions.scala:1090)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:414)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopDataset(PairRDDFunctions.scala:1088)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopFile$4(PairRDDFunctions.scala:1061)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:414)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1026)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopFile$3(PairRDDFunctions.scala:1008)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:414)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1007)","Submission Time":1641575659586,"Accumulables":[],"Resource Profile Id":0},"Properties":{"__fetch_continuous_blocks_in_batch_enabled":"true","resource.executor.cores":"2","spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"93\",\"name\":\"saveAsTextFile\"}"}}
{"Event":"SparkListenerTaskStart","Stage ID":20,"Stage Attempt ID":0,"Task Info":{"Task ID":32,"Index":0,"Attempt":0,"Launch Time":1641575659599,"Executor ID":"1","Host":"host-name","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":20,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":32,"Index":0,"Attempt":0,"Launch Time":1641575659599,"Executor ID":"1","Host":"host-name","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1641575659788,"Failed":false,"Killed":false,"Accumulables":[{"ID":542,"Name":"internal.metrics.executorDeserializeTime","Update":12,"Value":12,"Internal":true,"Count Failed Values":true},{"ID":543,"Name":"internal.metrics.executorDeserializeCpuTime","Update":8654770,"Value":8654770,"Internal":true,"Count Failed Values":true},{"ID":544,"Name":"internal.metrics.executorRunTime","Update":171,"Value":171,"Internal":true,"Count Failed Values":true},{"ID":545,"Name":"internal.metrics.executorCpuTime","Update":5727098,"Value":5727098,"Internal":true,"Count Failed Values":true},{"ID":546,"Name":"internal.metrics.resultSize","Update":1158,"Value":1158,"Internal":true,"Count Failed Values":true},{"ID":565,"Name":"internal.metrics.output.bytesWritten","Update":305,"Value":305,"Internal":true,"Count Failed Values":true},{"ID":566,"Name":"internal.metrics.output.recordsWritten","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0},"Task Metrics":{"Executor Deserialize Time":12,"Executor Deserialize CPU Time":8654770,"Executor Run Time":171,"Executor CPU Time":5727098,"Peak Execution Memory":0,"Result Size":1158,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":0},"Output Metrics":{"Bytes Written":305,"Records Written":1},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":20,"Stage Attempt ID":0,"Stage Name":"runJob at SparkHadoopWriter.scala:83","Number of Tasks":1,"RDD Info":[{"RDD ID":57,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"93\",\"name\":\"saveAsTextFile\"}","Callsite":"saveAsTextFile at ReadWrite.scala:413","Parent IDs":[56],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":56,"Name":"ParallelCollectionRDD","Scope":"{\"id\":\"92\",\"name\":\"parallelize\"}","Callsite":"parallelize at ReadWrite.scala:413","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.SparkContext.runJob(SparkContext.scala:2249)\norg.apache.spark.internal.io.SparkHadoopWriter$.write(SparkHadoopWriter.scala:83)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopDataset$1(PairRDDFunctions.scala:1090)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:414)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopDataset(PairRDDFunctions.scala:1088)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopFile$4(PairRDDFunctions.scala:1061)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:414)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1026)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopFile$3(PairRDDFunctions.scala:1008)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:414)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1007)","Submission Time":1641575659586,"Completion Time":1641575659788,"Accumulables":[{"ID":542,"Name":"internal.metrics.executorDeserializeTime","Value":12,"Internal":true,"Count Failed Values":true},{"ID":543,"Name":"internal.metrics.executorDeserializeCpuTime","Value":8654770,"Internal":true,"Count Failed Values":true},{"ID":544,"Name":"internal.metrics.executorRunTime","Value":171,"Internal":true,"Count Failed Values":true},{"ID":545,"Name":"internal.metrics.executorCpuTime","Value":5727098,"Internal":true,"Count Failed Values":true},{"ID":546,"Name":"internal.metrics.resultSize","Value":1158,"Internal":true,"Count Failed Values":true},{"ID":565,"Name":"internal.metrics.output.bytesWritten","Value":305,"Internal":true,"Count Failed Values":true},{"ID":566,"Name":"internal.metrics.output.recordsWritten","Value":1,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0}}
{"Event":"SparkListenerJobEnd","Job ID":19,"Completion Time":1641575659789,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"SparkListenerJobStart","Job ID":20,"Submission Time":1641575660009,"Stage Infos":[{"Stage ID":21,"Stage Attempt ID":0,"Stage Name":"runJob at SparkHadoopWriter.scala:83","Number of Tasks":1,"RDD Info":[{"RDD ID":59,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"97\",\"name\":\"saveAsTextFile\"}","Callsite":"saveAsTextFile at ReadWrite.scala:413","Parent IDs":[58],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":58,"Name":"ParallelCollectionRDD","Scope":"{\"id\":\"96\",\"name\":\"parallelize\"}","Callsite":"parallelize at ReadWrite.scala:413","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.SparkContext.runJob(SparkContext.scala:2249)\norg.apache.spark.internal.io.SparkHadoopWriter$.write(SparkHadoopWriter.scala:83)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopDataset$1(PairRDDFunctions.scala:1090)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:414)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopDataset(PairRDDFunctions.scala:1088)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopFile$4(PairRDDFunctions.scala:1061)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:414)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1026)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopFile$3(PairRDDFunctions.scala:1008)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:414)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1007)","Accumulables":[],"Resource Profile Id":0}],"Stage IDs":[21],"Properties":{"__fetch_continuous_blocks_in_batch_enabled":"true","spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"97\",\"name\":\"saveAsTextFile\"}"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":21,"Stage Attempt ID":0,"Stage Name":"runJob at SparkHadoopWriter.scala:83","Number of Tasks":1,"RDD Info":[{"RDD ID":59,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"97\",\"name\":\"saveAsTextFile\"}","Callsite":"saveAsTextFile at ReadWrite.scala:413","Parent IDs":[58],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":58,"Name":"ParallelCollectionRDD","Scope":"{\"id\":\"96\",\"name\":\"parallelize\"}","Callsite":"parallelize at ReadWrite.scala:413","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.SparkContext.runJob(SparkContext.scala:2249)\norg.apache.spark.internal.io.SparkHadoopWriter$.write(SparkHadoopWriter.scala:83)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopDataset$1(PairRDDFunctions.scala:1090)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:414)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopDataset(PairRDDFunctions.scala:1088)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopFile$4(PairRDDFunctions.scala:1061)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:414)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1026)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopFile$3(PairRDDFunctions.scala:1008)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:414)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1007)","Submission Time":1641575660010,"Accumulables":[],"Resource Profile Id":0},"Properties":{"__fetch_continuous_blocks_in_batch_enabled":"true","resource.executor.cores":"2","spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"97\",\"name\":\"saveAsTextFile\"}"}}
{"Event":"SparkListenerTaskStart","Stage ID":21,"Stage Attempt ID":0,"Task Info":{"Task ID":33,"Index":0,"Attempt":0,"Launch Time":1641575660020,"Executor ID":"1","Host":"host-name","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":21,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":33,"Index":0,"Attempt":0,"Launch Time":1641575660020,"Executor ID":"1","Host":"host-name","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1641575660234,"Failed":false,"Killed":false,"Accumulables":[{"ID":567,"Name":"internal.metrics.executorDeserializeTime","Update":11,"Value":11,"Internal":true,"Count Failed Values":true},{"ID":568,"Name":"internal.metrics.executorDeserializeCpuTime","Update":7880023,"Value":7880023,"Internal":true,"Count Failed Values":true},{"ID":569,"Name":"internal.metrics.executorRunTime","Update":195,"Value":195,"Internal":true,"Count Failed Values":true},{"ID":570,"Name":"internal.metrics.executorCpuTime","Update":10328424,"Value":10328424,"Internal":true,"Count Failed Values":true},{"ID":571,"Name":"internal.metrics.resultSize","Update":1158,"Value":1158,"Internal":true,"Count Failed Values":true},{"ID":590,"Name":"internal.metrics.output.bytesWritten","Update":528,"Value":528,"Internal":true,"Count Failed Values":true},{"ID":591,"Name":"internal.metrics.output.recordsWritten","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0},"Task Metrics":{"Executor Deserialize Time":11,"Executor Deserialize CPU Time":7880023,"Executor Run Time":195,"Executor CPU Time":10328424,"Peak Execution Memory":0,"Result Size":1158,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":0},"Output Metrics":{"Bytes Written":528,"Records Written":1},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":21,"Stage Attempt ID":0,"Stage Name":"runJob at SparkHadoopWriter.scala:83","Number of Tasks":1,"RDD Info":[{"RDD ID":59,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"97\",\"name\":\"saveAsTextFile\"}","Callsite":"saveAsTextFile at ReadWrite.scala:413","Parent IDs":[58],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":58,"Name":"ParallelCollectionRDD","Scope":"{\"id\":\"96\",\"name\":\"parallelize\"}","Callsite":"parallelize at ReadWrite.scala:413","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.SparkContext.runJob(SparkContext.scala:2249)\norg.apache.spark.internal.io.SparkHadoopWriter$.write(SparkHadoopWriter.scala:83)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopDataset$1(PairRDDFunctions.scala:1090)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:414)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopDataset(PairRDDFunctions.scala:1088)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopFile$4(PairRDDFunctions.scala:1061)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:414)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1026)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopFile$3(PairRDDFunctions.scala:1008)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:414)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1007)","Submission Time":1641575660010,"Completion Time":1641575660235,"Accumulables":[{"ID":567,"Name":"internal.metrics.executorDeserializeTime","Value":11,"Internal":true,"Count Failed Values":true},{"ID":568,"Name":"internal.metrics.executorDeserializeCpuTime","Value":7880023,"Internal":true,"Count Failed Values":true},{"ID":569,"Name":"internal.metrics.executorRunTime","Value":195,"Internal":true,"Count Failed Values":true},{"ID":570,"Name":"internal.metrics.executorCpuTime","Value":10328424,"Internal":true,"Count Failed Values":true},{"ID":571,"Name":"internal.metrics.resultSize","Value":1158,"Internal":true,"Count Failed Values":true},{"ID":590,"Name":"internal.metrics.output.bytesWritten","Value":528,"Internal":true,"Count Failed Values":true},{"ID":591,"Name":"internal.metrics.output.recordsWritten","Value":1,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0}}
{"Event":"SparkListenerJobEnd","Job ID":20,"Completion Time":1641575660236,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"SparkListenerJobStart","Job ID":21,"Submission Time":1641575660534,"Stage Infos":[{"Stage ID":22,"Stage Attempt ID":0,"Stage Name":"first at ReadWrite.scala:587","Number of Tasks":1,"RDD Info":[{"RDD ID":61,"Name":"/tmp/spark-logistic-regression-model/metadata","Scope":"{\"id\":\"100\",\"name\":\"textFile\"}","Callsite":"textFile at ReadWrite.scala:587","Parent IDs":[60],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":60,"Name":"/tmp/spark-logistic-regression-model/metadata","Scope":"{\"id\":\"100\",\"name\":\"textFile\"}","Callsite":"textFile at ReadWrite.scala:587","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.rdd.RDD.first(RDD.scala:1463)\norg.apache.spark.ml.util.DefaultParamsReader$.loadMetadata(ReadWrite.scala:587)\norg.apache.spark.ml.Pipeline$SharedReadWrite$.$anonfun$load$3(Pipeline.scala:269)\norg.apache.spark.ml.util.Instrumentation$.$anonfun$instrumented$1(Instrumentation.scala:191)\nscala.util.Try$.apply(Try.scala:213)\norg.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:191)\norg.apache.spark.ml.Pipeline$SharedReadWrite$.load(Pipeline.scala:268)\norg.apache.spark.ml.PipelineModel$PipelineModelReader.$anonfun$load$7(Pipeline.scala:356)\norg.apache.spark.ml.MLEvents.withLoadInstanceEvent(events.scala:160)\norg.apache.spark.ml.MLEvents.withLoadInstanceEvent$(events.scala:155)\norg.apache.spark.ml.util.Instrumentation.withLoadInstanceEvent(Instrumentation.scala:42)\norg.apache.spark.ml.PipelineModel$PipelineModelReader.$anonfun$load$6(Pipeline.scala:355)\norg.apache.spark.ml.util.Instrumentation$.$anonfun$instrumented$1(Instrumentation.scala:191)\nscala.util.Try$.apply(Try.scala:213)\norg.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:191)\norg.apache.spark.ml.PipelineModel$PipelineModelReader.load(Pipeline.scala:355)\norg.apache.spark.ml.PipelineModel$PipelineModelReader.load(Pipeline.scala:349)\norg.apache.spark.ml.util.MLReadable.load(ReadWrite.scala:355)\norg.apache.spark.ml.util.MLReadable.load$(ReadWrite.scala:355)\norg.apache.spark.ml.PipelineModel$.load(Pipeline.scala:337)","Accumulables":[],"Resource Profile Id":0}],"Stage IDs":[22],"Properties":{"__fetch_continuous_blocks_in_batch_enabled":"true","spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"101\",\"name\":\"first\"}"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":22,"Stage Attempt ID":0,"Stage Name":"first at ReadWrite.scala:587","Number of Tasks":1,"RDD Info":[{"RDD ID":61,"Name":"/tmp/spark-logistic-regression-model/metadata","Scope":"{\"id\":\"100\",\"name\":\"textFile\"}","Callsite":"textFile at ReadWrite.scala:587","Parent IDs":[60],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":60,"Name":"/tmp/spark-logistic-regression-model/metadata","Scope":"{\"id\":\"100\",\"name\":\"textFile\"}","Callsite":"textFile at ReadWrite.scala:587","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.rdd.RDD.first(RDD.scala:1463)\norg.apache.spark.ml.util.DefaultParamsReader$.loadMetadata(ReadWrite.scala:587)\norg.apache.spark.ml.Pipeline$SharedReadWrite$.$anonfun$load$3(Pipeline.scala:269)\norg.apache.spark.ml.util.Instrumentation$.$anonfun$instrumented$1(Instrumentation.scala:191)\nscala.util.Try$.apply(Try.scala:213)\norg.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:191)\norg.apache.spark.ml.Pipeline$SharedReadWrite$.load(Pipeline.scala:268)\norg.apache.spark.ml.PipelineModel$PipelineModelReader.$anonfun$load$7(Pipeline.scala:356)\norg.apache.spark.ml.MLEvents.withLoadInstanceEvent(events.scala:160)\norg.apache.spark.ml.MLEvents.withLoadInstanceEvent$(events.scala:155)\norg.apache.spark.ml.util.Instrumentation.withLoadInstanceEvent(Instrumentation.scala:42)\norg.apache.spark.ml.PipelineModel$PipelineModelReader.$anonfun$load$6(Pipeline.scala:355)\norg.apache.spark.ml.util.Instrumentation$.$anonfun$instrumented$1(Instrumentation.scala:191)\nscala.util.Try$.apply(Try.scala:213)\norg.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:191)\norg.apache.spark.ml.PipelineModel$PipelineModelReader.load(Pipeline.scala:355)\norg.apache.spark.ml.PipelineModel$PipelineModelReader.load(Pipeline.scala:349)\norg.apache.spark.ml.util.MLReadable.load(ReadWrite.scala:355)\norg.apache.spark.ml.util.MLReadable.load$(ReadWrite.scala:355)\norg.apache.spark.ml.PipelineModel$.load(Pipeline.scala:337)","Submission Time":1641575660535,"Accumulables":[],"Resource Profile Id":0},"Properties":{"__fetch_continuous_blocks_in_batch_enabled":"true","resource.executor.cores":"2","spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"101\",\"name\":\"first\"}"}}
{"Event":"SparkListenerTaskStart","Stage ID":22,"Stage Attempt ID":0,"Task Info":{"Task ID":34,"Index":0,"Attempt":0,"Launch Time":1641575660539,"Executor ID":"1","Host":"host-name","Locality":"NODE_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":22,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":34,"Index":0,"Attempt":0,"Launch Time":1641575660539,"Executor ID":"1","Host":"host-name","Locality":"NODE_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1641575660640,"Failed":false,"Killed":false,"Accumulables":[{"ID":592,"Name":"internal.metrics.executorDeserializeTime","Update":22,"Value":22,"Internal":true,"Count Failed Values":true},{"ID":593,"Name":"internal.metrics.executorDeserializeCpuTime","Update":19088573,"Value":19088573,"Internal":true,"Count Failed Values":true},{"ID":594,"Name":"internal.metrics.executorRunTime","Update":69,"Value":69,"Internal":true,"Count Failed Values":true},{"ID":595,"Name":"internal.metrics.executorCpuTime","Update":63992842,"Value":63992842,"Internal":true,"Count Failed Values":true},{"ID":596,"Name":"internal.metrics.resultSize","Update":1167,"Value":1167,"Internal":true,"Count Failed Values":true},{"ID":613,"Name":"internal.metrics.input.bytesRead","Update":239,"Value":239,"Internal":true,"Count Failed Values":true},{"ID":614,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0},"Task Metrics":{"Executor Deserialize Time":22,"Executor Deserialize CPU Time":19088573,"Executor Run Time":69,"Executor CPU Time":63992842,"Peak Execution Memory":0,"Result Size":1167,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":239,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":22,"Stage Attempt ID":0,"Stage Name":"first at ReadWrite.scala:587","Number of Tasks":1,"RDD Info":[{"RDD ID":61,"Name":"/tmp/spark-logistic-regression-model/metadata","Scope":"{\"id\":\"100\",\"name\":\"textFile\"}","Callsite":"textFile at ReadWrite.scala:587","Parent IDs":[60],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":60,"Name":"/tmp/spark-logistic-regression-model/metadata","Scope":"{\"id\":\"100\",\"name\":\"textFile\"}","Callsite":"textFile at ReadWrite.scala:587","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.rdd.RDD.first(RDD.scala:1463)\norg.apache.spark.ml.util.DefaultParamsReader$.loadMetadata(ReadWrite.scala:587)\norg.apache.spark.ml.Pipeline$SharedReadWrite$.$anonfun$load$3(Pipeline.scala:269)\norg.apache.spark.ml.util.Instrumentation$.$anonfun$instrumented$1(Instrumentation.scala:191)\nscala.util.Try$.apply(Try.scala:213)\norg.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:191)\norg.apache.spark.ml.Pipeline$SharedReadWrite$.load(Pipeline.scala:268)\norg.apache.spark.ml.PipelineModel$PipelineModelReader.$anonfun$load$7(Pipeline.scala:356)\norg.apache.spark.ml.MLEvents.withLoadInstanceEvent(events.scala:160)\norg.apache.spark.ml.MLEvents.withLoadInstanceEvent$(events.scala:155)\norg.apache.spark.ml.util.Instrumentation.withLoadInstanceEvent(Instrumentation.scala:42)\norg.apache.spark.ml.PipelineModel$PipelineModelReader.$anonfun$load$6(Pipeline.scala:355)\norg.apache.spark.ml.util.Instrumentation$.$anonfun$instrumented$1(Instrumentation.scala:191)\nscala.util.Try$.apply(Try.scala:213)\norg.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:191)\norg.apache.spark.ml.PipelineModel$PipelineModelReader.load(Pipeline.scala:355)\norg.apache.spark.ml.PipelineModel$PipelineModelReader.load(Pipeline.scala:349)\norg.apache.spark.ml.util.MLReadable.load(ReadWrite.scala:355)\norg.apache.spark.ml.util.MLReadable.load$(ReadWrite.scala:355)\norg.apache.spark.ml.PipelineModel$.load(Pipeline.scala:337)","Submission Time":1641575660535,"Completion Time":1641575660641,"Accumulables":[{"ID":592,"Name":"internal.metrics.executorDeserializeTime","Value":22,"Internal":true,"Count Failed Values":true},{"ID":593,"Name":"internal.metrics.executorDeserializeCpuTime","Value":19088573,"Internal":true,"Count Failed Values":true},{"ID":594,"Name":"internal.metrics.executorRunTime","Value":69,"Internal":true,"Count Failed Values":true},{"ID":595,"Name":"internal.metrics.executorCpuTime","Value":63992842,"Internal":true,"Count Failed Values":true},{"ID":596,"Name":"internal.metrics.resultSize","Value":1167,"Internal":true,"Count Failed Values":true},{"ID":613,"Name":"internal.metrics.input.bytesRead","Value":239,"Internal":true,"Count Failed Values":true},{"ID":614,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0}}
{"Event":"SparkListenerJobEnd","Job ID":21,"Completion Time":1641575660641,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"SparkListenerJobStart","Job ID":22,"Submission Time":1641575660708,"Stage Infos":[{"Stage ID":23,"Stage Attempt ID":0,"Stage Name":"first at ReadWrite.scala:587","Number of Tasks":1,"RDD Info":[{"RDD ID":63,"Name":"/tmp/spark-logistic-regression-model/stages/0_tok_f00f56049c5a/metadata","Scope":"{\"id\":\"104\",\"name\":\"textFile\"}","Callsite":"textFile at ReadWrite.scala:587","Parent IDs":[62],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":62,"Name":"/tmp/spark-logistic-regression-model/stages/0_tok_f00f56049c5a/metadata","Scope":"{\"id\":\"104\",\"name\":\"textFile\"}","Callsite":"textFile at ReadWrite.scala:587","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.rdd.RDD.first(RDD.scala:1463)\norg.apache.spark.ml.util.DefaultParamsReader$.loadMetadata(ReadWrite.scala:587)\norg.apache.spark.ml.util.DefaultParamsReader$.loadParamsInstanceReader(ReadWrite.scala:629)\norg.apache.spark.ml.Pipeline$SharedReadWrite$.$anonfun$load$4(Pipeline.scala:276)\nscala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:238)\nscala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)\nscala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)\nscala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)\nscala.collection.TraversableLike.map(TraversableLike.scala:238)\nscala.collection.TraversableLike.map$(TraversableLike.scala:231)\nscala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:198)\norg.apache.spark.ml.Pipeline$SharedReadWrite$.$anonfun$load$3(Pipeline.scala:274)\norg.apache.spark.ml.util.Instrumentation$.$anonfun$instrumented$1(Instrumentation.scala:191)\nscala.util.Try$.apply(Try.scala:213)\norg.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:191)\norg.apache.spark.ml.Pipeline$SharedReadWrite$.load(Pipeline.scala:268)\norg.apache.spark.ml.PipelineModel$PipelineModelReader.$anonfun$load$7(Pipeline.scala:356)\norg.apache.spark.ml.MLEvents.withLoadInstanceEvent(events.scala:160)\norg.apache.spark.ml.MLEvents.withLoadInstanceEvent$(events.scala:155)\norg.apache.spark.ml.util.Instrumentation.withLoadInstanceEvent(Instrumentation.scala:42)","Accumulables":[],"Resource Profile Id":0}],"Stage IDs":[23],"Properties":{"__fetch_continuous_blocks_in_batch_enabled":"true","spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"105\",\"name\":\"first\"}"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":23,"Stage Attempt ID":0,"Stage Name":"first at ReadWrite.scala:587","Number of Tasks":1,"RDD Info":[{"RDD ID":63,"Name":"/tmp/spark-logistic-regression-model/stages/0_tok_f00f56049c5a/metadata","Scope":"{\"id\":\"104\",\"name\":\"textFile\"}","Callsite":"textFile at ReadWrite.scala:587","Parent IDs":[62],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":62,"Name":"/tmp/spark-logistic-regression-model/stages/0_tok_f00f56049c5a/metadata","Scope":"{\"id\":\"104\",\"name\":\"textFile\"}","Callsite":"textFile at ReadWrite.scala:587","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.rdd.RDD.first(RDD.scala:1463)\norg.apache.spark.ml.util.DefaultParamsReader$.loadMetadata(ReadWrite.scala:587)\norg.apache.spark.ml.util.DefaultParamsReader$.loadParamsInstanceReader(ReadWrite.scala:629)\norg.apache.spark.ml.Pipeline$SharedReadWrite$.$anonfun$load$4(Pipeline.scala:276)\nscala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:238)\nscala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)\nscala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)\nscala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)\nscala.collection.TraversableLike.map(TraversableLike.scala:238)\nscala.collection.TraversableLike.map$(TraversableLike.scala:231)\nscala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:198)\norg.apache.spark.ml.Pipeline$SharedReadWrite$.$anonfun$load$3(Pipeline.scala:274)\norg.apache.spark.ml.util.Instrumentation$.$anonfun$instrumented$1(Instrumentation.scala:191)\nscala.util.Try$.apply(Try.scala:213)\norg.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:191)\norg.apache.spark.ml.Pipeline$SharedReadWrite$.load(Pipeline.scala:268)\norg.apache.spark.ml.PipelineModel$PipelineModelReader.$anonfun$load$7(Pipeline.scala:356)\norg.apache.spark.ml.MLEvents.withLoadInstanceEvent(events.scala:160)\norg.apache.spark.ml.MLEvents.withLoadInstanceEvent$(events.scala:155)\norg.apache.spark.ml.util.Instrumentation.withLoadInstanceEvent(Instrumentation.scala:42)","Submission Time":1641575660709,"Accumulables":[],"Resource Profile Id":0},"Properties":{"__fetch_continuous_blocks_in_batch_enabled":"true","resource.executor.cores":"2","spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"105\",\"name\":\"first\"}"}}
{"Event":"SparkListenerTaskStart","Stage ID":23,"Stage Attempt ID":0,"Task Info":{"Task ID":35,"Index":0,"Attempt":0,"Launch Time":1641575660712,"Executor ID":"1","Host":"host-name","Locality":"NODE_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":23,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":35,"Index":0,"Attempt":0,"Launch Time":1641575660712,"Executor ID":"1","Host":"host-name","Locality":"NODE_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1641575660741,"Failed":false,"Killed":false,"Accumulables":[{"ID":617,"Name":"internal.metrics.executorDeserializeTime","Update":7,"Value":7,"Internal":true,"Count Failed Values":true},{"ID":618,"Name":"internal.metrics.executorDeserializeCpuTime","Update":3927445,"Value":3927445,"Internal":true,"Count Failed Values":true},{"ID":619,"Name":"internal.metrics.executorRunTime","Update":18,"Value":18,"Internal":true,"Count Failed Values":true},{"ID":620,"Name":"internal.metrics.executorCpuTime","Update":13190048,"Value":13190048,"Internal":true,"Count Failed Values":true},{"ID":621,"Name":"internal.metrics.resultSize","Update":1162,"Value":1162,"Internal":true,"Count Failed Values":true},{"ID":638,"Name":"internal.metrics.input.bytesRead","Update":234,"Value":234,"Internal":true,"Count Failed Values":true},{"ID":639,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0},"Task Metrics":{"Executor Deserialize Time":7,"Executor Deserialize CPU Time":3927445,"Executor Run Time":18,"Executor CPU Time":13190048,"Peak Execution Memory":0,"Result Size":1162,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":234,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":23,"Stage Attempt ID":0,"Stage Name":"first at ReadWrite.scala:587","Number of Tasks":1,"RDD Info":[{"RDD ID":63,"Name":"/tmp/spark-logistic-regression-model/stages/0_tok_f00f56049c5a/metadata","Scope":"{\"id\":\"104\",\"name\":\"textFile\"}","Callsite":"textFile at ReadWrite.scala:587","Parent IDs":[62],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":62,"Name":"/tmp/spark-logistic-regression-model/stages/0_tok_f00f56049c5a/metadata","Scope":"{\"id\":\"104\",\"name\":\"textFile\"}","Callsite":"textFile at ReadWrite.scala:587","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.rdd.RDD.first(RDD.scala:1463)\norg.apache.spark.ml.util.DefaultParamsReader$.loadMetadata(ReadWrite.scala:587)\norg.apache.spark.ml.util.DefaultParamsReader$.loadParamsInstanceReader(ReadWrite.scala:629)\norg.apache.spark.ml.Pipeline$SharedReadWrite$.$anonfun$load$4(Pipeline.scala:276)\nscala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:238)\nscala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)\nscala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)\nscala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)\nscala.collection.TraversableLike.map(TraversableLike.scala:238)\nscala.collection.TraversableLike.map$(TraversableLike.scala:231)\nscala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:198)\norg.apache.spark.ml.Pipeline$SharedReadWrite$.$anonfun$load$3(Pipeline.scala:274)\norg.apache.spark.ml.util.Instrumentation$.$anonfun$instrumented$1(Instrumentation.scala:191)\nscala.util.Try$.apply(Try.scala:213)\norg.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:191)\norg.apache.spark.ml.Pipeline$SharedReadWrite$.load(Pipeline.scala:268)\norg.apache.spark.ml.PipelineModel$PipelineModelReader.$anonfun$load$7(Pipeline.scala:356)\norg.apache.spark.ml.MLEvents.withLoadInstanceEvent(events.scala:160)\norg.apache.spark.ml.MLEvents.withLoadInstanceEvent$(events.scala:155)\norg.apache.spark.ml.util.Instrumentation.withLoadInstanceEvent(Instrumentation.scala:42)","Submission Time":1641575660709,"Completion Time":1641575660741,"Accumulables":[{"ID":617,"Name":"internal.metrics.executorDeserializeTime","Value":7,"Internal":true,"Count Failed Values":true},{"ID":618,"Name":"internal.metrics.executorDeserializeCpuTime","Value":3927445,"Internal":true,"Count Failed Values":true},{"ID":619,"Name":"internal.metrics.executorRunTime","Value":18,"Internal":true,"Count Failed Values":true},{"ID":620,"Name":"internal.metrics.executorCpuTime","Value":13190048,"Internal":true,"Count Failed Values":true},{"ID":621,"Name":"internal.metrics.resultSize","Value":1162,"Internal":true,"Count Failed Values":true},{"ID":638,"Name":"internal.metrics.input.bytesRead","Value":234,"Internal":true,"Count Failed Values":true},{"ID":639,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0}}
{"Event":"SparkListenerJobEnd","Job ID":22,"Completion Time":1641575660741,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"SparkListenerJobStart","Job ID":23,"Submission Time":1641575660774,"Stage Infos":[{"Stage ID":24,"Stage Attempt ID":0,"Stage Name":"first at ReadWrite.scala:587","Number of Tasks":1,"RDD Info":[{"RDD ID":65,"Name":"/tmp/spark-logistic-regression-model/stages/0_tok_f00f56049c5a/metadata","Scope":"{\"id\":\"108\",\"name\":\"textFile\"}","Callsite":"textFile at ReadWrite.scala:587","Parent IDs":[64],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":64,"Name":"/tmp/spark-logistic-regression-model/stages/0_tok_f00f56049c5a/metadata","Scope":"{\"id\":\"108\",\"name\":\"textFile\"}","Callsite":"textFile at ReadWrite.scala:587","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.rdd.RDD.first(RDD.scala:1463)\norg.apache.spark.ml.util.DefaultParamsReader$.loadMetadata(ReadWrite.scala:587)\norg.apache.spark.ml.util.DefaultParamsReader.load(ReadWrite.scala:465)\norg.apache.spark.ml.Pipeline$SharedReadWrite$.$anonfun$load$5(Pipeline.scala:277)\norg.apache.spark.ml.MLEvents.withLoadInstanceEvent(events.scala:160)\norg.apache.spark.ml.MLEvents.withLoadInstanceEvent$(events.scala:155)\norg.apache.spark.ml.util.Instrumentation.withLoadInstanceEvent(Instrumentation.scala:42)\norg.apache.spark.ml.Pipeline$SharedReadWrite$.$anonfun$load$4(Pipeline.scala:277)\nscala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:238)\nscala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)\nscala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)\nscala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)\nscala.collection.TraversableLike.map(TraversableLike.scala:238)\nscala.collection.TraversableLike.map$(TraversableLike.scala:231)\nscala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:198)\norg.apache.spark.ml.Pipeline$SharedReadWrite$.$anonfun$load$3(Pipeline.scala:274)\norg.apache.spark.ml.util.Instrumentation$.$anonfun$instrumented$1(Instrumentation.scala:191)\nscala.util.Try$.apply(Try.scala:213)\norg.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:191)\norg.apache.spark.ml.Pipeline$SharedReadWrite$.load(Pipeline.scala:268)","Accumulables":[],"Resource Profile Id":0}],"Stage IDs":[24],"Properties":{"__fetch_continuous_blocks_in_batch_enabled":"true","spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"109\",\"name\":\"first\"}"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":24,"Stage Attempt ID":0,"Stage Name":"first at ReadWrite.scala:587","Number of Tasks":1,"RDD Info":[{"RDD ID":65,"Name":"/tmp/spark-logistic-regression-model/stages/0_tok_f00f56049c5a/metadata","Scope":"{\"id\":\"108\",\"name\":\"textFile\"}","Callsite":"textFile at ReadWrite.scala:587","Parent IDs":[64],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":64,"Name":"/tmp/spark-logistic-regression-model/stages/0_tok_f00f56049c5a/metadata","Scope":"{\"id\":\"108\",\"name\":\"textFile\"}","Callsite":"textFile at ReadWrite.scala:587","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.rdd.RDD.first(RDD.scala:1463)\norg.apache.spark.ml.util.DefaultParamsReader$.loadMetadata(ReadWrite.scala:587)\norg.apache.spark.ml.util.DefaultParamsReader.load(ReadWrite.scala:465)\norg.apache.spark.ml.Pipeline$SharedReadWrite$.$anonfun$load$5(Pipeline.scala:277)\norg.apache.spark.ml.MLEvents.withLoadInstanceEvent(events.scala:160)\norg.apache.spark.ml.MLEvents.withLoadInstanceEvent$(events.scala:155)\norg.apache.spark.ml.util.Instrumentation.withLoadInstanceEvent(Instrumentation.scala:42)\norg.apache.spark.ml.Pipeline$SharedReadWrite$.$anonfun$load$4(Pipeline.scala:277)\nscala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:238)\nscala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)\nscala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)\nscala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)\nscala.collection.TraversableLike.map(TraversableLike.scala:238)\nscala.collection.TraversableLike.map$(TraversableLike.scala:231)\nscala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:198)\norg.apache.spark.ml.Pipeline$SharedReadWrite$.$anonfun$load$3(Pipeline.scala:274)\norg.apache.spark.ml.util.Instrumentation$.$anonfun$instrumented$1(Instrumentation.scala:191)\nscala.util.Try$.apply(Try.scala:213)\norg.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:191)\norg.apache.spark.ml.Pipeline$SharedReadWrite$.load(Pipeline.scala:268)","Submission Time":1641575660774,"Accumulables":[],"Resource Profile Id":0},"Properties":{"__fetch_continuous_blocks_in_batch_enabled":"true","resource.executor.cores":"2","spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"109\",\"name\":\"first\"}"}}
{"Event":"SparkListenerTaskStart","Stage ID":24,"Stage Attempt ID":0,"Task Info":{"Task ID":36,"Index":0,"Attempt":0,"Launch Time":1641575660777,"Executor ID":"1","Host":"host-name","Locality":"NODE_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":24,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":36,"Index":0,"Attempt":0,"Launch Time":1641575660777,"Executor ID":"1","Host":"host-name","Locality":"NODE_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1641575660801,"Failed":false,"Killed":false,"Accumulables":[{"ID":642,"Name":"internal.metrics.executorDeserializeTime","Update":6,"Value":6,"Internal":true,"Count Failed Values":true},{"ID":643,"Name":"internal.metrics.executorDeserializeCpuTime","Update":3541722,"Value":3541722,"Internal":true,"Count Failed Values":true},{"ID":644,"Name":"internal.metrics.executorRunTime","Update":13,"Value":13,"Internal":true,"Count Failed Values":true},{"ID":645,"Name":"internal.metrics.executorCpuTime","Update":9685894,"Value":9685894,"Internal":true,"Count Failed Values":true},{"ID":646,"Name":"internal.metrics.resultSize","Update":1162,"Value":1162,"Internal":true,"Count Failed Values":true},{"ID":663,"Name":"internal.metrics.input.bytesRead","Update":234,"Value":234,"Internal":true,"Count Failed Values":true},{"ID":664,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0},"Task Metrics":{"Executor Deserialize Time":6,"Executor Deserialize CPU Time":3541722,"Executor Run Time":13,"Executor CPU Time":9685894,"Peak Execution Memory":0,"Result Size":1162,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":234,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":24,"Stage Attempt ID":0,"Stage Name":"first at ReadWrite.scala:587","Number of Tasks":1,"RDD Info":[{"RDD ID":65,"Name":"/tmp/spark-logistic-regression-model/stages/0_tok_f00f56049c5a/metadata","Scope":"{\"id\":\"108\",\"name\":\"textFile\"}","Callsite":"textFile at ReadWrite.scala:587","Parent IDs":[64],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":64,"Name":"/tmp/spark-logistic-regression-model/stages/0_tok_f00f56049c5a/metadata","Scope":"{\"id\":\"108\",\"name\":\"textFile\"}","Callsite":"textFile at ReadWrite.scala:587","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.rdd.RDD.first(RDD.scala:1463)\norg.apache.spark.ml.util.DefaultParamsReader$.loadMetadata(ReadWrite.scala:587)\norg.apache.spark.ml.util.DefaultParamsReader.load(ReadWrite.scala:465)\norg.apache.spark.ml.Pipeline$SharedReadWrite$.$anonfun$load$5(Pipeline.scala:277)\norg.apache.spark.ml.MLEvents.withLoadInstanceEvent(events.scala:160)\norg.apache.spark.ml.MLEvents.withLoadInstanceEvent$(events.scala:155)\norg.apache.spark.ml.util.Instrumentation.withLoadInstanceEvent(Instrumentation.scala:42)\norg.apache.spark.ml.Pipeline$SharedReadWrite$.$anonfun$load$4(Pipeline.scala:277)\nscala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:238)\nscala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)\nscala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)\nscala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)\nscala.collection.TraversableLike.map(TraversableLike.scala:238)\nscala.collection.TraversableLike.map$(TraversableLike.scala:231)\nscala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:198)\norg.apache.spark.ml.Pipeline$SharedReadWrite$.$anonfun$load$3(Pipeline.scala:274)\norg.apache.spark.ml.util.Instrumentation$.$anonfun$instrumented$1(Instrumentation.scala:191)\nscala.util.Try$.apply(Try.scala:213)\norg.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:191)\norg.apache.spark.ml.Pipeline$SharedReadWrite$.load(Pipeline.scala:268)","Submission Time":1641575660774,"Completion Time":1641575660802,"Accumulables":[{"ID":642,"Name":"internal.metrics.executorDeserializeTime","Value":6,"Internal":true,"Count Failed Values":true},{"ID":643,"Name":"internal.metrics.executorDeserializeCpuTime","Value":3541722,"Internal":true,"Count Failed Values":true},{"ID":644,"Name":"internal.metrics.executorRunTime","Value":13,"Internal":true,"Count Failed Values":true},{"ID":645,"Name":"internal.metrics.executorCpuTime","Value":9685894,"Internal":true,"Count Failed Values":true},{"ID":646,"Name":"internal.metrics.resultSize","Value":1162,"Internal":true,"Count Failed Values":true},{"ID":663,"Name":"internal.metrics.input.bytesRead","Value":234,"Internal":true,"Count Failed Values":true},{"ID":664,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0}}
{"Event":"SparkListenerJobEnd","Job ID":23,"Completion Time":1641575660802,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"SparkListenerJobStart","Job ID":24,"Submission Time":1641575660834,"Stage Infos":[{"Stage ID":25,"Stage Attempt ID":0,"Stage Name":"first at ReadWrite.scala:587","Number of Tasks":1,"RDD Info":[{"RDD ID":67,"Name":"/tmp/spark-logistic-regression-model/stages/1_hashingTF_b3a61aa2a3a0/metadata","Scope":"{\"id\":\"112\",\"name\":\"textFile\"}","Callsite":"textFile at ReadWrite.scala:587","Parent IDs":[66],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":66,"Name":"/tmp/spark-logistic-regression-model/stages/1_hashingTF_b3a61aa2a3a0/metadata","Scope":"{\"id\":\"112\",\"name\":\"textFile\"}","Callsite":"textFile at ReadWrite.scala:587","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.rdd.RDD.first(RDD.scala:1463)\norg.apache.spark.ml.util.DefaultParamsReader$.loadMetadata(ReadWrite.scala:587)\norg.apache.spark.ml.util.DefaultParamsReader$.loadParamsInstanceReader(ReadWrite.scala:629)\norg.apache.spark.ml.Pipeline$SharedReadWrite$.$anonfun$load$4(Pipeline.scala:276)\nscala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:238)\nscala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)\nscala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)\nscala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)\nscala.collection.TraversableLike.map(TraversableLike.scala:238)\nscala.collection.TraversableLike.map$(TraversableLike.scala:231)\nscala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:198)\norg.apache.spark.ml.Pipeline$SharedReadWrite$.$anonfun$load$3(Pipeline.scala:274)\norg.apache.spark.ml.util.Instrumentation$.$anonfun$instrumented$1(Instrumentation.scala:191)\nscala.util.Try$.apply(Try.scala:213)\norg.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:191)\norg.apache.spark.ml.Pipeline$SharedReadWrite$.load(Pipeline.scala:268)\norg.apache.spark.ml.PipelineModel$PipelineModelReader.$anonfun$load$7(Pipeline.scala:356)\norg.apache.spark.ml.MLEvents.withLoadInstanceEvent(events.scala:160)\norg.apache.spark.ml.MLEvents.withLoadInstanceEvent$(events.scala:155)\norg.apache.spark.ml.util.Instrumentation.withLoadInstanceEvent(Instrumentation.scala:42)","Accumulables":[],"Resource Profile Id":0}],"Stage IDs":[25],"Properties":{"__fetch_continuous_blocks_in_batch_enabled":"true","spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"113\",\"name\":\"first\"}"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":25,"Stage Attempt ID":0,"Stage Name":"first at ReadWrite.scala:587","Number of Tasks":1,"RDD Info":[{"RDD ID":67,"Name":"/tmp/spark-logistic-regression-model/stages/1_hashingTF_b3a61aa2a3a0/metadata","Scope":"{\"id\":\"112\",\"name\":\"textFile\"}","Callsite":"textFile at ReadWrite.scala:587","Parent IDs":[66],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":66,"Name":"/tmp/spark-logistic-regression-model/stages/1_hashingTF_b3a61aa2a3a0/metadata","Scope":"{\"id\":\"112\",\"name\":\"textFile\"}","Callsite":"textFile at ReadWrite.scala:587","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.rdd.RDD.first(RDD.scala:1463)\norg.apache.spark.ml.util.DefaultParamsReader$.loadMetadata(ReadWrite.scala:587)\norg.apache.spark.ml.util.DefaultParamsReader$.loadParamsInstanceReader(ReadWrite.scala:629)\norg.apache.spark.ml.Pipeline$SharedReadWrite$.$anonfun$load$4(Pipeline.scala:276)\nscala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:238)\nscala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)\nscala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)\nscala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)\nscala.collection.TraversableLike.map(TraversableLike.scala:238)\nscala.collection.TraversableLike.map$(TraversableLike.scala:231)\nscala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:198)\norg.apache.spark.ml.Pipeline$SharedReadWrite$.$anonfun$load$3(Pipeline.scala:274)\norg.apache.spark.ml.util.Instrumentation$.$anonfun$instrumented$1(Instrumentation.scala:191)\nscala.util.Try$.apply(Try.scala:213)\norg.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:191)\norg.apache.spark.ml.Pipeline$SharedReadWrite$.load(Pipeline.scala:268)\norg.apache.spark.ml.PipelineModel$PipelineModelReader.$anonfun$load$7(Pipeline.scala:356)\norg.apache.spark.ml.MLEvents.withLoadInstanceEvent(events.scala:160)\norg.apache.spark.ml.MLEvents.withLoadInstanceEvent$(events.scala:155)\norg.apache.spark.ml.util.Instrumentation.withLoadInstanceEvent(Instrumentation.scala:42)","Submission Time":1641575660835,"Accumulables":[],"Resource Profile Id":0},"Properties":{"__fetch_continuous_blocks_in_batch_enabled":"true","resource.executor.cores":"2","spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"113\",\"name\":\"first\"}"}}
{"Event":"SparkListenerTaskStart","Stage ID":25,"Stage Attempt ID":0,"Task Info":{"Task ID":37,"Index":0,"Attempt":0,"Launch Time":1641575660838,"Executor ID":"1","Host":"host-name","Locality":"NODE_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":25,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":37,"Index":0,"Attempt":0,"Launch Time":1641575660838,"Executor ID":"1","Host":"host-name","Locality":"NODE_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1641575660866,"Failed":false,"Killed":false,"Accumulables":[{"ID":667,"Name":"internal.metrics.executorDeserializeTime","Update":6,"Value":6,"Internal":true,"Count Failed Values":true},{"ID":668,"Name":"internal.metrics.executorDeserializeCpuTime","Update":4132426,"Value":4132426,"Internal":true,"Count Failed Values":true},{"ID":669,"Name":"internal.metrics.executorRunTime","Update":17,"Value":17,"Internal":true,"Count Failed Values":true},{"ID":670,"Name":"internal.metrics.executorCpuTime","Update":13496816,"Value":13496816,"Internal":true,"Count Failed Values":true},{"ID":671,"Name":"internal.metrics.resultSize","Update":1233,"Value":1233,"Internal":true,"Count Failed Values":true},{"ID":688,"Name":"internal.metrics.input.bytesRead","Update":305,"Value":305,"Internal":true,"Count Failed Values":true},{"ID":689,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0},"Task Metrics":{"Executor Deserialize Time":6,"Executor Deserialize CPU Time":4132426,"Executor Run Time":17,"Executor CPU Time":13496816,"Peak Execution Memory":0,"Result Size":1233,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":305,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":25,"Stage Attempt ID":0,"Stage Name":"first at ReadWrite.scala:587","Number of Tasks":1,"RDD Info":[{"RDD ID":67,"Name":"/tmp/spark-logistic-regression-model/stages/1_hashingTF_b3a61aa2a3a0/metadata","Scope":"{\"id\":\"112\",\"name\":\"textFile\"}","Callsite":"textFile at ReadWrite.scala:587","Parent IDs":[66],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":66,"Name":"/tmp/spark-logistic-regression-model/stages/1_hashingTF_b3a61aa2a3a0/metadata","Scope":"{\"id\":\"112\",\"name\":\"textFile\"}","Callsite":"textFile at ReadWrite.scala:587","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.rdd.RDD.first(RDD.scala:1463)\norg.apache.spark.ml.util.DefaultParamsReader$.loadMetadata(ReadWrite.scala:587)\norg.apache.spark.ml.util.DefaultParamsReader$.loadParamsInstanceReader(ReadWrite.scala:629)\norg.apache.spark.ml.Pipeline$SharedReadWrite$.$anonfun$load$4(Pipeline.scala:276)\nscala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:238)\nscala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)\nscala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)\nscala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)\nscala.collection.TraversableLike.map(TraversableLike.scala:238)\nscala.collection.TraversableLike.map$(TraversableLike.scala:231)\nscala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:198)\norg.apache.spark.ml.Pipeline$SharedReadWrite$.$anonfun$load$3(Pipeline.scala:274)\norg.apache.spark.ml.util.Instrumentation$.$anonfun$instrumented$1(Instrumentation.scala:191)\nscala.util.Try$.apply(Try.scala:213)\norg.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:191)\norg.apache.spark.ml.Pipeline$SharedReadWrite$.load(Pipeline.scala:268)\norg.apache.spark.ml.PipelineModel$PipelineModelReader.$anonfun$load$7(Pipeline.scala:356)\norg.apache.spark.ml.MLEvents.withLoadInstanceEvent(events.scala:160)\norg.apache.spark.ml.MLEvents.withLoadInstanceEvent$(events.scala:155)\norg.apache.spark.ml.util.Instrumentation.withLoadInstanceEvent(Instrumentation.scala:42)","Submission Time":1641575660835,"Completion Time":1641575660867,"Accumulables":[{"ID":667,"Name":"internal.metrics.executorDeserializeTime","Value":6,"Internal":true,"Count Failed Values":true},{"ID":668,"Name":"internal.metrics.executorDeserializeCpuTime","Value":4132426,"Internal":true,"Count Failed Values":true},{"ID":669,"Name":"internal.metrics.executorRunTime","Value":17,"Internal":true,"Count Failed Values":true},{"ID":670,"Name":"internal.metrics.executorCpuTime","Value":13496816,"Internal":true,"Count Failed Values":true},{"ID":671,"Name":"internal.metrics.resultSize","Value":1233,"Internal":true,"Count Failed Values":true},{"ID":688,"Name":"internal.metrics.input.bytesRead","Value":305,"Internal":true,"Count Failed Values":true},{"ID":689,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0}}
{"Event":"SparkListenerJobEnd","Job ID":24,"Completion Time":1641575660867,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"SparkListenerJobStart","Job ID":25,"Submission Time":1641575660896,"Stage Infos":[{"Stage ID":26,"Stage Attempt ID":0,"Stage Name":"first at ReadWrite.scala:587","Number of Tasks":1,"RDD Info":[{"RDD ID":69,"Name":"/tmp/spark-logistic-regression-model/stages/1_hashingTF_b3a61aa2a3a0/metadata","Scope":"{\"id\":\"116\",\"name\":\"textFile\"}","Callsite":"textFile at ReadWrite.scala:587","Parent IDs":[68],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":68,"Name":"/tmp/spark-logistic-regression-model/stages/1_hashingTF_b3a61aa2a3a0/metadata","Scope":"{\"id\":\"116\",\"name\":\"textFile\"}","Callsite":"textFile at ReadWrite.scala:587","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.rdd.RDD.first(RDD.scala:1463)\norg.apache.spark.ml.util.DefaultParamsReader$.loadMetadata(ReadWrite.scala:587)\norg.apache.spark.ml.feature.HashingTF$HashingTFReader.load(HashingTF.scala:157)\norg.apache.spark.ml.feature.HashingTF$HashingTFReader.load(HashingTF.scala:152)\norg.apache.spark.ml.Pipeline$SharedReadWrite$.$anonfun$load$5(Pipeline.scala:277)\norg.apache.spark.ml.MLEvents.withLoadInstanceEvent(events.scala:160)\norg.apache.spark.ml.MLEvents.withLoadInstanceEvent$(events.scala:155)\norg.apache.spark.ml.util.Instrumentation.withLoadInstanceEvent(Instrumentation.scala:42)\norg.apache.spark.ml.Pipeline$SharedReadWrite$.$anonfun$load$4(Pipeline.scala:277)\nscala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:238)\nscala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)\nscala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)\nscala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)\nscala.collection.TraversableLike.map(TraversableLike.scala:238)\nscala.collection.TraversableLike.map$(TraversableLike.scala:231)\nscala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:198)\norg.apache.spark.ml.Pipeline$SharedReadWrite$.$anonfun$load$3(Pipeline.scala:274)\norg.apache.spark.ml.util.Instrumentation$.$anonfun$instrumented$1(Instrumentation.scala:191)\nscala.util.Try$.apply(Try.scala:213)\norg.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:191)","Accumulables":[],"Resource Profile Id":0}],"Stage IDs":[26],"Properties":{"__fetch_continuous_blocks_in_batch_enabled":"true","spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"117\",\"name\":\"first\"}"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":26,"Stage Attempt ID":0,"Stage Name":"first at ReadWrite.scala:587","Number of Tasks":1,"RDD Info":[{"RDD ID":69,"Name":"/tmp/spark-logistic-regression-model/stages/1_hashingTF_b3a61aa2a3a0/metadata","Scope":"{\"id\":\"116\",\"name\":\"textFile\"}","Callsite":"textFile at ReadWrite.scala:587","Parent IDs":[68],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":68,"Name":"/tmp/spark-logistic-regression-model/stages/1_hashingTF_b3a61aa2a3a0/metadata","Scope":"{\"id\":\"116\",\"name\":\"textFile\"}","Callsite":"textFile at ReadWrite.scala:587","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.rdd.RDD.first(RDD.scala:1463)\norg.apache.spark.ml.util.DefaultParamsReader$.loadMetadata(ReadWrite.scala:587)\norg.apache.spark.ml.feature.HashingTF$HashingTFReader.load(HashingTF.scala:157)\norg.apache.spark.ml.feature.HashingTF$HashingTFReader.load(HashingTF.scala:152)\norg.apache.spark.ml.Pipeline$SharedReadWrite$.$anonfun$load$5(Pipeline.scala:277)\norg.apache.spark.ml.MLEvents.withLoadInstanceEvent(events.scala:160)\norg.apache.spark.ml.MLEvents.withLoadInstanceEvent$(events.scala:155)\norg.apache.spark.ml.util.Instrumentation.withLoadInstanceEvent(Instrumentation.scala:42)\norg.apache.spark.ml.Pipeline$SharedReadWrite$.$anonfun$load$4(Pipeline.scala:277)\nscala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:238)\nscala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)\nscala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)\nscala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)\nscala.collection.TraversableLike.map(TraversableLike.scala:238)\nscala.collection.TraversableLike.map$(TraversableLike.scala:231)\nscala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:198)\norg.apache.spark.ml.Pipeline$SharedReadWrite$.$anonfun$load$3(Pipeline.scala:274)\norg.apache.spark.ml.util.Instrumentation$.$anonfun$instrumented$1(Instrumentation.scala:191)\nscala.util.Try$.apply(Try.scala:213)\norg.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:191)","Submission Time":1641575660896,"Accumulables":[],"Resource Profile Id":0},"Properties":{"__fetch_continuous_blocks_in_batch_enabled":"true","resource.executor.cores":"2","spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"117\",\"name\":\"first\"}"}}
{"Event":"SparkListenerTaskStart","Stage ID":26,"Stage Attempt ID":0,"Task Info":{"Task ID":38,"Index":0,"Attempt":0,"Launch Time":1641575660900,"Executor ID":"1","Host":"host-name","Locality":"NODE_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":26,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":38,"Index":0,"Attempt":0,"Launch Time":1641575660900,"Executor ID":"1","Host":"host-name","Locality":"NODE_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1641575660928,"Failed":false,"Killed":false,"Accumulables":[{"ID":692,"Name":"internal.metrics.executorDeserializeTime","Update":7,"Value":7,"Internal":true,"Count Failed Values":true},{"ID":693,"Name":"internal.metrics.executorDeserializeCpuTime","Update":4419848,"Value":4419848,"Internal":true,"Count Failed Values":true},{"ID":694,"Name":"internal.metrics.executorRunTime","Update":16,"Value":16,"Internal":true,"Count Failed Values":true},{"ID":695,"Name":"internal.metrics.executorCpuTime","Update":13021901,"Value":13021901,"Internal":true,"Count Failed Values":true},{"ID":696,"Name":"internal.metrics.resultSize","Update":1233,"Value":1233,"Internal":true,"Count Failed Values":true},{"ID":713,"Name":"internal.metrics.input.bytesRead","Update":305,"Value":305,"Internal":true,"Count Failed Values":true},{"ID":714,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0},"Task Metrics":{"Executor Deserialize Time":7,"Executor Deserialize CPU Time":4419848,"Executor Run Time":16,"Executor CPU Time":13021901,"Peak Execution Memory":0,"Result Size":1233,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":305,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":26,"Stage Attempt ID":0,"Stage Name":"first at ReadWrite.scala:587","Number of Tasks":1,"RDD Info":[{"RDD ID":69,"Name":"/tmp/spark-logistic-regression-model/stages/1_hashingTF_b3a61aa2a3a0/metadata","Scope":"{\"id\":\"116\",\"name\":\"textFile\"}","Callsite":"textFile at ReadWrite.scala:587","Parent IDs":[68],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":68,"Name":"/tmp/spark-logistic-regression-model/stages/1_hashingTF_b3a61aa2a3a0/metadata","Scope":"{\"id\":\"116\",\"name\":\"textFile\"}","Callsite":"textFile at ReadWrite.scala:587","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.rdd.RDD.first(RDD.scala:1463)\norg.apache.spark.ml.util.DefaultParamsReader$.loadMetadata(ReadWrite.scala:587)\norg.apache.spark.ml.feature.HashingTF$HashingTFReader.load(HashingTF.scala:157)\norg.apache.spark.ml.feature.HashingTF$HashingTFReader.load(HashingTF.scala:152)\norg.apache.spark.ml.Pipeline$SharedReadWrite$.$anonfun$load$5(Pipeline.scala:277)\norg.apache.spark.ml.MLEvents.withLoadInstanceEvent(events.scala:160)\norg.apache.spark.ml.MLEvents.withLoadInstanceEvent$(events.scala:155)\norg.apache.spark.ml.util.Instrumentation.withLoadInstanceEvent(Instrumentation.scala:42)\norg.apache.spark.ml.Pipeline$SharedReadWrite$.$anonfun$load$4(Pipeline.scala:277)\nscala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:238)\nscala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)\nscala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)\nscala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)\nscala.collection.TraversableLike.map(TraversableLike.scala:238)\nscala.collection.TraversableLike.map$(TraversableLike.scala:231)\nscala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:198)\norg.apache.spark.ml.Pipeline$SharedReadWrite$.$anonfun$load$3(Pipeline.scala:274)\norg.apache.spark.ml.util.Instrumentation$.$anonfun$instrumented$1(Instrumentation.scala:191)\nscala.util.Try$.apply(Try.scala:213)\norg.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:191)","Submission Time":1641575660896,"Completion Time":1641575660929,"Accumulables":[{"ID":692,"Name":"internal.metrics.executorDeserializeTime","Value":7,"Internal":true,"Count Failed Values":true},{"ID":693,"Name":"internal.metrics.executorDeserializeCpuTime","Value":4419848,"Internal":true,"Count Failed Values":true},{"ID":694,"Name":"internal.metrics.executorRunTime","Value":16,"Internal":true,"Count Failed Values":true},{"ID":695,"Name":"internal.metrics.executorCpuTime","Value":13021901,"Internal":true,"Count Failed Values":true},{"ID":696,"Name":"internal.metrics.resultSize","Value":1233,"Internal":true,"Count Failed Values":true},{"ID":713,"Name":"internal.metrics.input.bytesRead","Value":305,"Internal":true,"Count Failed Values":true},{"ID":714,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0}}
{"Event":"SparkListenerJobEnd","Job ID":25,"Completion Time":1641575660929,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"SparkListenerJobStart","Job ID":26,"Submission Time":1641575660959,"Stage Infos":[{"Stage ID":27,"Stage Attempt ID":0,"Stage Name":"first at ReadWrite.scala:587","Number of Tasks":1,"RDD Info":[{"RDD ID":71,"Name":"/tmp/spark-logistic-regression-model/stages/2_logreg_8b15d2f29345/metadata","Scope":"{\"id\":\"120\",\"name\":\"textFile\"}","Callsite":"textFile at ReadWrite.scala:587","Parent IDs":[70],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":70,"Name":"/tmp/spark-logistic-regression-model/stages/2_logreg_8b15d2f29345/metadata","Scope":"{\"id\":\"120\",\"name\":\"textFile\"}","Callsite":"textFile at ReadWrite.scala:587","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.rdd.RDD.first(RDD.scala:1463)\norg.apache.spark.ml.util.DefaultParamsReader$.loadMetadata(ReadWrite.scala:587)\norg.apache.spark.ml.util.DefaultParamsReader$.loadParamsInstanceReader(ReadWrite.scala:629)\norg.apache.spark.ml.Pipeline$SharedReadWrite$.$anonfun$load$4(Pipeline.scala:276)\nscala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:238)\nscala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)\nscala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)\nscala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)\nscala.collection.TraversableLike.map(TraversableLike.scala:238)\nscala.collection.TraversableLike.map$(TraversableLike.scala:231)\nscala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:198)\norg.apache.spark.ml.Pipeline$SharedReadWrite$.$anonfun$load$3(Pipeline.scala:274)\norg.apache.spark.ml.util.Instrumentation$.$anonfun$instrumented$1(Instrumentation.scala:191)\nscala.util.Try$.apply(Try.scala:213)\norg.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:191)\norg.apache.spark.ml.Pipeline$SharedReadWrite$.load(Pipeline.scala:268)\norg.apache.spark.ml.PipelineModel$PipelineModelReader.$anonfun$load$7(Pipeline.scala:356)\norg.apache.spark.ml.MLEvents.withLoadInstanceEvent(events.scala:160)\norg.apache.spark.ml.MLEvents.withLoadInstanceEvent$(events.scala:155)\norg.apache.spark.ml.util.Instrumentation.withLoadInstanceEvent(Instrumentation.scala:42)","Accumulables":[],"Resource Profile Id":0}],"Stage IDs":[27],"Properties":{"__fetch_continuous_blocks_in_batch_enabled":"true","spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"121\",\"name\":\"first\"}"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":27,"Stage Attempt ID":0,"Stage Name":"first at ReadWrite.scala:587","Number of Tasks":1,"RDD Info":[{"RDD ID":71,"Name":"/tmp/spark-logistic-regression-model/stages/2_logreg_8b15d2f29345/metadata","Scope":"{\"id\":\"120\",\"name\":\"textFile\"}","Callsite":"textFile at ReadWrite.scala:587","Parent IDs":[70],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":70,"Name":"/tmp/spark-logistic-regression-model/stages/2_logreg_8b15d2f29345/metadata","Scope":"{\"id\":\"120\",\"name\":\"textFile\"}","Callsite":"textFile at ReadWrite.scala:587","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.rdd.RDD.first(RDD.scala:1463)\norg.apache.spark.ml.util.DefaultParamsReader$.loadMetadata(ReadWrite.scala:587)\norg.apache.spark.ml.util.DefaultParamsReader$.loadParamsInstanceReader(ReadWrite.scala:629)\norg.apache.spark.ml.Pipeline$SharedReadWrite$.$anonfun$load$4(Pipeline.scala:276)\nscala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:238)\nscala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)\nscala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)\nscala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)\nscala.collection.TraversableLike.map(TraversableLike.scala:238)\nscala.collection.TraversableLike.map$(TraversableLike.scala:231)\nscala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:198)\norg.apache.spark.ml.Pipeline$SharedReadWrite$.$anonfun$load$3(Pipeline.scala:274)\norg.apache.spark.ml.util.Instrumentation$.$anonfun$instrumented$1(Instrumentation.scala:191)\nscala.util.Try$.apply(Try.scala:213)\norg.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:191)\norg.apache.spark.ml.Pipeline$SharedReadWrite$.load(Pipeline.scala:268)\norg.apache.spark.ml.PipelineModel$PipelineModelReader.$anonfun$load$7(Pipeline.scala:356)\norg.apache.spark.ml.MLEvents.withLoadInstanceEvent(events.scala:160)\norg.apache.spark.ml.MLEvents.withLoadInstanceEvent$(events.scala:155)\norg.apache.spark.ml.util.Instrumentation.withLoadInstanceEvent(Instrumentation.scala:42)","Submission Time":1641575660960,"Accumulables":[],"Resource Profile Id":0},"Properties":{"__fetch_continuous_blocks_in_batch_enabled":"true","resource.executor.cores":"2","spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"121\",\"name\":\"first\"}"}}
{"Event":"SparkListenerTaskStart","Stage ID":27,"Stage Attempt ID":0,"Task Info":{"Task ID":39,"Index":0,"Attempt":0,"Launch Time":1641575660981,"Executor ID":"1","Host":"host-name","Locality":"NODE_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":27,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":39,"Index":0,"Attempt":0,"Launch Time":1641575660981,"Executor ID":"1","Host":"host-name","Locality":"NODE_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1641575661021,"Failed":false,"Killed":false,"Accumulables":[{"ID":717,"Name":"internal.metrics.executorDeserializeTime","Update":15,"Value":15,"Internal":true,"Count Failed Values":true},{"ID":718,"Name":"internal.metrics.executorDeserializeCpuTime","Update":5012771,"Value":5012771,"Internal":true,"Count Failed Values":true},{"ID":719,"Name":"internal.metrics.executorRunTime","Update":18,"Value":18,"Internal":true,"Count Failed Values":true},{"ID":720,"Name":"internal.metrics.executorCpuTime","Update":11107372,"Value":11107372,"Internal":true,"Count Failed Values":true},{"ID":721,"Name":"internal.metrics.resultSize","Update":1461,"Value":1461,"Internal":true,"Count Failed Values":true},{"ID":738,"Name":"internal.metrics.input.bytesRead","Update":533,"Value":533,"Internal":true,"Count Failed Values":true},{"ID":739,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0},"Task Metrics":{"Executor Deserialize Time":15,"Executor Deserialize CPU Time":5012771,"Executor Run Time":18,"Executor CPU Time":11107372,"Peak Execution Memory":0,"Result Size":1461,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":533,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":27,"Stage Attempt ID":0,"Stage Name":"first at ReadWrite.scala:587","Number of Tasks":1,"RDD Info":[{"RDD ID":71,"Name":"/tmp/spark-logistic-regression-model/stages/2_logreg_8b15d2f29345/metadata","Scope":"{\"id\":\"120\",\"name\":\"textFile\"}","Callsite":"textFile at ReadWrite.scala:587","Parent IDs":[70],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":70,"Name":"/tmp/spark-logistic-regression-model/stages/2_logreg_8b15d2f29345/metadata","Scope":"{\"id\":\"120\",\"name\":\"textFile\"}","Callsite":"textFile at ReadWrite.scala:587","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.rdd.RDD.first(RDD.scala:1463)\norg.apache.spark.ml.util.DefaultParamsReader$.loadMetadata(ReadWrite.scala:587)\norg.apache.spark.ml.util.DefaultParamsReader$.loadParamsInstanceReader(ReadWrite.scala:629)\norg.apache.spark.ml.Pipeline$SharedReadWrite$.$anonfun$load$4(Pipeline.scala:276)\nscala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:238)\nscala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)\nscala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)\nscala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)\nscala.collection.TraversableLike.map(TraversableLike.scala:238)\nscala.collection.TraversableLike.map$(TraversableLike.scala:231)\nscala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:198)\norg.apache.spark.ml.Pipeline$SharedReadWrite$.$anonfun$load$3(Pipeline.scala:274)\norg.apache.spark.ml.util.Instrumentation$.$anonfun$instrumented$1(Instrumentation.scala:191)\nscala.util.Try$.apply(Try.scala:213)\norg.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:191)\norg.apache.spark.ml.Pipeline$SharedReadWrite$.load(Pipeline.scala:268)\norg.apache.spark.ml.PipelineModel$PipelineModelReader.$anonfun$load$7(Pipeline.scala:356)\norg.apache.spark.ml.MLEvents.withLoadInstanceEvent(events.scala:160)\norg.apache.spark.ml.MLEvents.withLoadInstanceEvent$(events.scala:155)\norg.apache.spark.ml.util.Instrumentation.withLoadInstanceEvent(Instrumentation.scala:42)","Submission Time":1641575660960,"Completion Time":1641575661022,"Accumulables":[{"ID":717,"Name":"internal.metrics.executorDeserializeTime","Value":15,"Internal":true,"Count Failed Values":true},{"ID":718,"Name":"internal.metrics.executorDeserializeCpuTime","Value":5012771,"Internal":true,"Count Failed Values":true},{"ID":719,"Name":"internal.metrics.executorRunTime","Value":18,"Internal":true,"Count Failed Values":true},{"ID":720,"Name":"internal.metrics.executorCpuTime","Value":11107372,"Internal":true,"Count Failed Values":true},{"ID":721,"Name":"internal.metrics.resultSize","Value":1461,"Internal":true,"Count Failed Values":true},{"ID":738,"Name":"internal.metrics.input.bytesRead","Value":533,"Internal":true,"Count Failed Values":true},{"ID":739,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0}}
{"Event":"SparkListenerJobEnd","Job ID":26,"Completion Time":1641575661022,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"SparkListenerJobStart","Job ID":27,"Submission Time":1641575661059,"Stage Infos":[{"Stage ID":28,"Stage Attempt ID":0,"Stage Name":"first at ReadWrite.scala:587","Number of Tasks":1,"RDD Info":[{"RDD ID":73,"Name":"/tmp/spark-logistic-regression-model/stages/2_logreg_8b15d2f29345/metadata","Scope":"{\"id\":\"124\",\"name\":\"textFile\"}","Callsite":"textFile at ReadWrite.scala:587","Parent IDs":[72],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":72,"Name":"/tmp/spark-logistic-regression-model/stages/2_logreg_8b15d2f29345/metadata","Scope":"{\"id\":\"124\",\"name\":\"textFile\"}","Callsite":"textFile at ReadWrite.scala:587","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.rdd.RDD.first(RDD.scala:1463)\norg.apache.spark.ml.util.DefaultParamsReader$.loadMetadata(ReadWrite.scala:587)\norg.apache.spark.ml.classification.LogisticRegressionModel$LogisticRegressionModelReader.load(LogisticRegression.scala:1298)\norg.apache.spark.ml.classification.LogisticRegressionModel$LogisticRegressionModelReader.load(LogisticRegression.scala:1292)\norg.apache.spark.ml.Pipeline$SharedReadWrite$.$anonfun$load$5(Pipeline.scala:277)\norg.apache.spark.ml.MLEvents.withLoadInstanceEvent(events.scala:160)\norg.apache.spark.ml.MLEvents.withLoadInstanceEvent$(events.scala:155)\norg.apache.spark.ml.util.Instrumentation.withLoadInstanceEvent(Instrumentation.scala:42)\norg.apache.spark.ml.Pipeline$SharedReadWrite$.$anonfun$load$4(Pipeline.scala:277)\nscala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:238)\nscala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)\nscala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)\nscala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)\nscala.collection.TraversableLike.map(TraversableLike.scala:238)\nscala.collection.TraversableLike.map$(TraversableLike.scala:231)\nscala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:198)\norg.apache.spark.ml.Pipeline$SharedReadWrite$.$anonfun$load$3(Pipeline.scala:274)\norg.apache.spark.ml.util.Instrumentation$.$anonfun$instrumented$1(Instrumentation.scala:191)\nscala.util.Try$.apply(Try.scala:213)\norg.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:191)","Accumulables":[],"Resource Profile Id":0}],"Stage IDs":[28],"Properties":{"__fetch_continuous_blocks_in_batch_enabled":"true","spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"125\",\"name\":\"first\"}"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":28,"Stage Attempt ID":0,"Stage Name":"first at ReadWrite.scala:587","Number of Tasks":1,"RDD Info":[{"RDD ID":73,"Name":"/tmp/spark-logistic-regression-model/stages/2_logreg_8b15d2f29345/metadata","Scope":"{\"id\":\"124\",\"name\":\"textFile\"}","Callsite":"textFile at ReadWrite.scala:587","Parent IDs":[72],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":72,"Name":"/tmp/spark-logistic-regression-model/stages/2_logreg_8b15d2f29345/metadata","Scope":"{\"id\":\"124\",\"name\":\"textFile\"}","Callsite":"textFile at ReadWrite.scala:587","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.rdd.RDD.first(RDD.scala:1463)\norg.apache.spark.ml.util.DefaultParamsReader$.loadMetadata(ReadWrite.scala:587)\norg.apache.spark.ml.classification.LogisticRegressionModel$LogisticRegressionModelReader.load(LogisticRegression.scala:1298)\norg.apache.spark.ml.classification.LogisticRegressionModel$LogisticRegressionModelReader.load(LogisticRegression.scala:1292)\norg.apache.spark.ml.Pipeline$SharedReadWrite$.$anonfun$load$5(Pipeline.scala:277)\norg.apache.spark.ml.MLEvents.withLoadInstanceEvent(events.scala:160)\norg.apache.spark.ml.MLEvents.withLoadInstanceEvent$(events.scala:155)\norg.apache.spark.ml.util.Instrumentation.withLoadInstanceEvent(Instrumentation.scala:42)\norg.apache.spark.ml.Pipeline$SharedReadWrite$.$anonfun$load$4(Pipeline.scala:277)\nscala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:238)\nscala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)\nscala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)\nscala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)\nscala.collection.TraversableLike.map(TraversableLike.scala:238)\nscala.collection.TraversableLike.map$(TraversableLike.scala:231)\nscala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:198)\norg.apache.spark.ml.Pipeline$SharedReadWrite$.$anonfun$load$3(Pipeline.scala:274)\norg.apache.spark.ml.util.Instrumentation$.$anonfun$instrumented$1(Instrumentation.scala:191)\nscala.util.Try$.apply(Try.scala:213)\norg.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:191)","Submission Time":1641575661060,"Accumulables":[],"Resource Profile Id":0},"Properties":{"__fetch_continuous_blocks_in_batch_enabled":"true","resource.executor.cores":"2","spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"125\",\"name\":\"first\"}"}}
{"Event":"SparkListenerTaskStart","Stage ID":28,"Stage Attempt ID":0,"Task Info":{"Task ID":40,"Index":0,"Attempt":0,"Launch Time":1641575661068,"Executor ID":"1","Host":"host-name","Locality":"NODE_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":28,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":40,"Index":0,"Attempt":0,"Launch Time":1641575661068,"Executor ID":"1","Host":"host-name","Locality":"NODE_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1641575661101,"Failed":false,"Killed":false,"Accumulables":[{"ID":742,"Name":"internal.metrics.executorDeserializeTime","Update":8,"Value":8,"Internal":true,"Count Failed Values":true},{"ID":743,"Name":"internal.metrics.executorDeserializeCpuTime","Update":4535290,"Value":4535290,"Internal":true,"Count Failed Values":true},{"ID":744,"Name":"internal.metrics.executorRunTime","Update":20,"Value":20,"Internal":true,"Count Failed Values":true},{"ID":745,"Name":"internal.metrics.executorCpuTime","Update":12478607,"Value":12478607,"Internal":true,"Count Failed Values":true},{"ID":746,"Name":"internal.metrics.resultSize","Update":1461,"Value":1461,"Internal":true,"Count Failed Values":true},{"ID":763,"Name":"internal.metrics.input.bytesRead","Update":533,"Value":533,"Internal":true,"Count Failed Values":true},{"ID":764,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0},"Task Metrics":{"Executor Deserialize Time":8,"Executor Deserialize CPU Time":4535290,"Executor Run Time":20,"Executor CPU Time":12478607,"Peak Execution Memory":0,"Result Size":1461,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":533,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":28,"Stage Attempt ID":0,"Stage Name":"first at ReadWrite.scala:587","Number of Tasks":1,"RDD Info":[{"RDD ID":73,"Name":"/tmp/spark-logistic-regression-model/stages/2_logreg_8b15d2f29345/metadata","Scope":"{\"id\":\"124\",\"name\":\"textFile\"}","Callsite":"textFile at ReadWrite.scala:587","Parent IDs":[72],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":72,"Name":"/tmp/spark-logistic-regression-model/stages/2_logreg_8b15d2f29345/metadata","Scope":"{\"id\":\"124\",\"name\":\"textFile\"}","Callsite":"textFile at ReadWrite.scala:587","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.rdd.RDD.first(RDD.scala:1463)\norg.apache.spark.ml.util.DefaultParamsReader$.loadMetadata(ReadWrite.scala:587)\norg.apache.spark.ml.classification.LogisticRegressionModel$LogisticRegressionModelReader.load(LogisticRegression.scala:1298)\norg.apache.spark.ml.classification.LogisticRegressionModel$LogisticRegressionModelReader.load(LogisticRegression.scala:1292)\norg.apache.spark.ml.Pipeline$SharedReadWrite$.$anonfun$load$5(Pipeline.scala:277)\norg.apache.spark.ml.MLEvents.withLoadInstanceEvent(events.scala:160)\norg.apache.spark.ml.MLEvents.withLoadInstanceEvent$(events.scala:155)\norg.apache.spark.ml.util.Instrumentation.withLoadInstanceEvent(Instrumentation.scala:42)\norg.apache.spark.ml.Pipeline$SharedReadWrite$.$anonfun$load$4(Pipeline.scala:277)\nscala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:238)\nscala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)\nscala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)\nscala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)\nscala.collection.TraversableLike.map(TraversableLike.scala:238)\nscala.collection.TraversableLike.map$(TraversableLike.scala:231)\nscala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:198)\norg.apache.spark.ml.Pipeline$SharedReadWrite$.$anonfun$load$3(Pipeline.scala:274)\norg.apache.spark.ml.util.Instrumentation$.$anonfun$instrumented$1(Instrumentation.scala:191)\nscala.util.Try$.apply(Try.scala:213)\norg.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:191)","Submission Time":1641575661060,"Completion Time":1641575661102,"Accumulables":[{"ID":742,"Name":"internal.metrics.executorDeserializeTime","Value":8,"Internal":true,"Count Failed Values":true},{"ID":743,"Name":"internal.metrics.executorDeserializeCpuTime","Value":4535290,"Internal":true,"Count Failed Values":true},{"ID":744,"Name":"internal.metrics.executorRunTime","Value":20,"Internal":true,"Count Failed Values":true},{"ID":745,"Name":"internal.metrics.executorCpuTime","Value":12478607,"Internal":true,"Count Failed Values":true},{"ID":746,"Name":"internal.metrics.resultSize","Value":1461,"Internal":true,"Count Failed Values":true},{"ID":763,"Name":"internal.metrics.input.bytesRead","Value":533,"Internal":true,"Count Failed Values":true},{"ID":764,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0}}
{"Event":"SparkListenerJobEnd","Job ID":27,"Completion Time":1641575661102,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"SparkListenerJobStart","Job ID":28,"Submission Time":1641575661207,"Stage Infos":[{"Stage ID":29,"Stage Attempt ID":0,"Stage Name":"load at LogisticRegression.scala:1302","Number of Tasks":1,"RDD Info":[{"RDD ID":75,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"129\",\"name\":\"mapPartitions\"}","Callsite":"load at LogisticRegression.scala:1302","Parent IDs":[74],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":74,"Name":"ParallelCollectionRDD","Scope":"{\"id\":\"128\",\"name\":\"parallelize\"}","Callsite":"load at LogisticRegression.scala:1302","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:239)\norg.apache.spark.ml.classification.LogisticRegressionModel$LogisticRegressionModelReader.load(LogisticRegression.scala:1302)\norg.apache.spark.ml.classification.LogisticRegressionModel$LogisticRegressionModelReader.load(LogisticRegression.scala:1292)\norg.apache.spark.ml.Pipeline$SharedReadWrite$.$anonfun$load$5(Pipeline.scala:277)\norg.apache.spark.ml.MLEvents.withLoadInstanceEvent(events.scala:160)\norg.apache.spark.ml.MLEvents.withLoadInstanceEvent$(events.scala:155)\norg.apache.spark.ml.util.Instrumentation.withLoadInstanceEvent(Instrumentation.scala:42)\norg.apache.spark.ml.Pipeline$SharedReadWrite$.$anonfun$load$4(Pipeline.scala:277)\nscala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:238)\nscala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)\nscala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)\nscala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)\nscala.collection.TraversableLike.map(TraversableLike.scala:238)\nscala.collection.TraversableLike.map$(TraversableLike.scala:231)\nscala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:198)\norg.apache.spark.ml.Pipeline$SharedReadWrite$.$anonfun$load$3(Pipeline.scala:274)\norg.apache.spark.ml.util.Instrumentation$.$anonfun$instrumented$1(Instrumentation.scala:191)\nscala.util.Try$.apply(Try.scala:213)\norg.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:191)\norg.apache.spark.ml.Pipeline$SharedReadWrite$.load(Pipeline.scala:268)","Accumulables":[],"Resource Profile Id":0}],"Stage IDs":[29],"Properties":{"__fetch_continuous_blocks_in_batch_enabled":"true","spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"130\",\"name\":\"collect\"}"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":29,"Stage Attempt ID":0,"Stage Name":"load at LogisticRegression.scala:1302","Number of Tasks":1,"RDD Info":[{"RDD ID":75,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"129\",\"name\":\"mapPartitions\"}","Callsite":"load at LogisticRegression.scala:1302","Parent IDs":[74],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":74,"Name":"ParallelCollectionRDD","Scope":"{\"id\":\"128\",\"name\":\"parallelize\"}","Callsite":"load at LogisticRegression.scala:1302","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:239)\norg.apache.spark.ml.classification.LogisticRegressionModel$LogisticRegressionModelReader.load(LogisticRegression.scala:1302)\norg.apache.spark.ml.classification.LogisticRegressionModel$LogisticRegressionModelReader.load(LogisticRegression.scala:1292)\norg.apache.spark.ml.Pipeline$SharedReadWrite$.$anonfun$load$5(Pipeline.scala:277)\norg.apache.spark.ml.MLEvents.withLoadInstanceEvent(events.scala:160)\norg.apache.spark.ml.MLEvents.withLoadInstanceEvent$(events.scala:155)\norg.apache.spark.ml.util.Instrumentation.withLoadInstanceEvent(Instrumentation.scala:42)\norg.apache.spark.ml.Pipeline$SharedReadWrite$.$anonfun$load$4(Pipeline.scala:277)\nscala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:238)\nscala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)\nscala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)\nscala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)\nscala.collection.TraversableLike.map(TraversableLike.scala:238)\nscala.collection.TraversableLike.map$(TraversableLike.scala:231)\nscala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:198)\norg.apache.spark.ml.Pipeline$SharedReadWrite$.$anonfun$load$3(Pipeline.scala:274)\norg.apache.spark.ml.util.Instrumentation$.$anonfun$instrumented$1(Instrumentation.scala:191)\nscala.util.Try$.apply(Try.scala:213)\norg.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:191)\norg.apache.spark.ml.Pipeline$SharedReadWrite$.load(Pipeline.scala:268)","Submission Time":1641575661207,"Accumulables":[],"Resource Profile Id":0},"Properties":{"__fetch_continuous_blocks_in_batch_enabled":"true","resource.executor.cores":"2","spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"130\",\"name\":\"collect\"}"}}
{"Event":"SparkListenerTaskStart","Stage ID":29,"Stage Attempt ID":0,"Task Info":{"Task ID":41,"Index":0,"Attempt":0,"Launch Time":1641575661215,"Executor ID":"1","Host":"host-name","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":29,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":41,"Index":0,"Attempt":0,"Launch Time":1641575661215,"Executor ID":"1","Host":"host-name","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1641575661319,"Failed":false,"Killed":false,"Accumulables":[{"ID":767,"Name":"internal.metrics.executorDeserializeTime","Update":20,"Value":20,"Internal":true,"Count Failed Values":true},{"ID":768,"Name":"internal.metrics.executorDeserializeCpuTime","Update":17782085,"Value":17782085,"Internal":true,"Count Failed Values":true},{"ID":769,"Name":"internal.metrics.executorRunTime","Update":78,"Value":78,"Internal":true,"Count Failed Values":true},{"ID":770,"Name":"internal.metrics.executorCpuTime","Update":11699125,"Value":11699125,"Internal":true,"Count Failed Values":true},{"ID":771,"Name":"internal.metrics.resultSize","Update":2389,"Value":2389,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0},"Task Metrics":{"Executor Deserialize Time":20,"Executor Deserialize CPU Time":17782085,"Executor Run Time":78,"Executor CPU Time":11699125,"Peak Execution Memory":0,"Result Size":2389,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":0},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":29,"Stage Attempt ID":0,"Stage Name":"load at LogisticRegression.scala:1302","Number of Tasks":1,"RDD Info":[{"RDD ID":75,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"129\",\"name\":\"mapPartitions\"}","Callsite":"load at LogisticRegression.scala:1302","Parent IDs":[74],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":74,"Name":"ParallelCollectionRDD","Scope":"{\"id\":\"128\",\"name\":\"parallelize\"}","Callsite":"load at LogisticRegression.scala:1302","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:239)\norg.apache.spark.ml.classification.LogisticRegressionModel$LogisticRegressionModelReader.load(LogisticRegression.scala:1302)\norg.apache.spark.ml.classification.LogisticRegressionModel$LogisticRegressionModelReader.load(LogisticRegression.scala:1292)\norg.apache.spark.ml.Pipeline$SharedReadWrite$.$anonfun$load$5(Pipeline.scala:277)\norg.apache.spark.ml.MLEvents.withLoadInstanceEvent(events.scala:160)\norg.apache.spark.ml.MLEvents.withLoadInstanceEvent$(events.scala:155)\norg.apache.spark.ml.util.Instrumentation.withLoadInstanceEvent(Instrumentation.scala:42)\norg.apache.spark.ml.Pipeline$SharedReadWrite$.$anonfun$load$4(Pipeline.scala:277)\nscala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:238)\nscala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)\nscala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)\nscala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)\nscala.collection.TraversableLike.map(TraversableLike.scala:238)\nscala.collection.TraversableLike.map$(TraversableLike.scala:231)\nscala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:198)\norg.apache.spark.ml.Pipeline$SharedReadWrite$.$anonfun$load$3(Pipeline.scala:274)\norg.apache.spark.ml.util.Instrumentation$.$anonfun$instrumented$1(Instrumentation.scala:191)\nscala.util.Try$.apply(Try.scala:213)\norg.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:191)\norg.apache.spark.ml.Pipeline$SharedReadWrite$.load(Pipeline.scala:268)","Submission Time":1641575661207,"Completion Time":1641575661319,"Accumulables":[{"ID":767,"Name":"internal.metrics.executorDeserializeTime","Value":20,"Internal":true,"Count Failed Values":true},{"ID":768,"Name":"internal.metrics.executorDeserializeCpuTime","Value":17782085,"Internal":true,"Count Failed Values":true},{"ID":769,"Name":"internal.metrics.executorRunTime","Value":78,"Internal":true,"Count Failed Values":true},{"ID":770,"Name":"internal.metrics.executorCpuTime","Value":11699125,"Internal":true,"Count Failed Values":true},{"ID":771,"Name":"internal.metrics.resultSize","Value":2389,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0}}
{"Event":"SparkListenerJobEnd","Job ID":28,"Completion Time":1641575661319,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":1,"description":"head at LogisticRegression.scala:1320","details":"org.apache.spark.sql.Dataset.head(Dataset.scala:2729)\norg.apache.spark.ml.classification.LogisticRegressionModel$LogisticRegressionModelReader.load(LogisticRegression.scala:1320)\norg.apache.spark.ml.classification.LogisticRegressionModel$LogisticRegressionModelReader.load(LogisticRegression.scala:1292)\norg.apache.spark.ml.Pipeline$SharedReadWrite$.$anonfun$load$5(Pipeline.scala:277)\norg.apache.spark.ml.MLEvents.withLoadInstanceEvent(events.scala:160)\norg.apache.spark.ml.MLEvents.withLoadInstanceEvent$(events.scala:155)\norg.apache.spark.ml.util.Instrumentation.withLoadInstanceEvent(Instrumentation.scala:42)\norg.apache.spark.ml.Pipeline$SharedReadWrite$.$anonfun$load$4(Pipeline.scala:277)\nscala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:238)\nscala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)\nscala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)\nscala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)\nscala.collection.TraversableLike.map(TraversableLike.scala:238)\nscala.collection.TraversableLike.map$(TraversableLike.scala:231)\nscala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:198)\norg.apache.spark.ml.Pipeline$SharedReadWrite$.$anonfun$load$3(Pipeline.scala:274)\norg.apache.spark.ml.util.Instrumentation$.$anonfun$instrumented$1(Instrumentation.scala:191)\nscala.util.Try$.apply(Try.scala:213)\norg.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:191)\norg.apache.spark.ml.Pipeline$SharedReadWrite$.load(Pipeline.scala:268)","physicalPlanDescription":"== Physical Plan ==\nCollectLimit (2)\n+- Scan parquet  (1)\n\n\n(1) Scan parquet \nOutput [5]: [numClasses#118, numFeatures#119, interceptVector#120, coefficientMatrix#121, isMultinomial#122]\nBatched: false\nLocation: InMemoryFileIndex [hdfs://localhost:9000/tmp/spark-logistic-regression-model/stages/2_logreg_8b15d2f29345/data]\nReadSchema: struct<numClasses:int,numFeatures:int,interceptVector:struct<type:tinyint,size:int,indices:array<int>,values:array<double>>,coefficientMatrix:struct<type:tinyint,numRows:int,numCols:int,colPtrs:array<int>,rowIndices:array<int>,values:array<double>,isTransposed:boolean>,isMultinomial:boolean>\n\n(2) CollectLimit\nInput [5]: [numClasses#118, numFeatures#119, interceptVector#120, coefficientMatrix#121, isMultinomial#122]\nArguments: 1\n\n","sparkPlanInfo":{"nodeName":"CollectLimit","simpleString":"CollectLimit 1","children":[{"nodeName":"Scan parquet ","simpleString":"FileScan parquet [numClasses#118,numFeatures#119,interceptVector#120,coefficientMatrix#121,isMultinomial#122] Batched: false, DataFilters: [], Format: Parquet, Location: InMemoryFileIndex[hdfs://localhost:9000/tmp/spark-logistic-regression-model/stages/2_logreg_8b15d..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<numClasses:int,numFeatures:int,interceptVector:struct<type:tinyint,size:int,indices:array<...","children":[],"metadata":{"Location":"InMemoryFileIndex[hdfs://localhost:9000/tmp/spark-logistic-regression-model/stages/2_logreg_8b15d2f29345/data]","ReadSchema":"struct<numClasses:int,numFeatures:int,interceptVector:struct<type:tinyint,size:int,indices:array<int>,values:array<double>>,coefficientMatrix:struct<type:tinyint,numRows:int,numCols:int,colPtrs:array<int>,rowIndices:array<int>,values:array<double>,isTransposed:boolean>,isMultinomial:boolean>","Format":"Parquet","Batched":"false","PartitionFilters":"[]","PushedFilters":"[]","DataFilters":"[]"},"metrics":[{"name":"number of output rows","accumulatorId":802,"metricType":"sum"},{"name":"number of files read","accumulatorId":803,"metricType":"sum"},{"name":"metadata time","accumulatorId":804,"metricType":"timing"},{"name":"size of files read","accumulatorId":805,"metricType":"size"}]}],"metadata":{},"metrics":[{"name":"shuffle records written","accumulatorId":800,"metricType":"sum"},{"name":"shuffle write time","accumulatorId":801,"metricType":"nsTiming"},{"name":"records read","accumulatorId":798,"metricType":"sum"},{"name":"local bytes read","accumulatorId":796,"metricType":"size"},{"name":"fetch wait time","accumulatorId":797,"metricType":"timing"},{"name":"remote bytes read","accumulatorId":794,"metricType":"size"},{"name":"local blocks read","accumulatorId":793,"metricType":"sum"},{"name":"remote blocks read","accumulatorId":792,"metricType":"sum"},{"name":"remote bytes read to disk","accumulatorId":795,"metricType":"size"},{"name":"shuffle bytes written","accumulatorId":799,"metricType":"size"}]},"time":1641575661418}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":1,"accumUpdates":[[803,1],[804,1],[805,4366]]}
{"Event":"SparkListenerJobStart","Job ID":29,"Submission Time":1641575661465,"Stage Infos":[{"Stage ID":30,"Stage Attempt ID":0,"Stage Name":"head at LogisticRegression.scala:1320","Number of Tasks":1,"RDD Info":[{"RDD ID":78,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"134\",\"name\":\"mapPartitionsInternal\"}","Callsite":"head at LogisticRegression.scala:1320","Parent IDs":[77],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":76,"Name":"FileScanRDD","Scope":"{\"id\":\"133\",\"name\":\"Scan parquet \"}","Callsite":"head at LogisticRegression.scala:1320","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":77,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"133\",\"name\":\"Scan parquet \"}","Callsite":"head at LogisticRegression.scala:1320","Parent IDs":[76],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.Dataset.head(Dataset.scala:2729)\norg.apache.spark.ml.classification.LogisticRegressionModel$LogisticRegressionModelReader.load(LogisticRegression.scala:1320)\norg.apache.spark.ml.classification.LogisticRegressionModel$LogisticRegressionModelReader.load(LogisticRegression.scala:1292)\norg.apache.spark.ml.Pipeline$SharedReadWrite$.$anonfun$load$5(Pipeline.scala:277)\norg.apache.spark.ml.MLEvents.withLoadInstanceEvent(events.scala:160)\norg.apache.spark.ml.MLEvents.withLoadInstanceEvent$(events.scala:155)\norg.apache.spark.ml.util.Instrumentation.withLoadInstanceEvent(Instrumentation.scala:42)\norg.apache.spark.ml.Pipeline$SharedReadWrite$.$anonfun$load$4(Pipeline.scala:277)\nscala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:238)\nscala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)\nscala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)\nscala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)\nscala.collection.TraversableLike.map(TraversableLike.scala:238)\nscala.collection.TraversableLike.map$(TraversableLike.scala:231)\nscala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:198)\norg.apache.spark.ml.Pipeline$SharedReadWrite$.$anonfun$load$3(Pipeline.scala:274)\norg.apache.spark.ml.util.Instrumentation$.$anonfun$instrumented$1(Instrumentation.scala:191)\nscala.util.Try$.apply(Try.scala:213)\norg.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:191)\norg.apache.spark.ml.Pipeline$SharedReadWrite$.load(Pipeline.scala:268)","Accumulables":[],"Resource Profile Id":0}],"Stage IDs":[30],"Properties":{"spark.sql.warehouse.dir":"file:/home/user/Benchmark/spark-warehouse","spark.driver.host":"host-name","spark.history.fs.logDirectory":"file:/home/user/logs","spark.eventLog.enabled":"true","spark.driver.port":"41119","__fetch_continuous_blocks_in_batch_enabled":"true","spark.jars":"file:/home/user/Benchmark/spark-3.1.2/examples/target/original-spark-examples_2.12-3.1.2.jar","spark.app.name":"PipelineExample","spark.driver.memory":"1g","spark.executor.instances":"1","spark.submit.pyFiles":"","spark.app.startTime":"1641575630976","spark.executor.id":"driver","spark.app.initial.jar.urls":"spark://host-name:41119/jars/original-spark-examples_2.12-3.1.2.jar","spark.submit.deployMode":"client","spark.master":"yarn","spark.ui.filters":"org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter","spark.executor.memory":"1g","spark.eventLog.dir":"file:/home/user/logs","spark.sql.execution.id":"1","spark.executor.cores":"2","spark.driver.appUIAddress":"http://host-name:4040","spark.org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter.param.PROXY_HOSTS":"host-name","spark.org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter.param.PROXY_URI_BASES":"http://host-name:8088/proxy/application_1641567765635_0075","spark.app.id":"application_1641567765635_0075"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":30,"Stage Attempt ID":0,"Stage Name":"head at LogisticRegression.scala:1320","Number of Tasks":1,"RDD Info":[{"RDD ID":78,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"134\",\"name\":\"mapPartitionsInternal\"}","Callsite":"head at LogisticRegression.scala:1320","Parent IDs":[77],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":76,"Name":"FileScanRDD","Scope":"{\"id\":\"133\",\"name\":\"Scan parquet \"}","Callsite":"head at LogisticRegression.scala:1320","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":77,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"133\",\"name\":\"Scan parquet \"}","Callsite":"head at LogisticRegression.scala:1320","Parent IDs":[76],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.Dataset.head(Dataset.scala:2729)\norg.apache.spark.ml.classification.LogisticRegressionModel$LogisticRegressionModelReader.load(LogisticRegression.scala:1320)\norg.apache.spark.ml.classification.LogisticRegressionModel$LogisticRegressionModelReader.load(LogisticRegression.scala:1292)\norg.apache.spark.ml.Pipeline$SharedReadWrite$.$anonfun$load$5(Pipeline.scala:277)\norg.apache.spark.ml.MLEvents.withLoadInstanceEvent(events.scala:160)\norg.apache.spark.ml.MLEvents.withLoadInstanceEvent$(events.scala:155)\norg.apache.spark.ml.util.Instrumentation.withLoadInstanceEvent(Instrumentation.scala:42)\norg.apache.spark.ml.Pipeline$SharedReadWrite$.$anonfun$load$4(Pipeline.scala:277)\nscala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:238)\nscala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)\nscala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)\nscala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)\nscala.collection.TraversableLike.map(TraversableLike.scala:238)\nscala.collection.TraversableLike.map$(TraversableLike.scala:231)\nscala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:198)\norg.apache.spark.ml.Pipeline$SharedReadWrite$.$anonfun$load$3(Pipeline.scala:274)\norg.apache.spark.ml.util.Instrumentation$.$anonfun$instrumented$1(Instrumentation.scala:191)\nscala.util.Try$.apply(Try.scala:213)\norg.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:191)\norg.apache.spark.ml.Pipeline$SharedReadWrite$.load(Pipeline.scala:268)","Submission Time":1641575661467,"Accumulables":[],"Resource Profile Id":0},"Properties":{"spark.sql.warehouse.dir":"file:/home/user/Benchmark/spark-warehouse","spark.driver.host":"host-name","spark.history.fs.logDirectory":"file:/home/user/logs","spark.eventLog.enabled":"true","resource.executor.cores":"2","spark.driver.port":"41119","__fetch_continuous_blocks_in_batch_enabled":"true","spark.jars":"file:/home/user/Benchmark/spark-3.1.2/examples/target/original-spark-examples_2.12-3.1.2.jar","spark.app.name":"PipelineExample","spark.driver.memory":"1g","spark.executor.instances":"1","spark.submit.pyFiles":"","spark.app.startTime":"1641575630976","spark.executor.id":"driver","spark.app.initial.jar.urls":"spark://host-name:41119/jars/original-spark-examples_2.12-3.1.2.jar","spark.submit.deployMode":"client","spark.master":"yarn","spark.ui.filters":"org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter","spark.executor.memory":"1g","spark.eventLog.dir":"file:/home/user/logs","spark.sql.execution.id":"1","spark.executor.cores":"2","spark.driver.appUIAddress":"http://host-name:4040","spark.org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter.param.PROXY_HOSTS":"host-name","spark.org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter.param.PROXY_URI_BASES":"http://host-name:8088/proxy/application_1641567765635_0075","spark.app.id":"application_1641567765635_0075"}}
{"Event":"SparkListenerTaskStart","Stage ID":30,"Stage Attempt ID":0,"Task Info":{"Task ID":42,"Index":0,"Attempt":0,"Launch Time":1641575661483,"Executor ID":"1","Host":"host-name","Locality":"NODE_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":30,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":42,"Index":0,"Attempt":0,"Launch Time":1641575661483,"Executor ID":"1","Host":"host-name","Locality":"NODE_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1641575661692,"Failed":false,"Killed":false,"Accumulables":[{"ID":802,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":806,"Name":"internal.metrics.executorDeserializeTime","Update":47,"Value":47,"Internal":true,"Count Failed Values":true},{"ID":807,"Name":"internal.metrics.executorDeserializeCpuTime","Update":44391878,"Value":44391878,"Internal":true,"Count Failed Values":true},{"ID":808,"Name":"internal.metrics.executorRunTime","Update":156,"Value":156,"Internal":true,"Count Failed Values":true},{"ID":809,"Name":"internal.metrics.executorCpuTime","Update":150112898,"Value":150112898,"Internal":true,"Count Failed Values":true},{"ID":810,"Name":"internal.metrics.resultSize","Update":1818,"Value":1818,"Internal":true,"Count Failed Values":true},{"ID":827,"Name":"internal.metrics.input.bytesRead","Update":7855,"Value":7855,"Internal":true,"Count Failed Values":true},{"ID":828,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0},"Task Metrics":{"Executor Deserialize Time":47,"Executor Deserialize CPU Time":44391878,"Executor Run Time":156,"Executor CPU Time":150112898,"Peak Execution Memory":0,"Result Size":1818,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":7855,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":30,"Stage Attempt ID":0,"Stage Name":"head at LogisticRegression.scala:1320","Number of Tasks":1,"RDD Info":[{"RDD ID":78,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"134\",\"name\":\"mapPartitionsInternal\"}","Callsite":"head at LogisticRegression.scala:1320","Parent IDs":[77],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":76,"Name":"FileScanRDD","Scope":"{\"id\":\"133\",\"name\":\"Scan parquet \"}","Callsite":"head at LogisticRegression.scala:1320","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":77,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"133\",\"name\":\"Scan parquet \"}","Callsite":"head at LogisticRegression.scala:1320","Parent IDs":[76],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.Dataset.head(Dataset.scala:2729)\norg.apache.spark.ml.classification.LogisticRegressionModel$LogisticRegressionModelReader.load(LogisticRegression.scala:1320)\norg.apache.spark.ml.classification.LogisticRegressionModel$LogisticRegressionModelReader.load(LogisticRegression.scala:1292)\norg.apache.spark.ml.Pipeline$SharedReadWrite$.$anonfun$load$5(Pipeline.scala:277)\norg.apache.spark.ml.MLEvents.withLoadInstanceEvent(events.scala:160)\norg.apache.spark.ml.MLEvents.withLoadInstanceEvent$(events.scala:155)\norg.apache.spark.ml.util.Instrumentation.withLoadInstanceEvent(Instrumentation.scala:42)\norg.apache.spark.ml.Pipeline$SharedReadWrite$.$anonfun$load$4(Pipeline.scala:277)\nscala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:238)\nscala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)\nscala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)\nscala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)\nscala.collection.TraversableLike.map(TraversableLike.scala:238)\nscala.collection.TraversableLike.map$(TraversableLike.scala:231)\nscala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:198)\norg.apache.spark.ml.Pipeline$SharedReadWrite$.$anonfun$load$3(Pipeline.scala:274)\norg.apache.spark.ml.util.Instrumentation$.$anonfun$instrumented$1(Instrumentation.scala:191)\nscala.util.Try$.apply(Try.scala:213)\norg.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:191)\norg.apache.spark.ml.Pipeline$SharedReadWrite$.load(Pipeline.scala:268)","Submission Time":1641575661467,"Completion Time":1641575661693,"Accumulables":[{"ID":802,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":806,"Name":"internal.metrics.executorDeserializeTime","Value":47,"Internal":true,"Count Failed Values":true},{"ID":807,"Name":"internal.metrics.executorDeserializeCpuTime","Value":44391878,"Internal":true,"Count Failed Values":true},{"ID":808,"Name":"internal.metrics.executorRunTime","Value":156,"Internal":true,"Count Failed Values":true},{"ID":809,"Name":"internal.metrics.executorCpuTime","Value":150112898,"Internal":true,"Count Failed Values":true},{"ID":810,"Name":"internal.metrics.resultSize","Value":1818,"Internal":true,"Count Failed Values":true},{"ID":827,"Name":"internal.metrics.input.bytesRead","Value":7855,"Internal":true,"Count Failed Values":true},{"ID":828,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0}}
{"Event":"SparkListenerJobEnd","Job ID":29,"Completion Time":1641575661693,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":1,"time":1641575661713}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":2,"description":"collect at PipelineExample.scala:83","details":"org.apache.spark.sql.Dataset.collect(Dataset.scala:2965)\norg.apache.spark.examples.ml.PipelineExample$.main(PipelineExample.scala:83)\norg.apache.spark.examples.ml.PipelineExample.main(PipelineExample.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\norg.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)\norg.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:951)\norg.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:203)\norg.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:90)\norg.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1039)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1048)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","physicalPlanDescription":"== Physical Plan ==\nLocalTableScan (1)\n\n\n(1) LocalTableScan\nOutput [4]: [id#143L, text#144, probability#177, prediction#190]\nArguments: [id#143L, text#144, probability#177, prediction#190]\n\n","sparkPlanInfo":{"nodeName":"LocalTableScan","simpleString":"LocalTableScan [id#143L, text#144, probability#177, prediction#190]","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":831,"metricType":"sum"}]},"time":1641575661828}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":2,"time":1641575661857}
{"Event":"SparkListenerApplicationEnd","Timestamp":1641575661861}
